/**
 * Seed Data - Ricky Chen Profile
 * Improved and normalized structure matching the backend schema
 */

export const seedProfileData = {
  name: "Ricky Chen",
  title: "Software Engineer & AI Researcher",
  location: "Sydney, Australia",
  bio: "Experienced in backend, mobile, and frontend development, with hands-on projects at Samsung R&D and Apple Developer Academy. Strong foundation in algorithms and competitive programming. Currently preparing for a Master of Artificial Intelligence at UTS, driven to build scalable tech with real-world impact.",

  academics: [
    {
      institution: "University of Technology Sydney – Australia",
      degree: "Master of Artificial Intelligence",
      field: "Artificial Intelligence",
      startDate: "2025-02-01",
      endDate: "2027-12-31",
      description:
        "Master of Artificial Intelligence | Specializing in machine learning, deep learning, and AI applications. Expected graduation in 2027.",
    },
    {
      institution: "Binus University – Indonesia",
      degree: "Bachelor of Computer Science",
      field: "Computer Science",
      startDate: "2019-09-01",
      endDate: "2023-06-30",
      description:
        "Bachelor of Computer Science | GPA: 3.83/4.00 | Focused on software engineering, algorithms, data structures, and software development methodologies. Completed capstone project in IoT and computer vision.",
    },
  ],

  certifications: [
    {
      name: "iOS & Swift Development",
      issuer: "Udemy",
      issueDate: "2023-02-01",
      credentialId: "UDEMY-IOS-SWIFT-2023",
      credentialUrl: "https://www.udemy.com",
    },
    {
      name: "Databases for Developers",
      issuer: "Oracle",
      issueDate: "2021-04-01",
      credentialId: "ORACLE-DB-DEV-2021",
      credentialUrl: "https://www.oracle.com",
    },
    {
      name: "Multiple Programming Languages Certification",
      issuer: "SoloLearn",
      issueDate: "2020-02-01",
      credentialId: "SOLOLEARN-MULTI-LANG-2020",
      credentialUrl: "https://www.sololearn.com",
    },
  ],

  contacts: [
    {
      type: "email" as const,
      value: "rickychen930@gmail.com",
      label: "Email",
      isPrimary: true,
    },
    {
      type: "linkedin" as const,
      value: "https://www.linkedin.com/in/rickychen930",
      label: "LinkedIn",
      isPrimary: false,
    },
    {
      type: "github" as const,
      value: "https://github.com/rickychen930",
      label: "GitHub",
      isPrimary: false,
    },
  ],

  experiences: [
    {
      company: "Web Architech",
      position: "Full-Stack Developer | Founder of Web Architech",
      location: "Sydney, Australia · Remote",
      startDate: "2025-01-01",
      isCurrent: true,
      description:
        "Founded a freelance practice delivering modern, high-performance web applications using MongoDB, Node.js, and React. Owned the full lifecycle: requirements, system design, implementation, testing, deployment, and optimization. Designed clean, maintainable codebases by applying OOP, SOLID, DRY, and MVC principles. Delivered custom client solutions with clear documentation, responsive communication, and ongoing support.",
      achievements: [
        "Founded a freelance practice delivering modern, high-performance web applications using MongoDB, Node.js, and React",
        "Owned the full lifecycle: requirements, system design, implementation, testing, deployment, and optimization",
        "Designed clean, maintainable codebases by applying OOP, SOLID, DRY, and MVC principles",
        "Delivered custom client solutions with clear documentation, responsive communication, and ongoing support",
      ],
      technologies: [
        "MongoDB",
        "Node.js",
        "React",
        "TypeScript",
        "REST APIs",
        "Git",
      ],
      skillIds: [
        "TypeScript",
        "Node.js",
        "React",
        "MongoDB",
        "Full-Stack Development",
      ],
    },
    {
      company: "Samsung R&D Institute – Jakarta",
      position: "Software Engineer",
      location: "Jakarta, Indonesia",
      startDate: "2023-05-01",
      endDate: "2024-05-31",
      isCurrent: false,
      description:
        "Enhanced SmartThings app functionality and performance. Developed TV Plugin for seamless smart TV integration, enabling device discovery, remote control, and status monitoring. Contributed to One UI 6 enhancements, improving UI/UX and accessibility across devices. Focused on TypeScript, modular architecture, and scalable design. Worked in an Agile environment with cross-functional teams.",
      achievements: [
        "Developed TV Plugin for SmartThings enabling device discovery, remote control, and status monitoring",
        "Contributed to One UI 6 enhancements improving UI/UX and accessibility",
        "Improved user experience for millions of SmartThings users worldwide",
        "Implemented scalable architecture using TypeScript and Node.js",
      ],
      technologies: [
        "TypeScript",
        "Node.js",
        "Samsung SmartThings SDK",
        "REST APIs",
        "Git",
        "Agile",
        "Scrum",
      ],
      skillIds: [
        "TypeScript",
        "Node.js",
        "Express.js",
        "RESTful APIs",
        "Git",
        "GitHub",
        "Backend Development",
      ],
    },
    {
      company: "Apple Developer Academy – Tangerang",
      position: "Software Engineer",
      location: "Tangerang, Indonesia",
      startDate: "2022-03-01",
      endDate: "2022-12-31",
      isCurrent: false,
      description:
        "Mastered Swift, UIKit, SwiftUI, GitHub, and soft skills through intensive training program. Developed five projects including Phowto (photography tutorials), Reguards (women's travel safety), and Bottani (farm management with remote control). Participated in design thinking workshops, user research, and iterative development processes. Collaborated with designers and other developers to create user-centered applications.",
      achievements: [
        "Developed five iOS applications using Swift and SwiftUI",
        "Mastered iOS development lifecycle, app architecture, and best practices",
        "Participated in design thinking workshops and user research",
        "Collaborated effectively with designers and developers in cross-functional teams",
      ],
      technologies: [
        "Swift",
        "SwiftUI",
        "UIKit",
        "Xcode",
        "Git",
        "Core Data",
        "Core Location",
        "AVFoundation",
      ],
      skillIds: [
        "Swift",
        "SwiftUI",
        "UIKit",
        "Git",
        "GitHub",
        "iOS Development",
      ],
    },
  ],

  honors: [
    {
      title: "LeetCode Problem Solver",
      issuer: "LeetCode Platform",
      date: "2024-01-01",
      description:
        "Solved 84+ problems covering data structures, algorithms, and system design. Skilled in C++, Python, and Java. Focused on improving problem-solving efficiency and code optimization.",
      url: "https://leetcode.com/rickychen930",
    },
    {
      title: "Top Global Programmer",
      issuer: "Kattis Platform",
      date: "2024-01-01",
      description:
        "Ranked 5510 globally with a score of 220.4. Ranked among top global programmers. Skilled in C++, Python, and Java. Demonstrates proficiency in competitive programming and algorithmic problem-solving.",
      url: "https://open.kattis.com/users/rickychen930",
    },
    {
      title: "Codeforces Specialist",
      issuer: "Codeforces Platform",
      date: "2024-01-01",
      description:
        "Achieved Specialist rating (1450) with 171 problems solved. Actively participates in contests and algorithmic challenges. Consistently solving problems across various difficulty levels including dynamic programming, graph algorithms, and data structures.",
      url: "https://codeforces.com/profile/rickychen930",
    },
    {
      title: "3rd Place – Competitive Programming",
      issuer: "Widyatama International Coding Competition",
      date: "2021-01-15",
      description:
        "Ranked 3rd in a Southeast Asia-wide coding competition. Collaborated in a team to solve advanced algorithmic challenges using C++, Python, and Java under time pressure. Demonstrated strong problem-solving skills and algorithmic thinking.",
    },
  ],

  languages: [
    {
      name: "Bahasa Indonesia",
      proficiency: "native" as const,
    },
    {
      name: "English",
      proficiency: "professional" as const,
    },
  ],

  projects: [
    {
      title: "Web Architech",
      description:
        "Company website for Web Architech, a web development company in Sydney.",
      longDescription:
        "Company website for Web Architech, a web development company in Sydney. Built with React, TypeScript, Express.js, and MongoDB, featuring a modern and responsive user interface. Enables visitors to browse services and contact the team. Implemented RESTful API architecture, secure forms, and efficient database design for scalability and performance.",
      technologies: [
        "React",
        "TypeScript",
        "Express.js",
        "MongoDB",
        "Node.js",
        "RESTful APIs",
      ],
      category: "fullstack" as const,
      startDate: "2025-12-01",
      isActive: true,
      liveUrl: "https://web-architech.com.au",
      achievements: [
        "Built production-ready company website with modern tech stack",
        "Implemented contact and inquiry flows with backend API",
        "Designed scalable RESTful API architecture",
        "Created responsive and accessible user interface",
      ],
      architecture:
        "Full-stack architecture with React frontend, Express.js backend, and MongoDB database. RESTful API design with secure form handling.",
    },
    {
      title: "JB IT Services",
      description:
        "Store and service website for JB IT Services, an IT services provider in Sydney.",
      longDescription:
        "Store and service website for JB IT Services, an IT services provider in Sydney. Built with React, TypeScript, Express.js, and MongoDB, featuring a modern and responsive user interface. Enables customers to browse and purchase IT services with seamless integration. Implemented RESTful API architecture, secure authentication, and efficient database design for scalability and performance.",
      technologies: [
        "React",
        "TypeScript",
        "Express.js",
        "MongoDB",
        "Node.js",
        "RESTful APIs",
      ],
      category: "fullstack" as const,
      startDate: "2025-12-01",
      isActive: true,
      liveUrl: "https://jbitservices.com.au",
      achievements: [
        "Built production-ready service and store front with modern tech stack",
        "Implemented secure authentication and payment integration",
        "Designed scalable RESTful API architecture",
        "Created responsive and user-friendly interface",
      ],
      architecture:
        "Full-stack architecture with React frontend, Express.js backend, and MongoDB database. RESTful API design with JWT authentication.",
    },
    {
      title: "Christina Sings4You",
      description:
        "Personal website for Christina Sings4You, a singer and vocal coach in Sydney.",
      longDescription:
        "Personal website for Christina Sings4You, a singer and vocal coach in Sydney. Built with React, TypeScript, and a modern stack, featuring a responsive user interface. Showcases services, bookings, and contact options. Implemented with clean architecture and performance in mind.",
      technologies: [
        "React",
        "TypeScript",
        "Express.js",
        "MongoDB",
        "Node.js",
        "RESTful APIs",
      ],
      category: "fullstack" as const,
      startDate: "2025-12-01",
      isActive: true,
      liveUrl: "https://christina-sings4you.com.au",
      achievements: [
        "Built production-ready personal branding and booking site",
        "Implemented contact and booking flows",
        "Designed responsive layout and clear information hierarchy",
        "Created accessible and mobile-friendly interface",
      ],
      architecture:
        "Full-stack architecture with React frontend and Node.js backend. RESTful API for forms and contact.",
    },
    {
      title: "giftforyou.idn",
      description:
        "A full-stack e-commerce platform for bouquet shopping in Indonesia.",
      longDescription:
        "A full-stack e-commerce platform for bouquet shopping in Indonesia. Built with React, TypeScript, Express.js, and MongoDB, featuring a modern and responsive user interface. The platform enables customers to browse, customize, and purchase bouquets with seamless payment integration and order tracking. Implemented RESTful API architecture, secure authentication, and efficient database design to ensure scalability and performance.",
      technologies: [
        "React",
        "TypeScript",
        "Express.js",
        "MongoDB",
        "Node.js",
        "RESTful APIs",
      ],
      category: "fullstack" as const,
      startDate: "2025-01-01",
      isActive: true,
      githubUrl: "https://github.com/rickychen930/giftforyou.idn",
      liveUrl: "https://giftforyou-idn.cloud",
      achievements: [
        "Built production-ready e-commerce platform with modern tech stack",
        "Implemented secure authentication and payment integration",
        "Designed scalable RESTful API architecture",
        "Created responsive and user-friendly interface",
      ],
      architecture:
        "Full-stack architecture with React frontend, Express.js backend, and MongoDB database. RESTful API design with JWT authentication and secure payment processing.",
    },
    {
      title: "TV Plugin – SmartThings",
      description:
        "Developed a TV control plugin for Samsung SmartThings app enabling device discovery, remote control, and status monitoring.",
      longDescription:
        "Developed a TV control plugin for Samsung SmartThings app. Enabled device discovery, remote control, and status monitoring for smart TVs. Contributed to One UI 6 enhancements and improved user experience for millions of users. Built with TypeScript, Node.js, and Samsung SmartThings SDK.",
      technologies: [
        "TypeScript",
        "Node.js",
        "Samsung SmartThings SDK",
        "REST APIs",
      ],
      category: "backend" as const,
      startDate: "2023-05-01",
      endDate: "2024-05-31",
      isActive: false,
      achievements: [
        "Enabled device discovery and remote control for smart TVs",
        "Improved user experience for millions of SmartThings users worldwide",
        "Integrated seamlessly with SmartThings ecosystem",
        "Implemented modular and scalable architecture",
      ],
    },
    {
      title: "Bottani",
      description:
        "A smart agriculture app integrated with IoT devices to monitor soil parameters in real time.",
      longDescription:
        "A smart agriculture app integrated with IoT devices to monitor soil parameters in real time. Enables automated responses based on environmental data, helping farmers maintain optimal soil conditions and improve crop productivity. Built during Apple Developer Academy using Swift, SwiftUI, and IoT integration.",
      technologies: ["Swift", "SwiftUI", "IoT", "Core Data", "Bluetooth"],
      category: "mobile" as const,
      startDate: "2022-08-01",
      endDate: "2022-12-31",
      isActive: false,
      achievements: [
        "Integrated IoT devices for real-time soil monitoring",
        "Implemented automated irrigation control system",
        "Created predictive analytics for crop management",
        "Built intuitive mobile interface for farmers",
      ],
    },
    {
      title: "Kabisa",
      description:
        "An educational app introducing Sundanese script through game-based learning.",
      longDescription:
        "An educational app introducing Sundanese script through game-based learning. Designed to preserve traditional language and culture. Presented in academic forums and published in IEEE. Built with Swift and SwiftUI, featuring interactive learning modules, gamification elements, and cultural preservation features.",
      technologies: [
        "Swift",
        "SwiftUI",
        "Game Development",
        "Education Technology",
      ],
      category: "mobile" as const,
      startDate: "2023-01-01",
      endDate: "2023-12-31",
      isActive: false,
      githubUrl: "https://github.com/rickychen930/kabisa",
      achievements: [
        "Preserved traditional Sundanese script through gamification",
        "Presented research at academic forums and published in IEEE",
        "Created engaging interactive learning modules",
        "Promoted cultural preservation through technology",
      ],
    },
    {
      title: "Reguards",
      description:
        "A women's travel safety app designed to enhance safety for women travelers.",
      longDescription:
        "A women's travel safety app developed during Apple Developer Academy. Designed to enhance safety for women travelers through real-time location sharing, emergency contacts, and safety alerts. Built with Swift and SwiftUI, featuring GPS tracking, emergency SOS functionality, and community safety features.",
      technologies: [
        "Swift",
        "SwiftUI",
        "Core Location",
        "AVFoundation",
        "GPS",
      ],
      category: "mobile" as const,
      startDate: "2022-03-01",
      endDate: "2022-12-31",
      isActive: false,
      achievements: [
        "Implemented real-time GPS tracking and location sharing",
        "Created emergency SOS functionality for user safety",
        "Built community safety features and alerts",
        "Addressed real-world safety concerns through technology",
      ],
    },
    {
      title: "Phowto",
      description:
        "A photography tutorial app providing interactive tutorials and guides for photography enthusiasts.",
      longDescription:
        "A photography tutorial app developed during Apple Developer Academy. Provides interactive tutorials and guides for photography enthusiasts. Built with Swift and SwiftUI, featuring video tutorials, step-by-step guides, and community features.",
      technologies: ["Swift", "SwiftUI", "AVFoundation", "Video Processing"],
      category: "mobile" as const,
      startDate: "2022-03-01",
      endDate: "2022-12-31",
      isActive: false,
      achievements: [
        "Created comprehensive photography learning platform",
        "Implemented video tutorial system",
        "Built step-by-step interactive guides",
        "Designed engaging user interface for learning",
      ],
    },
    {
      title: "M-arkir",
      description:
        "A license plate recognition system using Python and OpenCV with Arduino integration.",
      longDescription:
        "A license plate recognition system using Python and OpenCV. Integrated with Arduino for hardware control, combining C++ and Python to enable real-time image processing and automated response. Built as a university project.",
      technologies: [
        "Python",
        "OpenCV",
        "Arduino",
        "C++",
        "Computer Vision",
        "OCR",
      ],
      category: "ai" as const,
      startDate: "2022-01-01",
      endDate: "2022-06-30",
      isActive: false,
      achievements: [
        "Implemented real-time license plate recognition using OpenCV",
        "Integrated computer vision with embedded systems",
        "Created automated gate control system",
        "Demonstrated expertise in computer vision and IoT integration",
      ],
    },
    {
      title: "L-emot",
      description:
        "A smart lamp controller built with Arduino and custom hardware for wireless lighting control.",
      longDescription:
        "A smart lamp controller built with Arduino and custom hardware. Enabled wireless control of lighting through embedded systems and software integration. Demonstrates practical IoT applications in home automation.",
      technologies: ["Arduino", "C++", "Bluetooth", "IoT", "Embedded Systems"],
      category: "other" as const,
      startDate: "2022-01-01",
      endDate: "2022-06-30",
      isActive: false,
      achievements: [
        "Built custom hardware solution for smart lighting",
        "Implemented wireless control via Bluetooth",
        "Created energy monitoring features",
        "Demonstrated practical IoT application in home automation",
      ],
    },
  ],

  softSkills: [
    {
      name: "Agile & Scrum Development",
      category: "collaboration" as const,
    },
    {
      name: "Analytical Thinking",
      category: "problem-solving" as const,
    },
    {
      name: "Adaptability",
      category: "adaptability" as const,
    },
    {
      name: "Collaboration",
      category: "collaboration" as const,
    },
    {
      name: "Leadership",
      category: "leadership" as const,
    },
    {
      name: "Problem Solving",
      category: "problem-solving" as const,
    },
  ],

  stats: [
    {
      label: "Years of Experience",
      value: "2+",
      description: "Professional software development experience",
    },
    {
      label: "Projects Delivered",
      value: 12,
      description: "Successfully completed projects across various domains",
    },
    {
      label: "Users Impacted",
      value: "1M+",
      description: "Total users impacted by developed applications",
    },
  ],

  technicalSkills: [
    // Programming Languages
    {
      name: "Python",
      category: "language" as const,
      proficiency: "advanced" as const,
      yearsOfExperience: 4,
    },
    {
      name: "Swift",
      category: "language" as const,
      proficiency: "advanced" as const,
      yearsOfExperience: 3,
    },
    {
      name: "JavaScript",
      category: "language" as const,
      proficiency: "advanced" as const,
      yearsOfExperience: 3,
    },
    {
      name: "TypeScript",
      category: "language" as const,
      proficiency: "advanced" as const,
      yearsOfExperience: 2,
    },
    {
      name: "C",
      category: "language" as const,
      proficiency: "intermediate" as const,
      yearsOfExperience: 2,
    },
    {
      name: "C++",
      category: "language" as const,
      proficiency: "advanced" as const,
      yearsOfExperience: 4,
    },
    {
      name: "Java",
      category: "language" as const,
      proficiency: "intermediate" as const,
      yearsOfExperience: 2,
    },
    // Frameworks & Libraries
    {
      name: "React",
      category: "framework" as const,
      proficiency: "advanced" as const,
      yearsOfExperience: 2,
    },
    {
      name: "Node.js",
      category: "framework" as const,
      proficiency: "advanced" as const,
      yearsOfExperience: 2,
    },
    {
      name: "Express.js",
      category: "framework" as const,
      proficiency: "advanced" as const,
      yearsOfExperience: 2,
    },
    {
      name: "SwiftUI",
      category: "framework" as const,
      proficiency: "advanced" as const,
      yearsOfExperience: 3,
    },
    {
      name: "UIKit",
      category: "framework" as const,
      proficiency: "advanced" as const,
      yearsOfExperience: 3,
    },
    {
      name: "OpenCV",
      category: "framework" as const,
      proficiency: "intermediate" as const,
      yearsOfExperience: 2,
    },
    // Databases
    {
      name: "MongoDB",
      category: "database" as const,
      proficiency: "advanced" as const,
      yearsOfExperience: 2,
    },
    {
      name: "MySQL",
      category: "database" as const,
      proficiency: "intermediate" as const,
      yearsOfExperience: 2,
    },
    {
      name: "SQLite",
      category: "database" as const,
      proficiency: "intermediate" as const,
      yearsOfExperience: 2,
    },
    // Tools & Platforms
    {
      name: "Git",
      category: "tool" as const,
      proficiency: "advanced" as const,
      yearsOfExperience: 4,
    },
    {
      name: "GitHub",
      category: "tool" as const,
      proficiency: "advanced" as const,
      yearsOfExperience: 4,
    },
    {
      name: "Docker",
      category: "tool" as const,
      proficiency: "intermediate" as const,
      yearsOfExperience: 1,
    },
    {
      name: "RESTful APIs",
      category: "tool" as const,
      proficiency: "advanced" as const,
      yearsOfExperience: 2,
    },
    {
      name: "Arduino",
      category: "tool" as const,
      proficiency: "intermediate" as const,
      yearsOfExperience: 2,
    },
    // Specialties
    {
      name: "iOS Development",
      category: "other" as const,
      proficiency: "advanced" as const,
      yearsOfExperience: 3,
    },
    {
      name: "Machine Learning",
      category: "other" as const,
      proficiency: "intermediate" as const,
      yearsOfExperience: 1,
    },
    {
      name: "Computer Vision",
      category: "other" as const,
      proficiency: "intermediate" as const,
      yearsOfExperience: 2,
    },
    {
      name: "IoT Development",
      category: "other" as const,
      proficiency: "intermediate" as const,
      yearsOfExperience: 2,
    },
    {
      name: "Competitive Programming",
      category: "other" as const,
      proficiency: "advanced" as const,
      yearsOfExperience: 4,
    },
    {
      name: "Backend Development",
      category: "other" as const,
      proficiency: "advanced" as const,
      yearsOfExperience: 2,
    },
  ],

  testimonials: [
    {
      author: "Latifah Munawaroh",
      role: "Data Scientist",
      company: "Apple Developer Academy | Digital Talent Scholarship Awardee",
      content:
        "I had the pleasure of working alongside Ricky at Apple Developer Academy. As a highly skilled programmer with a strong background in competitive programming and IoT, Ricky consistently impressed me with his technical abilities. He is a dedicated problem solver who is always eager to explore the most effective solutions, striking a balance between design and development considerations. Ricky is an excellent communicator and collaborator. He actively listens to the ideas of others, particularly during design team meetings, and is always open to learning new techniques from colleagues, regardless of seniority. His confident and innovative approach to problem-solving makes him a valuable asset to any team.",
      date: "2024-11-01",
    },
    {
      author: "Ariel Waraney Manueke",
      role: "Master of IT Student @ UTS",
      company: "Apple Developer Academy",
      content:
        "I highly recommend Ricky for his outstanding skills in iOS development, collaboration, critical thinking, and problem-solving. We have worked together on an internship project, and I found him highly passionate and dedicated to his profession in tackling every task. He has a fun personality that makes me enjoy working with him every time. His contribution to the team as a developer is highly considerable as it helped our team to build our first app. Ricky definitely would become an appreciated member of any team.",
      date: "2023-05-01",
    },
    {
      author: "Galih Laras Prakoso",
      role: "Software Engineer",
      company: "Apple Developer Academy",
      content:
        "I am delighted to recommend my friend Ricky Chen, who I had the pleasure of working with me at the same team at Apple Developer Academy. Ricky Chen is a highly skilled software engineer who excels at competitive programming and has a natural talent for learning new technologies, as I witnessed firsthand when we were building iOS apps using SwiftUI. His ability to grasp complex concepts and implement them quickly and efficiently is remarkable. Ricky Chen is a critical thinker who brings a fresh perspective to ideation and is always willing to contribute ideas to the project. He takes his responsibilities seriously, always ensuring that the quality of work meets the highest standards. His positive attitude and fun personality make him a joy to work with, and his commitment to getting things done is second to none. Overall, I have no doubt that Ricky Chen would be an asset to any team or organization that he joins, and I wholeheartedly recommend him for any software engineering or development role.",
      date: "2023-05-01",
    },
    {
      author: "Queency Lowen",
      role: "Graphic Designer | UI/UX Designer",
      company: "Apple Developer Academy",
      content:
        "Ricky is a talented developer with excellent collaboration skills. Working with him on design and development projects was a great experience. He understands the importance of balancing technical implementation with user experience, making him a valuable team member.",
      date: "2023-05-01",
    },
    {
      author: "Rido Hendrawan",
      role: "Product Designer",
      company: "Apple Developer Academy",
      content:
        "Based on my experience working with Ricky on an iOS project app, I would highly recommend him as a skilled and dedicated software engineer. Ricky's expertise in Swift and iOS frameworks was instrumental in the success of our project, and his ability to work collaboratively with our team was invaluable. He consistently demonstrated strong communication skills, providing clear and concise updates on his progress and effectively addressing any issues that arose.",
      date: "2023-04-01",
    },
  ],

  learningSections: [
    {
      title: "How to Learn This Curriculum",
      slug: "how-to-learn",
      description:
        "Start here: suggested learning order, study tips (active recall, one topic at a time), time estimates per topic and for the full curriculum, and how to use Jump to and bookmarks for efficient revision.",
      order: 0,
      published: true,
      items: [
        {
          title: "Learning Path & Study Tips",
          description:
            "Suggested order, time per topic, active recall, and practice strategy",
          order: 0,
          imageUrl:
            "https://placehold.co/800x400/4338ca/white?text=Learning+Path+%26+Study+Tips",
          content:
            "**1. Learning flow:**\n\n(1) Read the suggested order and tips below — so you know which topics to do first and how much time to set aside; this avoids jumping between unrelated topics and helps you build on foundations before applied topics. (2) Bookmark /learning#section-{slug} for each section — then you can return to any section quickly from your browser without scrolling; replace {slug} with the section slug (e.g. competitive-programming, react). (3) Follow one topic at a time: read → summarize → try code → 1–2 practice problems — finishing one topic before moving on builds retention and avoids confusion; summarizing in your own words and typing the code yourself makes the knowledge stick. (4) Use Jump to above to navigate; do active recall after each topic — after reading, close the page and write three bullet points from memory or explain aloud; testing yourself strengthens long-term recall more than re-reading.\n\n**Your first step:** Open the Learning page, use the Jump to menu to go to **Competitive Programming**, then open the first item (**Complexity & Strategy**). Read sections 1–8 in order so you see the full structure (flow → material → explanation → application → implementation → logic → example → extras). Type the code example yourself so your hands learn the syntax; then try one problem (e.g. LeetCode Two Sum) to apply the idea. Do the same for each topic—one at a time.\n\n**Prerequisites:** Basic programming in one language (variables, loops, functions). If you are completely new, start with an introductory programming course first.\n\n**By the end of this section you will:** Know the recommended study order, how long to spend per topic, and how to use active recall and bookmarks to remember better.\n\n**2. Material:**\n\nEach topic in this curriculum follows the same structure (1. Learning flow → 2. Material → 3. Explanation → 4. Application → 5. How to implement → 6. Logic & how the code works → 7. Example problem & solution → 8. Additional information) so you always know what to expect.\n\nSuggested order: 1) How to Learn 2) Competitive Programming (Complexity, Sorting, Prefix Sum, DP, Graph, Trees, Heaps, Bit, Recursion) 3) CS Theory (OOP, SOLID, Data Structures) 4) Database & SQL 5) Computer Networks 6) OS & Concurrency 7) System Design & DevOps 8) React & Node.js 9) Security & Testing 10) Interview Preparation (read early for timeline; deep-dive before interviews).\n\n**3. Explanation:**\n\nOrder is chosen so foundations (CP, theory, DB, networks, OS) come before applied topics (React, Node, security). Interview Prep is useful to read early for planning and again before interviews. One topic at a time avoids context switching and builds retention.\n\n**4. Application:**\n\nUse this path for a full curriculum pass or for interview-only focus (CP, CS Theory, Networks, OS, System Design, Interview Prep). Adjust order if you are building a project first (e.g. React + Node earlier).\n\n**5. How to implement:**\n\n(1) For each topic: read the material first so you have context; then summarize in your own words (one or two sentences per section) so you check your understanding. (2) Run or type the code from the example—typing by hand helps you remember syntax and logic better than copy-paste. (3) Do 1–2 practice problems (e.g. from LeetCode or the suggested list) so you apply the concept; if you get stuck, re-read the Logic section and the example solution. (4) Use the Jump to menu to open a section quickly; bookmark /learning#section-competitive-programming (and similar for other sections) so you can revisit from your browser. (5) After each topic, close the page and write 3 bullets from memory or explain aloud to a peer (active recall)—this retrieval practice strengthens long-term retention more than re-reading.\n\n**6. Logic & how the code works:**\n\nThe suggested order forms one learning path; bookmarks link to section anchors (e.g. #section-competitive-programming). Active recall works because retrieving information from memory strengthens long-term retention more than re-reading.\n\n**7. Example problem & solution:**\n\nProblem: Forgetting topics after a few days. Solution: Active recall — after reading, close the page and write 3 key points or explain to a peer. For coding: type the code yourself and change inputs. Spaced repetition: revisit CP and System Design with practice problems weekly.\n\n**8. Additional information:** Time: 15–30 min read + 15–30 min practice per topic. CP and System Design need more practice. Full pass: 2–4 months with practice; interview-only: 2–6 weeks. Use LeetCode or Codeforces for CP; mock system design with a partner or video.",
          codeExample:
            "// Active recall template (after each topic)\n// 1. Close the page\n// 2. Write 3 key points from memory:\n//    - Point 1: _______________\n//    - Point 2: _______________\n//    - Point 3: _______________\n// 3. Compare with material; fill gaps\n// Bookmark format: /learning#section-competitive-programming",
          codeLanguage: "text",
        },
      ],
    },
    {
      title: "Competitive Programming",
      slug: "competitive-programming",
      description:
        "Foundation for coding interviews: Big O, sorting and binary search, prefix sum and sliding window, greedy and divide-and-conquer, dynamic programming, graphs (BFS, DFS, Dijkstra), trees and heaps, strings and math, bit manipulation, recursion and backtracking, and basic geometry. Each topic follows the same 8-part structure (learning flow → material → explanation → application → how to implement → logic & code walkthrough → example → additional info). Before you start: one programming language (C++, Python, or Java) and basic loops, arrays, and functions. Start with Complexity & Strategy, then follow the order of items.",
      order: 1,
      published: true,
      items: [
        {
          title: "Complexity & Strategy",
          description:
            "Big O, time/space trade-offs, mindset and practice approach",
          order: 0,
          content:
            '**1. Learning flow:**\n\n(1) Read the material below so you know what Big O is and how it describes growth with input size. (2) Understand Big O for one loop (linear) and nested loops (quadratic)—this is the most common pattern in interviews; practice by looking at a loop and asking "how many times does the body run?" (3) Try the code implementation: type the loop and Two Sum example yourself so you see how one pass with a hash map gives O(n). (4) Solve the example problem (Two Sum) on LeetCode; if you get stuck, re-read the Logic section. (5) Estimate complexity for 3 of your own solutions (e.g. other LeetCode problems)—state the complexity and justify it in one sentence; this habit is what interviewers expect.\n\n**2. Material:**\n\nBig O notation describes how time or space grows as input size n increases. O(1) = constant, O(n) = linear, O(n²) = quadratic, O(log n) = logarithmic. Time vs space trade-off: you can often use extra memory (e.g. a hash map) to reduce time.\n\n**3. Explanation:**\n\nBig O is an upper bound: we say an algorithm is O(n) if the number of steps is at most proportional to n for large n. One loop over n elements is O(n). Two nested loops over n each is O(n²). In contests and interviews, state your complexity and justify it; aim for the simplest correct solution first, then optimize if needed.\n\n**4. Application:**\n\nUse Big O to choose between algorithms (e.g. O(n log n) sort vs O(n²) bubble), to explain your solution in interviews, and to spot bottlenecks (e.g. a loop inside a loop may be O(n²)).\n\n**5. How to implement:**\n\n(1) When writing code, count loops: one pass over n elements = O(n); two nested loops each over n = O(n²)—this quick check catches most complexity mistakes. (2) Prefer built-in sort (O(n log n)) instead of writing an O(n²) sort unless the problem specifically asks for a custom sort. (3) When you need fast lookups (e.g. "have I seen this value?" or "what index is this value at?"), use a hash map—lookup and insert are O(1) per operation on average. (4) See the code block below for C++ examples: run them, then modify the loop bounds or add a nested loop and reason about the new complexity.\n\n**6. Logic & how the code works:**\n\nLoop O(n): Iteration from i=0 to i=n-1; each iteration does constant work. Total iterations = n, so O(n).\n\nNested loop O(n²): Outer loop i runs n times; inner loop j also n times. Total: n × n = n² iterations, so O(n²).\n\nTwo Sum O(n): One pass with unordered_map. For each number x, check if (target - x) is already in the map. If yes, pair found. Insert x into map after check. Map stores values already seen; lookup O(1) per element.\n\n**7. Example problem & solution:**\n\nProblem: Two Sum — Given array nums and target, return indices of two numbers that add up to target. LeetCode #1.\n\nSolution C++: One pass with unordered_map<int,int> storing value → index. For each nums[i], if (target - nums[i]) exists in map, return {map[target-nums[i]], i}. Otherwise, map[nums[i]] = i. Time O(n), space O(n). Edge: ensure we don\'t use the same element twice; since we check map before adding, index in map is always < i.\n\n**8. Additional information:** Strategy: practice daily on Codeforces or LeetCode; focus on patterns (two pointers, sliding window, DP); read editorials after solving. Common complexities: O(1), O(log n) binary search, O(n) linear scan, O(n log n) sort, O(n²) two loops, O(2^n) subsets. Interview tip: State complexity when presenting solution; explain trade-off (e.g. O(n) time + O(n) space vs O(n²) time + O(1) space). Common mistake: Off-by-one in loops; verify with edge cases (n=0, n=1). Language note: Examples in this section use C++; the same ideas apply in Python (dict, list) or Java (HashMap, ArrayList)—use the language you are most comfortable with for interviews.',
          codeExample:
            "// C++: Loop O(n) - one pass, n iterations\nfor (int i = 0; i < n; i++) {\n  // constant work per iteration\n}\n// Nested loop O(n²) - n×n iterations\nfor (int i = 0; i < n; i++)\n  for (int j = 0; j < n; j++)\n    process(i, j);\n\n// Two Sum - O(n) with hash map\nvector<int> twoSum(vector<int>& nums, int target) {\n  unordered_map<int,int> seen; // value -> index\n  for (int i = 0; i < nums.size(); i++) {\n    int need = target - nums[i];\n    if (seen.count(need)) return {seen[need], i};\n    seen[nums[i]] = i;\n  }\n  return {};\n}",
          codeLanguage: "cpp",
          imageUrl:
            "https://placehold.co/800x400/1e3a8a/white?text=Big+O+%7C+Complexity+%26+Strategy",
        },
        {
          title: "Sorting & Searching",
          description:
            "Comparison sorts, binary search, two pointers technique",
          order: 1,
          content:
            "**1. Learning flow:**\n\n(1) Read material and explanation so you know when to use sorting, binary search, and two pointers—each has a different use case (sorting for order, binary search for lookup in sorted data, two pointers for pairs or subarrays). (2) Implement binary search from the code: type it yourself and trace through with a small array (e.g. [1,3,5,7], find 5) so you see how lo/hi narrow. (3) Solve the example problem (Two Sum II) so you practice two pointers on a sorted array. (4) Try LeetCode Two Sum and 3Sum—3Sum uses sort plus one fixed element and two pointers for the remaining pair; this pattern appears often.\n\n**2. Material:**\n\nSorting: use built-in sort (C++ std::sort, Python sorted()) for O(n log n). Binary search: find position in sorted array in O(log n); maintain [lo, hi], compute mid, narrow range. Two pointers: two indices from both ends or same end; often O(n) on sorted arrays.\n\n**3. Explanation:**\n\nAfter sorting, many problems become easier: two pointers can find pairs with a given sum in O(n). Binary search works on the index space or on the answer space (binary search the answer). Always clarify if the array is sorted or if you may sort it.\n\n**4. Application:**\n\nUse sorting when order matters (e.g. find pairs, merge intervals). Use binary search for lookup in sorted data or when the answer is monotonic. Use two pointers for pairs, subarrays, or removal in place.\n\n**5. How to implement:**\n\n(1) Sort with std::sort(a.begin(), a.end()) (or Python sorted()) whenever you need ordered data; avoid writing your own sort unless required. (2) Binary search: keep a range [lo, hi] that could contain the answer; loop while lo <= hi; compute mid = lo + (hi - lo) / 2 to avoid overflow; compare a[mid] with target and set either lo = mid + 1 or hi = mid - 1 so the range shrinks; stop when lo > hi (not found) or when a[mid] == target. (3) Two pointers on a sorted array: start i=0, j=n-1; if a[i]+a[j] equals target you are done; if the sum is too small, increase i; if too large, decrease j—each step moves at least one pointer so the loop is O(n). See code below.\n\n**6. Logic & how the code works:**\n\nBinary search: Maintain range [lo, hi] that may contain x. Each iteration: compute mid = (lo+hi)/2. If a[mid]==x, done. If a[mid]<x, x must be on the right → lo=mid+1. If a[mid]>x, x must be on the left → hi=mid-1. Loop stops when lo>hi (x not found). Each step halves the range → O(log n).\n\nTwo pointers (sorted array): i on left, j on right. If a[i]+a[j]==target, found. If sum<target, need larger number → i++ (move i up). If sum>target, need smaller number → j-- (move j down). Since array is sorted, this strategy does not miss a solution.\n\n**7. Example problem & solution:**\n\nProblem: Two Sum II — Array is sorted in ascending order. Find two numbers that add up to target. Return 1-based indices. LeetCode #167.\n\nSolution C++: Two pointers. int i=0, j=n-1; while(i<j) { int s=a[i]+a[j]; if(s==target) return {i+1,j+1}; if(s<target) i++; else j--; } return {}; Time O(n), space O(1). Logic: Because the array is sorted, if sum is too small move the left pointer up; if too large move the right pointer down.\n\n**8. Additional information:** LeetCode: Two Sum, 3Sum (sort then two pointers per fixed first element), Binary Search. When to use binary search on answer: when the condition is monotonic (e.g. smallest x such that f(x) is true). Interview tip: Clarify if array is sorted; if not, ask if you may sort (O(n log n)). Binary search: use lo + (hi-lo)/2 to avoid overflow. Common mistake: Forgetting to handle duplicates in 3Sum.",
          codeExample:
            "// C++: Binary Search - find x in sorted array\nint lo = 0, hi = n - 1;\nwhile (lo <= hi) {\n  int mid = lo + (hi - lo) / 2; // avoid overflow\n  if (a[mid] == x) return mid;\n  if (a[mid] < x) lo = mid + 1;  // x on right\n  else hi = mid - 1;             // x on left\n}\nreturn -1; // not found\n\n// Two Sum II - two pointers on sorted array\nvector<int> twoSum(vector<int>& a, int target) {\n  int i = 0, j = (int)a.size() - 1;\n  while (i < j) {\n    int s = a[i] + a[j];\n    if (s == target) return {i+1, j+1};\n    if (s < target) i++;\n    else j--;\n  }\n  return {};\n}",
          codeLanguage: "cpp",
          imageUrl:
            "https://placehold.co/800x400/2563eb/white?text=Sorting+%26+Binary+Search",
        },
        {
          title: "Prefix Sum & Sliding Window",
          description:
            "Range queries, fixed/variable window, subarray problems",
          order: 2,
          content:
            '**1. Learning flow:**\n\n(1) Read material and explanation so you understand the two ideas: prefix sum turns range queries into O(1) lookups, and sliding window keeps a segment [i,j] and updates it incrementally instead of re-scanning. (2) Implement prefix sum (build pre[], then query sum(l..r)) and a sliding-window loop (expand j, then shrink i while invalid) from the code so you see the pattern. (3) Solve subarray sum equals K (prefix + frequency map) and longest substring with K distinct (sliding window + frequency map)—these are the classic patterns. (4) Try other LeetCode range-sum and sliding-window problems so you recognize when to use each.\n\n**2. Material:**\n\nPrefix sum: pre[i] = a[0]+...+a[i]; then sum(l..r) = pre[r+1]-pre[l] in O(1). Sliding window: maintain [i,j]; fixed size = move i and j together; variable size = expand j until valid, shrink i until invalid, update answer.\n\n**3. Explanation:**\n\nPrefix sum turns range-sum queries into two lookups. Sliding window avoids re-scanning by moving the window one step and updating state (e.g. frequency map). Both are one-pass O(n) or O(1) per query.\n\n**4. Application:**\n\nPrefix sum: range sum, count in range, subarray divisibility. Sliding window: max/min in window, longest substring with at most K distinct, minimum window substring.\n\n**5. How to implement:**\n\n(1) Build prefix array: pre[0]=0, then for i from 0 to n-1 set pre[i+1]=pre[i]+a[i]; now sum(l..r) = pre[r+1]-pre[l] in O(1). (2) For sliding window: use two pointers i and j; while j < n, extend the window by moving j and updating your state (e.g. frequency map); when the window becomes invalid, shrink from the left by moving i until valid again; at each valid step, update the answer (e.g. max length or min window). (3) For "subarray sum equals K": use a map that counts how many prefixes have a given sum; for each position j, add the count of prefixes with sum = (current_prefix_sum - K). See code below.\n\n**6. Logic & how the code works:**\n\nPrefix sum: pre[i] = sum of a[0..i-1]. So pre[r+1]-pre[l] = (a[0]+...+a[r]) - (a[0]+...+a[l-1]) = a[l]+...+a[r] = sum(l..r). Build: pre[0]=0; loop i from 0 to n-1, pre[i+1]=pre[i]+a[i]. Query O(1).\n\nSubarray sum K: For subarray ending at j, sum = pre[j+1]-pre[i] for some i<j. We want pre[j+1]-pre[i]=K → pre[i]=pre[j+1]-K. So for each j, count how many pre[i] we have seen equal to pre[j+1]-K. Store prefix counts in unordered_map; before moving j, add pre[j+1] to map.\n\n**7. Example problem & solution:**\n\nProblem: Subarray Sum Equals K — Count how many subarrays have sum K. LeetCode #560.\n\nSolution C++: unordered_map<int,int> cnt; cnt[0]=1 (empty prefix). int sum=0, ans=0; for(int x : nums) { sum+=x; ans+=cnt[sum-K]; cnt[sum]++; } return ans; Logic: sum = prefix up to current position. Subarray ending here with sum K exists if previous prefix = sum-K. cnt[sum-K] = number of matching prefixes. Time O(n), space O(n).\n\n**8. Additional information:** LeetCode: Subarray Sum Equals K, Longest Substring with At Most K Distinct, Minimum Window Substring. Variable window: expand right, shrink left while valid, update result. Interview tip: For subarray sum K, store prefix counts; count subarrays ending at j. Edge: K=0; empty subarray.',
          codeExample:
            "// C++: Prefix sum - build and query O(1)\nvector<int> pre(n+1);\npre[0] = 0;\nfor (int i = 0; i < n; i++)\n  pre[i+1] = pre[i] + a[i];\n// sum(l..r) = pre[r+1] - pre[l]\nint sum_lr = pre[r+1] - pre[l];\n\n// Subarray Sum Equals K - O(n)\nint subarraySum(vector<int>& nums, int k) {\n  unordered_map<int,int> cnt;\n  cnt[0] = 1;\n  int sum = 0, ans = 0;\n  for (int x : nums) {\n    sum += x;\n    ans += cnt[sum - k];\n    cnt[sum]++;\n  }\n  return ans;\n}",
          codeLanguage: "cpp",
          imageUrl:
            "https://placehold.co/800x400/16a34a/white?text=Prefix+Sum+%26+Sliding+Window",
        },
        {
          title: "Greedy & Divide & Conquer",
          description: "Optimal substructure, merge sort, quick select",
          order: 3,
          content:
            '**1. Learning flow:**\n\n(1) Read material and explanation so you know when greedy works (local optimal leads to global optimal, often provable by exchange argument) and how D&C works (split, solve subproblems, combine). (2) Implement the merge step and run merge sort once by hand on a small array so you see how two sorted halves become one sorted array in O(n). (3) Solve one greedy problem (e.g. activity selection or non-overlapping intervals) so you practice the "sort then choose" pattern. (4) Try quick select for the k-th smallest element so you see how partition plus recursion gives expected O(n).\n\n**2. Material:**\n\nGreedy: at each step choose the locally best option; works when local optimal implies global optimal. D&C: split into subproblems, solve recursively, combine. Merge sort: split at mid, sort halves, merge in O(n). Quick select: partition around pivot to find k-th smallest in expected O(n).\n\n**3. Explanation:**\n\nGreedy is correct when an exchange argument or induction shows that no other choice leads to a better result. D&C reduces problem size; recurrence T(n)=2T(n/2)+O(n) gives O(n log n) for merge sort.\n\n**4. Application:**\n\nGreedy: activity selection, Huffman coding, interval scheduling, coin change (when greedy works). D&C: merge sort, quick select, closest pair of points, Strassen.\n\n**5. How to implement:**\n\n(1) Greedy: Identify the choice at each step (e.g. pick the interval with earliest end time). Often you sort first (e.g. by end time) so the "best" choice is easy to see. Then one pass: at each step make the greedy choice (e.g. if the current interval does not overlap the last chosen one, take it). (2) Merge step (two sorted arrays → one): Use two pointers i and j on the two arrays; compare elements at i and j, append the smaller to the result and advance that pointer; when one array is exhausted, append the rest of the other. (3) Merge sort: Recursively sort the left and right halves (base case: length 0 or 1), then merge the two sorted halves with the merge step. (4) Quick select (k-th smallest): Partition the array around a pivot (like quicksort); if the pivot ends up at index p, then if p == k we are done; if p < k recurse on the right part with k adjusted; if p > k recurse on the left. See code below.\n\n**6. Logic & how the code works:**\n\nMerge step: Combine L = a[l..m] and R = a[m+1..r] (both already sorted). Two pointers i, j on L and R. Compare L[i] and R[j]; take the smaller, write to a[k], advance pointer. When one runs out, copy the rest. Total O(r-l+1).\n\nActivity selection greedy: Sort intervals by end time. Pick first interval (earliest end). For each next interval, pick if start >= last_end. Picking earliest end maximizes remaining space for other intervals.\n\n**7. Example problem & solution:**\n\nProblem: Non-overlapping Intervals — Remove minimal intervals so none overlap. LeetCode #435.\n\nSolution C++: Sort by end. int last=-1e9, ans=0; for(auto& v : intervals) { if(v[0]>=last) last=v[1]; else ans++; } return ans; Logic: Sort by end ensures we always have earliest end. If interval overlaps with last (v[0]<last), remove (ans++). If no overlap, update last=v[1]. Time O(n log n).\n\n**8. Additional information:**\n\nProve greedy with exchange: assume optimal differs; show we can swap to match greedy without worsening. LeetCode: Merge Intervals, Insert Interval, Kth Largest Element (quick select).',
          codeExample:
            "// C++: Merge sort - merge step: combine L and R\nvoid merge(vector<int>& a, int l, int m, int r) {\n  vector<int> L(a.begin()+l, a.begin()+m+1);\n  vector<int> R(a.begin()+m+1, a.begin()+r+1);\n  int i=0, j=0, k=l;\n  while (i < (int)L.size() && j < (int)R.size())\n    a[k++] = L[i] <= R[j] ? L[i++] : R[j++];\n  while (i < (int)L.size()) a[k++] = L[i++];\n  while (j < (int)R.size()) a[k++] = R[j++];\n}\n\n// Greedy: Non-overlapping Intervals (sort by end)\nint eraseOverlapIntervals(vector<vector<int>>& v) {\n  sort(v.begin(), v.end(), [](auto& a, auto& b){return a[1]<b[1];});\n  int last = -1e9, ans = 0;\n  for (auto& p : v)\n    if (p[0] >= last) last = p[1];\n    else ans++;\n  return ans;\n}",
          codeLanguage: "cpp",
          imageUrl:
            "https://placehold.co/800x400/0d9488/white?text=Greedy+%26+Divide+%26+Conquer",
        },
        {
          title: "Dynamic Programming",
          description:
            "Memoization, tabulation, classic problems (LIS, knapsack, etc.)",
          order: 4,
          content:
            '**1. Learning flow:**\n\n(1) Read material and identify state and recurrence—state is "what position am I in the problem?" (e.g. index i, or capacity w), recurrence is how the answer at this state depends on smaller states. (2) Implement the 0/1 knapsack from the code: build the table, then try the space-optimized version with one row and backward loop so you see how order matters. (3) Solve Climbing Stairs (simple 1D DP) and Coin Change (unbounded knapsack style) so you practice writing recurrence and base cases. (4) Try LIS (longest increasing subsequence) and LCS (longest common subsequence)—they use 2D state and are classic interview problems.\n\n**2. Material:**\n\nDP needs optimal substructure (best solution uses best sub-solutions) and overlapping subproblems (same subproblem repeated). Define state (e.g. dp[i], dp[i][j]), recurrence, base case, and order of computation. Memoization = top-down + cache; tabulation = bottom-up table.\n\n**3. Explanation:**\n\nState encodes the "position" in the problem (e.g. index, remaining capacity). Recurrence relates state to smaller states. Fill in order so dependencies are ready. Space can often be optimized (e.g. one row for knapsack).\n\n**4. Application:**\n\nClassic: Fibonacci, Climbing Stairs, Coin Change, LIS, 0/1 knapsack, LCS, edit distance, matrix chain. Many string and sequence problems are DP.\n\n**5. How to implement:**\n\n(1) Write the recurrence in words first: "The best value for the first i items with capacity w is the maximum of (skip item i: use dp[i-1][w]) or (take item i if it fits: value[i] + dp[i-1][w-weight[i]])." (2) Identify the base case: smallest subproblems (e.g. dp[0][w] = 0 for all w). (3) Choose the order of computation: for 0/1 knapsack, loop i from 1 to n and w from 0 to W so that when you compute dp[i][w] you have already computed dp[i-1][*]. (4) Implement the table: 2D array or, for space optimization, one row and loop w backwards so you do not overwrite values you still need. (5) Return the answer at dp[n][W] (or dp[W] if optimized). See 0/1 knapsack code below.\n\n**6. Logic & how the code works:**\n\n0/1 Knapsack: dp[i][w] = max value with items 1..i and capacity w. Choices: (1) Skip item i → dp[i-1][w]. (2) Take item i (if weight[i]<=w) → val[i] + dp[i-1][w-weight[i]]. Take max. Base: dp[0][w]=0. Loop i ascending so dp[i-1][*] is already filled.\n\nSpace optimization: Only need one row. Loop w backwards (from W to 0) so when updating dp[w] we use old value of dp[w-weight[i]] (not yet overwritten).\n\n**7. Example problem & solution:**\n\nProblem: 0/1 Knapsack — n items (weight[], value[]), capacity W. Maximize total value. Each item at most once.\n\nSolution C++: vector<int> dp(W+1, 0); for(int i=0; i<n; i++) for(int w=W; w>=weight[i]; w--) dp[w]=max(dp[w], value[i]+dp[w-weight[i]]); return dp[W]; Logic: Loop w backwards so dp[w-weight[i]] is not yet updated (still represents i-1). Time O(n*W), space O(W).\n\n**8. Additional information:** LeetCode: Climbing Stairs, Coin Change, Longest Increasing Subsequence, Partition Equal Subset Sum. Interview tip: Start with brute-force recursion; add memoization; convert to tabulation. Coin change: unbounded (loop coin dulu) vs bounded. Space optimization: knapsack iterate w backwards.',
          codeExample:
            "// C++: 0/1 Knapsack - tabulation 2D\nvector<vector<int>> dp(n+1, vector<int>(W+1, 0));\nfor (int i = 1; i <= n; i++)\n  for (int w = 0; w <= W; w++) {\n    dp[i][w] = dp[i-1][w];           // skip item i\n    if (weight[i-1] <= w)\n      dp[i][w] = max(dp[i][w],\n        val[i-1] + dp[i-1][w-weight[i-1]]); // take\n  }\nreturn dp[n][W];\n\n// Space optimization O(W) - loop w backwards\nvector<int> dp(W+1, 0);\nfor (int i = 0; i < n; i++)\n  for (int w = W; w >= weight[i]; w--)\n    dp[w] = max(dp[w], value[i] + dp[w-weight[i]]);\nreturn dp[W];",
          codeLanguage: "cpp",
          imageUrl:
            "https://placehold.co/800x400/7c3aed/white?text=Dynamic+Programming",
        },
        {
          title: "Graph Theory",
          description: "BFS, DFS, Dijkstra, MST, topological sort",
          order: 5,
          content:
            "**1. Learning flow:**\n\n(1) Read material and when to use BFS vs DFS vs Dijkstra—BFS for shortest path in unweighted graphs, DFS for exploring components or topological order, Dijkstra for weighted shortest path (non-negative). (2) Implement BFS from the code (queue, dist array, relax neighbors) so you see the level-by-level expansion. (3) Solve Number of Islands (DFS/BFS from each unvisited '1') and Course Schedule (topological sort) so you practice both traversal and dependency order. (4) Try Network Delay Time (Dijkstra with min-heap) so you see how weighted shortest path works.\n\n**2. Material:**\n\nBFS: level-order; shortest path in unweighted graph. DFS: depth-first; cycles, connected components, topological sort (post-order). Dijkstra: shortest path weighted (non-negative); priority queue. MST: Prim or Kruskal. Topo sort: order so every edge goes forward; DFS+stack or Kahn (in-degree).\n\n**3. Explanation:**\n\nBFS explores by layers so first time we reach a node is shortest in edge count. DFS goes deep; useful for exploring all nodes in a component or for topo order. Dijkstra relaxes edges from the closest unvisited node; non-negative weights required.\n\n**4. Application:**\n\nBFS: shortest path (unweighted), level-order, multi-source BFS. DFS: cycle detection, components, topo sort, path finding. Dijkstra: weighted shortest path. MST: connect all nodes with min total weight.\n\n**5. How to implement:**\n\n(1) BFS (shortest path unweighted): Initialize dist[s]=0 and dist[v]=-1 (or infinity) for others; queue containing s. While queue not empty: pop node u; for each neighbor v of u, if dist[v] is still -1 set dist[v]=dist[u]+1 and push v. The first time a node is reached, you have a shortest path to it. (2) DFS: Use a stack (or recursion) and a visited set; push start, then while stack not empty pop u, if u not visited mark it and push all unvisited neighbors. Use for exploring a component, cycle detection, or topological sort (post-order: process node after its descendants). (3) Dijkstra (weighted shortest path, non-negative weights): Min-heap of (distance, node); initialize dist[s]=0, others infinity; push (0, s). While heap not empty: pop (d, u); if d > dist[u] skip (stale); for each edge (u, v, w) if dist[u]+w < dist[v] update dist[v] and push (dist[v], v). (4) See BFS and Dijkstra code below.\n\n**6. Logic & how the code works:**\n\nBFS: Queue ensures we process nodes level by level. First time a node is visited = shortest distance (because each edge weight 1). For each u we pop, check all neighbors v. If v not yet visited (dist[v]==-1), set dist[v]=dist[u]+1 and push v. BFS finishes when queue is empty.\n\nDijkstra: Min-heap stores (distance, node). Extract node with smallest dist (not yet final). Relax: for each edge (u,v,w), if dist[u]+w < dist[v], update dist[v] and push (dist[v], v). Each node processed once when leaving heap (already optimal).\n\n**7. Example problem & solution:**\n\nProblem: Number of Islands — grid '1' and '0'. Count number of islands (connected '1'). LeetCode #200.\n\nSolution C++: DFS/BFS from each '1' not yet visited. int ans=0; for(i, j) if(grid[i][j]=='1') { ans++; dfs(i,j); } dfs: if out of bounds or '0', return. grid[i][j]='0' (mark visited). dfs(i±1,j); dfs(i,j±1). Or BFS with queue. Each DFS/BFS marks one island. Time O(rows*cols).\n\n**8. Additional information:**\n\nLeetCode: Number of Islands, Course Schedule (topo), Network Delay Time (Dijkstra). For negative weights use Bellman-Ford. Topo: Kahn = remove nodes with in-degree 0.",
          codeExample:
            "// C++: BFS shortest path (unweighted)\nvector<int> dist(n, -1);\ndist[s] = 0;\nqueue<int> q; q.push(s);\nwhile (!q.empty()) {\n  int u = q.front(); q.pop();\n  for (int v : adj[u])\n    if (dist[v] == -1) {\n      dist[v] = dist[u] + 1;\n      q.push(v);\n    }\n}\n\n// Dijkstra - shortest path weighted (non-negative)\nvector<int> dist(n, 1e9); dist[s] = 0;\npriority_queue<pair<int,int>, vector<pair<int,int>>, greater<>> pq;\npq.push({0, s});\nwhile (!pq.empty()) {\n  auto [d, u] = pq.top(); pq.pop();\n  if (d > dist[u]) continue;\n  for (auto [v, w] : adj[u])\n    if (dist[u] + w < dist[v]) {\n      dist[v] = dist[u] + w;\n      pq.push({dist[v], v});\n    }\n}",
          codeLanguage: "cpp",
          imageUrl:
            "https://placehold.co/800x400/dc2626/white?text=Graph+BFS+DFS+Dijkstra",
        },
        {
          title: "Trees",
          description: "Binary trees, LCA, segment tree, Fenwick tree",
          order: 6,
          content:
            "**1. Learning flow:**\n\n(1) Read material and traversals so you understand binary tree structure (at most two children per node), the three standard traversals (inorder: left–root–right, preorder: root–left–right, postorder: left–right–root), and when each is used—inorder gives sorted order in a BST; preorder for copying or prefix expressions; postorder for deletion or postfix. (2) Implement the segment tree query and update from the code: build the tree so each node stores the sum of its segment, then implement query(v, tl, tr, l, r) with the three cases (disjoint, fully inside, partial overlap) so you see how O(log n) range queries work. (3) Implement inorder traversal recursively and solve one range-sum problem (e.g. LeetCode 307) so you practice both the tree structure and the segment tree pattern. (4) Try LCA (lowest common ancestor) with binary lifting or a simple recursive approach, or Fenwick (BIT) for prefix sum with point updates—both are common in contests and interviews.\n\n**2. Material:**\n\n**Binary tree:** Each node has at most two children (left and right). Used for BST (binary search tree), expression trees, and as the basis for segment trees and heaps. Traversals: **inorder** (left, then root, then right)—for a BST this visits nodes in sorted order; **preorder** (root, then left, then right)—useful for copying or serialization; **postorder** (left, then right, then root)—useful when you need to process children before the root (e.g. deletion).\n\n**Segment tree:** A full binary tree built over an array so that each node corresponds to a range [tl, tr] and stores an aggregate (e.g. sum, min, max). The root covers [0, n-1]; the left child of a node covering [tl, tr] covers [tl, tm] and the right covers [tm+1, tr] where tm = (tl+tr)/2. Build: bottom-up, each node combines its children. Query(l, r): start at root; if the node’s range is disjoint from [l, r] return neutral (e.g. 0 for sum); if the node’s range is entirely inside [l, r] return the node’s value; otherwise recurse to both children and combine. Update(i, val): go to the leaf that covers index i, update it, then bubble up updating each parent. Both query and update are O(log n). Array size: 4*n is safe for the tree array.\n\n**Fenwick tree (BIT):** A structure that supports prefix sum and point update in O(log n) with less memory and code than a full segment tree. It uses bit tricks: the index of the parent of node i is i - (i & -i). Used for prefix sums, inversion count, and order statistics. Lighter than segment tree when you only need prefix/point operations.\n\n**LCA (lowest common ancestor):** The lowest node in a tree that is an ancestor of both of two given nodes. Can be computed with binary lifting (precompute 2^j-th ancestor for each node) or with a simple recursive approach that returns the node if it is one of the targets or if its subtree contains both targets. Used for distance between two nodes (dist(u,v) = depth(u) + depth(v) - 2*depth(lca(u,v))) and path queries.\n\n**3. Explanation:**\n\nSegment tree is a full binary tree over the array: each node covers a contiguous range and stores an aggregate. A query for [l, r] is answered by combining at most O(log n) node values because at each level you split at segment boundaries. An update at index i affects only the path from the leaf at i to the root, so O(log n) nodes are updated. Fenwick uses the binary representation of indices to compute prefix sums and perform updates in O(log n) with fewer nodes. Inorder traversal of a BST visits nodes in sorted order because for every node, all nodes in the left subtree are smaller and all in the right are larger, so left–root–right gives ascending order.\n\n**4. Application:**\n\nSegment tree: range sum, range min/max, range update (with lazy propagation). Fenwick: prefix sum with point update, inversion count (add elements in order and count how many existing elements are larger), order statistics. LCA: distance between two nodes in a tree, path sum or path min. Binary tree traversals: BST operations, expression evaluation, serialization.\n\n**5. How to implement:**\n\n(1) Segment tree build: allocate array t of size 4*n. Recursive build(v, tl, tr): if tl == tr, set t[v] = a[tl] and return; else tm = (tl+tr)/2, build(2*v, tl, tm), build(2*v+1, tm+1, tr), then t[v] = combine(t[2*v], t[2*v+1]) (e.g. t[2*v] + t[2*v+1] for sum). (2) Query(v, tl, tr, l, r): if l > tr or r < tl return neutral (0 for sum); if l <= tl and tr <= r return t[v]; tm = (tl+tr)/2; return combine(query(2*v, tl, tm, l, r), query(2*v+1, tm+1, tr, l, r)). (3) Update(v, tl, tr, i, val): if tl == tr set t[v] = val and return; tm = (tl+tr)/2; if i <= tm update(2*v, tl, tm, i, val), else update(2*v+1, tm+1, tr, i, val); then t[v] = combine(t[2*v], t[2*v+1]). (4) Inorder: if node is null return; inorder(left); process(node); inorder(right). See code below.\n\n**6. Logic & how the code works:**\n\nSegment tree query: Node v covers [tl, tr]. Cases: (1) [l,r] disjoint from [tl,tr] (l > tr or r < tl) → return 0 so this branch contributes nothing. (2) [tl,tr] entirely inside [l,r] → return t[v] (the precomputed sum for this segment). (3) Partial overlap → split at tm=(tl+tr)/2, recurse to left and right children, combine. Left child covers [tl,tm], right [tm+1,tr]. At most two recursive calls per level and O(log n) levels, so O(log n). Inorder: visit left subtree first, then the root, then the right subtree. For a BST, all left nodes are smaller than the root and all right nodes are larger, so this order yields ascending order.\n\n**7. Example problem & solution:**\n\nProblem: Range Sum Query - Mutable — Array with update(i, val) and sumRange(l, r). LeetCode #307.\n\nSolution C++: Segment tree. t[1..4n-1], node v covers [tl,tr]. build: if tl==tr, t[v]=a[tl]; else tm=(tl+tr)/2, build(2*v,tl,tm), build(2*v+1,tm+1,tr), t[v]=t[2*v]+t[2*v+1]. update: if tl==tr, t[v]=val; else update child containing i, then t[v]=t[2*v]+t[2*v+1]. query as above. O(log n) per operation. Space O(n) for the tree array.\n\n**8. Additional information:**\n\nFenwick: parent index is i - (i & -i); (i & -i) is the lowest set bit. LeetCode: Range Sum Query Mutable (#307), Count Smaller After Self. Lazy propagation for range updates on segment tree. Use 0-based or 1-based indexing consistently.",
          codeExample:
            "// C++: Segment tree - range sum query\nint t[4*N]; // tree array\nint query(int v, int tl, int tr, int l, int r) {\n  if (l > tr || r < tl) return 0;  // disjoint\n  if (l <= tl && tr <= r) return t[v]; // fully inside\n  int tm = (tl + tr) / 2;\n  return query(2*v, tl, tm, l, r) +\n         query(2*v+1, tm+1, tr, l, r);\n}\n// Update point i\nvoid update(int v, int tl, int tr, int i, int val) {\n  if (tl == tr) { t[v] = val; return; }\n  int tm = (tl + tr) / 2;\n  if (i <= tm) update(2*v, tl, tm, i, val);\n  else update(2*v+1, tm+1, tr, i, val);\n  t[v] = t[2*v] + t[2*v+1];\n}",
          codeLanguage: "cpp",
          imageUrl:
            "https://placehold.co/800x400/ea580c/white?text=Trees+Segment+Tree+Fenwick",
        },
        {
          title: "Heaps & Priority Queues",
          description: "Binary heap, min/max heap, heapify; Dijkstra and top-K",
          order: 7,
          content:
            '**1. Learning flow:**\n\n(1) Read material and the heap property: in a min-heap the parent is always less than or equal to both children, so the smallest element is at the root; the tree is stored in a complete binary tree layout in an array (parent at i/2, children at 2i and 2i+1). (2) Use the code to implement top-K: maintain a min-heap of size K; for each new element push it, then if size exceeds K pop the minimum—the root will be the K-th largest when you finish. (3) Solve Kth Largest Element (LeetCode 215) and Merge K Sorted Lists (LeetCode 23) so you practice both the top-K pattern and the merge pattern with a heap. (4) Use a heap in Dijkstra: the algorithm repeatedly extracts the node with smallest tentative distance and relaxes its neighbors; a min-heap keyed by distance gives you that in O(log n) per extraction.\n\n**2. Material:**\n\n**Binary heap:** A complete binary tree (all levels full except possibly the last, filled left to right) that satisfies the heap property. In a **min-heap**, every parent is less than or equal to its children, so the minimum is always at the root. In a **max-heap**, every parent is greater than or equal to its children. Stored in an array: for a node at index i (1-based), its parent is at i/2, left child at 2i, right child at 2i+1. This layout allows O(1) navigation and no pointers.\n\n**Operations:** Insert: add the new element at the end of the array (next free position in the complete tree), then "bubble up" by swapping with the parent while the parent is larger (min-heap) until the property is restored. O(log n). Extract-min: the minimum is at the root (index 1); swap it with the last element, remove the last, then "bubble down" the new root by swapping with the smaller child until the heap property holds. O(log n).\n\n**Use cases:** Priority queue (schedule by priority). Dijkstra: extract the node with smallest distance, relax edges; min-heap gives the next node in O(log n). Merge K sorted lists: put the first element of each list in a min-heap; pop the minimum, output it, push the next element from that list; repeat. Top K: keep a min-heap of size K; after processing all elements, the root is the K-th largest. Median: two heaps (max-heap for lower half, min-heap for upper half).\n\n**Libraries:** C++: priority_queue<T, vector<T>, greater<T>> for min-heap (default is max-heap). Python: heapq (min-heap only; negate for max-heap).\n\n**3. Explanation:**\n\nThe heap property ensures the minimum (or maximum) is at the root. Bubble up after insert and bubble down after extract maintain the property in O(log n) because the tree has O(log n) levels. For top-K with a min-heap of size K: you are effectively keeping the K largest elements; the smallest among those K is the K-th largest overall, and it sits at the root. For merge K lists, the heap always holds the current smallest unprocessed element from each list, so each pop gives the next smallest in the combined order.\n\n**4. Application:**\n\nDijkstra (shortest path: extract min distance, relax neighbors). Merge K sorted lists (one min-heap of size K). Top K elements (min-heap of size K). Find median from data stream (two heaps). Scheduling (priority queue). In interviews, state the complexity: insert O(log n), extract O(log n), and for top-K space O(K) and time O(n log K).\n\n**5. How to implement:**\n\n(1) C++ min-heap: priority_queue<int, vector<int>, greater<int>> pq; pq.push(x); pq.pop(); pq.top() returns the minimum. (2) Top-K: for each x in the array, pq.push(x); if pq.size() > K then pq.pop(). After the loop, pq.top() is the K-th largest. (3) Merge K lists: push (first value, list index) for each list. While heap not empty: pop the smallest (value, i); append value to result; if list i has a next node, push (next->val, i) and advance list i. (4) Dijkstra: initialize dist[s]=0, others infinity; push (0, s). While heap not empty: pop (d, u); if d > dist[u] continue (stale); for each neighbor (v, w): if dist[u]+w < dist[v], update dist[v] and push (dist[v], v). See code below.\n\n**6. Logic & how the code works:**\n\nTop-K with min-heap: You want the K-th largest. If you keep the K largest elements in a min-heap, the root is the smallest of those K, i.e. the K-th largest overall. When a new element arrives, you push it; if the heap size becomes K+1, you pop the minimum (which might be the one you just added or an older one)—either way you are left with the K largest. Merge K lists: The heap holds at most K elements (one per list). The smallest overall is the minimum of these, so you pop it, output it, and push the next element from that list. After N pops you have output all N elements in sorted order; each push/pop is O(log K), so total O(N log K).\n\n**7. Example problem & solution:**\n\nProblem: Kth Largest Element in an Array — Find the K-th largest element. LeetCode #215.\n\nSolution C++: Min-heap of size K. priority_queue<int, vector<int>, greater<int>> pq; for(int x : nums) { pq.push(x); if(pq.size()>k) pq.pop(); } return pq.top(); Logic: The heap keeps the K largest elements seen so far. The root is the minimum of those K, which is the K-th largest. Time O(n log K), space O(K). Alternative: quick select for O(n) expected time.\n\n**8. Additional information:**\n\nLeetCode: Kth Largest Element (#215), Merge K Sorted Lists (#23), Find Median from Data Stream. For Dijkstra, C++ priority_queue does not support decrease-key; use "lazy" deletion: push a new (dist, node) when you find a shorter path and ignore stale pops (when popped dist > current dist[node]).',
          codeExample:
            "// C++: Min-heap for Top-K\n// pq.top() = smallest in heap = K-th largest\npriority_queue<int, vector<int>, greater<int>> pq;\nfor (int x : nums) {\n  pq.push(x);\n  if ((int)pq.size() > k) pq.pop();\n}\nreturn pq.top();\n\n// Merge K sorted lists - heap of (value, list_idx)\npriority_queue<pair<int,int>, vector<pair<int,int>>, greater<>> pq;\nfor (int i = 0; i < k; i++) pq.push({lists[i]->val, i});\nwhile (!pq.empty()) {\n  auto [v, i] = pq.top(); pq.pop();\n  out->next = new ListNode(v); out = out->next;\n  if (lists[i]->next) {\n    lists[i] = lists[i]->next;\n    pq.push({lists[i]->val, i});\n  }\n}",
          codeLanguage: "cpp",
          imageUrl:
            "https://placehold.co/800x400/c2410c/white?text=Heaps+Priority+Queue",
        },
        {
          title: "Strings & Math",
          description:
            "KMP, Z-algorithm, Trie; GCD, LCM, modular arithmetic, combinatorics",
          order: 8,
          content:
            '**1. Learning flow:**\n\n(1) Read material so you know the string tools (KMP for pattern matching, Trie for prefix search and autocomplete) and the math tools (GCD, LCM, modular arithmetic, fast exponentiation)—these appear in both contests and interviews. (2) Implement GCD (Euclidean algorithm), LCM (a*b/gcd with overflow-safe form), and pow_mod (binary exponentiation) from the code so you can use them without thinking; trace one example by hand (e.g. gcd(48,18) or 3^13 mod 10). (3) Solve one Trie problem (e.g. Implement Trie or prefix search) so you practice building and querying the trie. (4) Try a problem using modular arithmetic (e.g. nCr mod m or count under modulo) so you see how to combine mod with factorials and inverses.\n\n**2. Material:**\n\n**Strings:** KMP (Knuth-Morris-Pratt) does pattern matching in O(n+m) by building a failure function that tells how much to shift the pattern when a mismatch occurs. Z-algorithm computes Z[i] = length of longest substring starting at i that matches the prefix of the string; used for pattern matching and border detection. Trie (prefix tree): a tree where each node has up to 26 (or 256) children, one per character; each path from the root spells a string. Used for storing a set of strings, prefix search ("all keys starting with \'pre\'"), and autocomplete. Insert: walk the path character by character, creating nodes as needed; mark the end of a word. Search: walk the path; if you reach the end and the node is marked, the word exists. Prefix search: walk to the prefix node, then DFS or BFS to collect all keys in that subtree.\n\n**Math:** GCD (greatest common divisor): Euclidean algorithm gcd(a,b) = gcd(b, a mod b) until b=0; then answer is a. LCM (least common multiple): a*b/gcd(a,b); to avoid overflow compute a/gcd(a,b)*b. Modular arithmetic: (a+b) mod m = ((a mod m)+(b mod m)) mod m; (a*b) mod m = ((a mod m)*(b mod m)) mod m. Use 1LL when multiplying to avoid int overflow (e.g. (r * 1LL * a) % m). Modular inverse: a^(-1) mod m satisfies a*x ≡ 1 (mod m); when m is prime, Fermat gives a^(-1) = a^(m-2) mod m. Fast exponentiation (binary): compute a^b mod m in O(log b) by writing b in binary: r=1, while b: if b odd then r=r*a mod m; a=a*a mod m; b=b/2. nCr mod m: precompute factorials and inverse factorials up to n, then nCr = fact[n] * inv_fact[r] * inv_fact[n-r] mod m.\n\n**3. Explanation:**\n\nGCD: The Euclidean step gcd(a,b)=gcd(b, a mod b) reduces the problem size; the remainder is at most half of b, so the algorithm runs in O(log min(a,b)). LCM: The product a*b counts every prime factor in both; dividing by GCD removes the overlap, so a*b/gcd is the smallest number divisible by both. Modular arithmetic keeps numbers in range [0, m-1] and (a*b) mod m = ((a mod m)*(b mod m)) mod m so you can reduce before multiplying. Fast pow: writing the exponent in binary, each bit corresponds to squaring (a -> a^2 -> a^4 -> ...); when the bit is 1 you multiply the current result by that power. Total multiplications O(log b).\n\n**4. Application:**\n\nStrings: pattern matching (KMP), autocomplete and prefix search (Trie), longest repeated substring (Z or suffix structures). Math: divisibility (GCD), combining periods (LCM), cryptography and hashing (modular arithmetic), combinatorics (nCr mod m), fast power in number theory. Interview tip: GCD and fast exponentiation are standard; have them ready. Trie for "design a structure that supports insert and search and prefix search."\n\n**5. How to implement:**\n\n(1) GCD: recursive int gcd(int a, int b) { return b ? gcd(b, a % b) : a; } or iterative while (b) { int t = b; b = a % b; a = t; } return a; (2) LCM: return a / gcd(a,b) * b; (order matters to avoid overflow). (3) pow_mod: r = 1; a %= m; while (b) { if (b & 1) r = (r * 1LL * a) % m; a = (a * 1LL * a) % m; b >>= 1; } return r; (4) Trie: struct Node { Node* next[26]; bool end; }; insert: walk and create; set end at last char. search: walk and check end. See code below.\n\n**6. Logic & how the code works:**\n\nGCD Euclidean: gcd(a,b) = gcd(b, a mod b). At each step the second argument decreases (a mod b < b), and we stop when b=0; then the first argument is the gcd. Example: gcd(48,18)=gcd(18,12)=gcd(12,6)=gcd(6,0)=6. LCM: a*b/gcd(a,b) gives the smallest positive integer divisible by both; writing a/gcd(a,b)*b avoids overflow. Fast pow: In the loop, we maintain the invariant that at the start of each iteration we are computing a^b * r mod m. When b is odd we multiply r by a (so r becomes r*a); then we square a (so a becomes a^2) and halve b (so b becomes (b-1)/2). So a^b * r = (a^2)^((b-1)/2) * (r*a), which is correct. When b is even we just square a and halve b. After O(log b) steps b becomes 0 and r is a^original_b mod m.\n\n**7. Example problem & solution:**\n\nProblem: Pow(x, n) — Compute x^n. n can be negative. LeetCode #50.\n\nSolution: If n < 0, set x = 1/x and n = -n so we compute (1/x)^(-n). Binary exponentiation: r=1; while (n) { if (n & 1) r *= x; x *= x; n >>= 1; } return r. Logic: Same as modular pow but without mod. Time O(log n), space O(1).\n\n**8. Additional information:**\n\nModular inverse: Fermat a^(m-2) when m is prime; extended Euclidean for general m. nCr mod m: precompute fact[0..n] and inv_fact (inv_fact[i] = fact[i]^(-1)); nCr = fact[n]*inv_fact[r]*inv_fact[n-r] mod m. LeetCode: Implement Trie (#208), Pow(x,n) (#50).',
          codeExample:
            "// C++: GCD Euclidean - recursive\nint gcd(int a, int b) { return b ? gcd(b, a % b) : a; }\n// LCM - be careful overflow: a/gcd*b\nint lcm(int a, int b) { return a / gcd(a, b) * b; }\n// Modular exponentiation - a^b mod m\nint pow_mod(int a, long long b, int m) {\n  int r = 1; a %= m;\n  while (b) {\n    if (b & 1) r = (r * 1LL * a) % m;\n    a = (a * 1LL * a) % m;\n    b >>= 1;\n  }\n  return r;\n}",
          codeLanguage: "cpp",
          imageUrl:
            "https://placehold.co/800x400/4f46e5/white?text=Strings+Math+Combinatorics",
        },
        {
          title: "Bit Manipulation",
          description:
            "XOR, shifts, masks; common interview tricks (single number, power of 2)",
          order: 9,
          content:
            '**1. Learning flow:**\n\n(1) Read material and XOR properties: a^a=0, a^0=a, and XOR is commutative and associative—so when every element appears twice except one, XORing all elements cancels the pairs and leaves the single one. (2) Implement single-number (XOR all) and power-of-2 check (n>0 && (n & (n-1))==0) from the code so you can recall them quickly in interviews. (3) Solve Single Number (LeetCode 136) and Power of Two (LeetCode 231) to reinforce the patterns. (4) Try one bitmask problem: enumerate all subsets with a loop over masks from 0 to 2^n-1 and check each bit with (mask>>i)&1, or use bitmask as state in DP (e.g. traveling salesman style).\n\n**2. Material:**\n\n**Bit operations:** AND (&): 1 only if both bits are 1. OR (|): 1 if either bit is 1. XOR (^): 1 if the bits differ. NOT (~): flip all bits. Left shift <<: multiply by 2 (e.g. 1<<i is 2^i). Right shift >>: integer divide by 2. **XOR properties:** a^a = 0 (same number cancels); a^0 = a (identity); XOR is commutative and associative, so order does not matter. **Power of 2:** A positive integer n is a power of 2 (1, 2, 4, 8, ...) iff it has exactly one bit set. In binary, n-1 flips the rightmost 1 and all bits to its right (e.g. 8=1000, 7=0111). So n & (n-1) clears the lowest set bit. If n is a power of 2, n has one bit so n & (n-1) = 0. **Common tricks:** Get the i-th bit (0-indexed from right): (n >> i) & 1. Set the i-th bit: n | (1 << i). Clear the i-th bit: n & ~(1 << i). Toggle: n ^ (1 << i). **Bitmask for subsets:** Represent a subset of {0, 1, ..., n-1} as an integer in [0, 2^n-1]: bit i is 1 iff element i is in the subset. Loop over all subsets: for (int mask = 0; mask < (1<<n); mask++). For each mask, iterate i and check (mask>>i)&1 to know if element i is in the subset. Used in DP (state = subset of visited nodes) and in brute-force over subsets.\n\n**3. Explanation:**\n\nXOR of the same number twice gives 0, so when you XOR all numbers in the array, every pair cancels and the only number that appears once remains. For power of 2, the only positive numbers with exactly one bit set are 1, 2, 4, 8, ...; (n & (n-1)) clears the lowest set bit, so the result is 0 iff there was only one bit. Bitmask enumeration: each number from 0 to 2^n-1 has a unique binary representation with n bits, and each bit pattern corresponds to one subset.\n\n**4. Application:**\n\nSingle number (one unique in pairs): XOR all. Swap without temp: a^=b; b^=a; a^=b (using a^a=0). Power-of-2 check: n>0 && (n&(n-1))==0. Subset enumeration: for (mask=0; mask<(1<<n); mask++) process the subset given by the bits. DP with state as bitmask: e.g. TSP (which cities visited), or "choose a subset that satisfies a condition." __builtin_popcount(n) (GCC) gives the number of set bits.\n\n**5. How to implement:**\n\n(1) Single number: int x = 0; for (int n : nums) x ^= n; return x; (2) Power of 2: return n > 0 && (n & (n-1)) == 0; (3) Enumerate subsets: for (int mask = 0; mask < (1<<n); mask++) { for (int i = 0; i < n; i++) if ((mask>>i)&1) /* element i in subset */ } (4) Set/clear/toggle bit: n | (1<<i), n & ~(1<<i), n ^ (1<<i). See code below.\n\n**6. Logic & how the code works:**\n\nSingle number XOR: Because XOR is commutative and associative, the expression nums[0]^nums[1]^...^nums[n-1] equals (pair1_a^pair1_b)^(pair2_a^pair2_b)^...^single. Each pair XORs to 0, so the total is 0^0^...^single = single. Example: [4,1,2,1,2] → 4^1^2^1^2 = 4^(1^1)^(2^2) = 4^0^0 = 4. Power of 2: In binary, 2^k is 1 followed by k zeros. For such n, n-1 is 0 followed by k ones. So n & (n-1) has no bit in common and equals 0. If n has more than one set bit, the lowest set bit is still cleared by n & (n-1), so the result is non-zero.\n\n**7. Example problem & solution:**\n\nProblem: Single Number — One number appears once, rest twice. Find the single number. LeetCode #136.\n\nSolution C++: int singleNumber(vector<int>& nums) { int x = 0; for (int n : nums) x ^= n; return x; } Logic: XOR all elements; pairs cancel (a^a=0), remainder is the single number. Time O(n), space O(1).\n\n**8. Additional information:**\n\nLeetCode: Single Number (#136), Power of Two (#231), Subsets (#78) with bitmask. __builtin_popcount(n), __builtin_ctz(n) (trailing zeros). For subset DP: state often (mask, i) or (mask) with transition adding one element.',
          codeExample:
            "// C++: Single number - XOR all; pairs cancel\nint singleNumber(vector<int>& nums) {\n  int x = 0;\n  for (int n : nums) x ^= n;\n  return x;\n}\n// Power of 2: only one bit set → n&(n-1)==0\nbool isPowerOfTwo(int n) {\n  return n > 0 && (n & (n-1)) == 0;\n}\n// Enumerate subsets with bitmask\nfor (int mask = 0; mask < (1 << n); mask++) {\n  for (int i = 0; i < n; i++)\n    if ((mask >> i) & 1) /* element i included */;\n}",
          codeLanguage: "cpp",
          imageUrl:
            "https://placehold.co/800x400/7c2d12/white?text=Bit+Manipulation",
        },
        {
          title: "Recursion & Backtracking",
          description:
            "Base case, recurrence; generate subsets, permutations, N-queens",
          order: 10,
          content:
            '**1. Learning flow:**\n\n(1) Read material and the subset template: at each index you have two choices (take or skip the element), and you recurse for both; after the "take" branch you must undo (pop) so the next choice sees the correct state. (2) Implement subset generation from the code: base case is when you have processed all elements (i == n), then you record the current path; otherwise recurse without the current element, then push the element, recurse, and pop. (3) Solve Subsets (LeetCode 78) and Permutations (LeetCode 46) so you see the difference: subsets use an index and take/skip; permutations use a position and try every unused element at that position. (4) Try Combination Sum (reuse elements, prune when sum > target) or N-Queens (place queen per row, check column and diagonal) to practice pruning and different state.\n\n**2. Material:**\n\n**Recursion:** A function that calls itself on a smaller instance of the problem. You need a **base case** (when to stop, e.g. index == n or empty list) and a **recurrence** (how to express the answer in terms of smaller subproblems). Example: Fibonacci, factorial, tree traversals.\n\n**Backtracking:** Systematic search over choices. At each step you have a set of choices; you try one (make the choice, update state), recurse to solve the rest, then **undo** the choice (restore state) so you can try the next option. The key is undoing: after the recursive call returns, the state must be as it was before the choice so the parent or the next iteration sees the correct state. Used for generating all configurations: subsets, permutations, combinations, N-queens, Sudoku, path finding.\n\n**Subsets:** For an array of n elements there are 2^n subsets (each element is either in or out). Template: maintain a path (current subset) and an index i (current element). Base case: i == n → add path to result. Recurse: (1) skip: recurse(i+1) without changing path; (2) take: path.push(nums[i]), recurse(i+1), path.pop(). The pop() is the undo. Complexity O(2^n) subsets, each of size up to n.\n\n**Permutations:** n! orderings. Template: maintain current permutation (or swap in place) and a position pos (how many elements are fixed). Base case: pos == n → record permutation. Recurse: for each index i from pos to n-1, swap(nums[pos], nums[i]), recurse(pos+1), swap back. Or use a path and a visited set: for each unvisited element, mark visited, add to path, recurse, unmark, remove from path. Complexity O(n!).\n\n**Pruning:** In combination sum or N-queens, you can stop exploring when the current path cannot lead to a solution (e.g. sum > target, or two queens attack). This reduces the search space.\n\n**3. Explanation:**\n\nThe base case is when there are no more decisions to make—you have built one valid configuration and you record it. The recurrence is "try every allowed choice here, recurse, undo." Backtracking is correct because every configuration is generated exactly once: the order of choices defines a path in the recursion tree, and undoing ensures that when you try the next choice you start from the same state. Subsets: 2^n leaves (one per subset). Permutations: n! leaves (one per permutation).\n\n**4. Application:**\n\nSubsets (LeetCode 78), permutations (46), combination sum (39, 40), N-Queens (51), word search (79), palindrome partitioning, path finding in a grid. Interview tip: state the complexity (2^n or n!) and mention pruning when applicable.\n\n**5. How to implement:**\n\n(1) Subsets: void bt(path, i, nums) { if (i == n) { ans.push_back(path); return; } bt(path, i+1, nums); path.push_back(nums[i]); bt(path, i+1, nums); path.pop_back(); }. Call bt(path, 0, nums). (2) Permutations (swap): void perm(nums, pos) { if (pos == n) { ans.push_back(nums); return; } for (int i = pos; i < n; i++) { swap(nums[pos], nums[i]); perm(nums, pos+1); swap(nums[pos], nums[i]); } }. (3) Always undo after the recursive call that made the choice. (4) Pruning: inside the loop, if (!isValid(path, choice)) continue; or if (sum + nums[i] > target) continue;. See code below.\n\n**6. Logic & how the code works:**\n\nSubsets: At index i we have two choices: skip nums[i] or take it. If we skip, we recurse with i+1 and the same path. If we take, we push nums[i], recurse with i+1, then pop so that when we return to this level the path no longer contains nums[i] and we can try the next choice (or return to the parent). The recursion tree has 2^n leaves, each corresponding to one subset. Permutations: At position pos we need to place one of the remaining elements. We try each element at position pos by swapping it to pos, recursing to fill position pos+1, then swapping back so the array is restored for the next try. Each leaf of the recursion tree is one permutation.\n\n**7. Example problem & solution:**\n\nProblem: Subsets — Generate all subsets of array. LeetCode #78.\n\nSolution C++: vector<vector<int>> ans; void bt(vector<int>& path, int i, vector<int>& nums) { if (i == (int)nums.size()) { ans.push_back(path); return; } bt(path, i+1, nums); path.push_back(nums[i]); bt(path, i+1, nums); path.pop_back(); } bt(path, 0, nums); return ans; Logic: Each element is either in or out. Skip branch and take branch (with undo). 2^n subsets. Time O(n*2^n), space O(n) for recursion and path.\n\n**8. Additional information:**\n\nLeetCode: Subsets (#78), Permutations (#46), Combination Sum (#39, #40), N-Queens (#51). Pruning: skip when sum > target or when placing a queen is invalid. Permutations: swap-in-place (no extra path) or path + visited array. Duplicate handling: sort and skip duplicate choices (e.g. if (i > pos && nums[i]==nums[i-1]) continue; when array is sorted).',
          codeExample:
            "// C++: Generate subsets - backtrack skip/take\nvector<vector<int>> ans;\nvoid bt(vector<int>& path, int i, vector<int>& nums) {\n  if (i == (int)nums.size()) {\n    ans.push_back(path);\n    return;\n  }\n  bt(path, i+1, nums);         // skip nums[i]\n  path.push_back(nums[i]);\n  bt(path, i+1, nums);         // take nums[i]\n  path.pop_back();            // undo\n}\n// Call: bt(path, 0, nums);\n\n// Permutations - swap in place\nvoid perm(vector<int>& nums, int pos) {\n  if (pos == (int)nums.size()) { record(nums); return; }\n  for (int i = pos; i < (int)nums.size(); i++) {\n    swap(nums[pos], nums[i]);\n    perm(nums, pos+1);\n    swap(nums[pos], nums[i]);  // undo\n  }\n}",
          codeLanguage: "cpp",
          imageUrl:
            "https://placehold.co/800x400/134e4a/white?text=Recursion+Backtracking",
        },
        {
          title: "Basic Geometry",
          description:
            "Points, lines, distance, area; 2D vectors and cross product",
          order: 11,
          content:
            "**1. Learning flow:**\n\n(1) Read material and the cross product: in 2D, cross(A,B,C) gives a signed value whose magnitude is twice the area of triangle ABC and whose sign tells you whether C is to the left of line AB (positive, counterclockwise), to the right (negative, clockwise), or on the line (zero, collinear). (2) Implement cross and dist from the code: cross = (b.x-a.x)*(c.y-a.y) - (b.y-a.y)*(c.x-a.x); dist = hypot(a.x-b.x, a.y-b.y). Use hypot to avoid overflow. (3) Solve point-in-triangle (all three cross products same sign) and distance point-to-line (cross magnitude / segment length) so you apply the formulas. (4) Try polygon area (sum of signed trapezoid areas) or convex hull (Graham scan or Andrew's) if you need more geometry.\n\n**2. Material:**\n\n**2D points:** Represent as (x, y). **Distance:** Euclidean distance between P and Q is sqrt((Q.x-P.x)² + (Q.y-P.y)²). In code use hypot(Q.x-P.x, Q.y-P.y) which is numerically safer than sqrt(dx*dx+dy*dy) for large values. **Cross product (2D):** For vectors AB and AC, the cross product (B-A)×(C-A) in 2D is a scalar: (B.x-A.x)*(C.y-A.y) - (B.y-A.y)*(C.x-A.x). Its magnitude is twice the signed area of triangle ABC. **Sign:** If the value is positive, C is to the left of line AB (counterclockwise from A to B to C). If negative, C is to the right (clockwise). If zero, A, B, C are collinear. So you can use cross to test orientation (ccw/cw), whether a point is left or right of a line, and whether three points are collinear. **Dot product:** A·B = A.x*B.x + A.y*B.y = |A||B|cos(θ). Used for projection and angle. **Triangle area:** |cross(A,B,C)|/2. **Polygon area:** For a polygon with vertices in order, area = (1/2)|sum over edges of (P[i].x * P[i+1].y - P[i+1].x * P[i].y)| (signed trapezoid formula). **Point in triangle:** P is inside triangle ABC iff P is on the same side of each edge as the opposite vertex: cross(P,A,B), cross(P,B,C), cross(P,C,A) all have the same sign (all positive or all negative).\n\n**3. Explanation:**\n\nThe cross product in 2D measures how much one vector \"rotates\" toward the other. Positive means counterclockwise, negative clockwise, zero collinear. So cross(A,B,C) tells you the orientation of the triangle. The magnitude is the area of the parallelogram spanned by (B-A) and (C-A), so half of it is the triangle area. For point-in-triangle, if P is inside, it lies on the same side of AB as C (cross(P,A,B) and cross(C,A,B) same sign), and similarly for the other edges. hypot avoids squaring large numbers that could overflow before the square root.\n\n**4. Application:**\n\nOrientation (are three points in ccw order?), collinearity (cross == 0), point in triangle (three crosses same sign), point in polygon (ray casting or winding), line segment intersection (both endpoints of one segment on opposite sides of the other line), polygon area, convex hull (Graham scan uses angle/cross to sort and then cross to decide which points to keep).\n\n**5. How to implement:**\n\n(1) Cross: double cross(Point a, Point b, Point c) { return (b.x-a.x)*(c.y-a.y) - (b.y-a.y)*(c.x-a.x); } (2) Distance: double dist(Point a, Point b) { return hypot(a.x-b.x, a.y-b.y); } (3) Point in triangle: compute c1 = cross(p,a,b), c2 = cross(p,b,c), c3 = cross(p,c,a); inside iff (c1>0 && c2>0 && c3>0) || (c1<0 && c2<0 && c3<0). (4) Collinear: cross(p0,p1,p2) == 0; use epsilon for floating point. See code below.\n\n**6. Logic & how the code works:**\n\nCross product 2D: cross(A,B,C) = (B.x-A.x)*(C.y-A.y) - (B.y-A.y)*(C.x-A.x). This equals the z-component of the 3D cross product of vectors (B-A,0) and (C-A,0). The value is positive when C is to the left of the directed line from A to B, negative when to the right, zero when on the line. Distance: hypot(dx, dy) computes sqrt(dx²+dy²) in a way that avoids overflow for large dx, dy. Point in triangle: For each edge, the cross product sign tells which side a point is on. If P is inside, it is on the same side of every edge as the interior (the opposite vertex). So all three cross products must have the same sign.\n\n**7. Example problem & solution:**\n\nProblem: Valid Boomerang — Three distinct points; do they form a triangle (not collinear)? LeetCode #1037.\n\nSolution: Compute cross(p0, p1, p2). If it is zero, the points are collinear (invalid boomerang). If non-zero, they are not collinear (valid). Return cross(p0,p1,p2) != 0. Use epsilon for floating point: fabs(cross(...)) > 1e-9. Time O(1).\n\n**8. Additional information:**\n\nFloating point: use const double eps = 1e-9; for equality use fabs(a-b) < eps. Convex hull: Graham scan (sort by angle, then scan with cross to remove right turns) or Andrew's monotone chain. LeetCode: Valid Boomerang (#1037), Convex Polygon.",
          codeExample:
            "// C++: Cross product 2D - signed area, orientation\n// >0: C to the left of AB (ccw), <0: cw, 0: collinear\ndouble cross(Point a, Point b, Point c) {\n  return (b.x - a.x) * (c.y - a.y) -\n         (b.y - a.y) * (c.x - a.x);\n}\n// Euclidean distance\ndouble dist(Point a, Point b) {\n  return hypot(a.x - b.x, a.y - b.y);\n}\n// Point P inside triangle ABC?\nbool inTriangle(Point p, Point a, Point b, Point c) {\n  double c1 = cross(p, a, b), c2 = cross(p, b, c), c3 = cross(p, c, a);\n  return (c1 > 0 && c2 > 0 && c3 > 0) || (c1 < 0 && c2 < 0 && c3 < 0);\n}",
          codeLanguage: "cpp",
          imageUrl:
            "https://placehold.co/800x400/0f766e/white?text=Geometry+Basics",
        },
      ],
    },
    {
      title: "React",
      slug: "react",
      description:
        "Build modern UIs with React: components and JSX, unidirectional data flow (props and state), hooks (useState, useEffect, useMemo, useCallback, useRef), Context API to avoid prop drilling, React Router for navigation and code splitting, Redux or Zustand when you need global state, and best practices for design, performance, accessibility, and testing. Before you start: complete How to Learn and have basic JavaScript (variables, functions, arrays, DOM). Competitive Programming and CS Theory are helpful but not required.",
      order: 2,
      published: true,
      items: [
        {
          title: "Fundamentals & JSX",
          description:
            "Components (functional and class), JSX syntax, composition",
          order: 0,
          content:
            '**1. Learning flow:**\n\n(1) Read material and explanation so you understand what a component is (a reusable piece of UI that receives props and returns JSX) and how JSX differs from HTML (className, camelCase events, { } for expressions). (2) Type the code below in a small React app (Create React App or Vite) so you see the component and JSX in action; do not just copy-paste—typing helps you remember. (3) Try composing Welcome with different props (e.g. name="Alice", name="Bob") and with children (e.g. <Welcome name="Ricky">Extra text</Welcome>) so you see how props and children make components flexible. (4) Build a simple card component (e.g. title and description as props) to practice structure and composition.\n\n**2. Material:**\n\nReact uses components: reusable pieces of UI. Functional components are functions that return JSX; class components use React.Component and render(). JSX looks like HTML but is JavaScript: className (not class), camelCase for events (onClick), { } for expressions. Compose by nesting and passing children.\n\n**3. Explanation:**\n\nComponents let you split the UI into small, reusable pieces. Each component receives props (read-only) and returns a tree of elements. JSX is syntactic sugar for React.createElement; a build tool (Babel, or the one bundled with Create React App/Vite) compiles JSX into browser-runnable JavaScript so the browser never sees raw JSX. Use className and style as object to avoid conflicts with JavaScript reserved words.\n\n**4. Application:**\n\nUse components for every repeated or logical piece of UI: buttons, cards, forms, layouts. Compose small components into pages. Pass data down via props and callbacks up for events.\n\n**5. How to implement:**\n\n(1) Create a function that takes props and returns JSX; use destructuring in the parameters (e.g. function Welcome({ name })) so you use name directly instead of props.name. (2) Use {expression} inside JSX for any dynamic content (variables, function calls, conditionals); everything inside curly braces is JavaScript. (3) Nest components by putting them inside other components (e.g. <Layout><Header /><Main /></Layout>); this is composition—small components build up to full pages. (4) Use className for CSS classes (not class, which is reserved in JS) and camelCase for event handlers (onClick, onChange). See code below.\n\n**6. Logic & how the code works:**\n\nThe Welcome function receives a props object; destructuring { name } takes the name property. JSX compiles to React.createElement calls; the browser renders the result. Using the component with different name values reuses the same logic with different output.\n\n**7. Example problem & solution:**\n\nProblem: Show a greeting that changes by user. Solution: Create a Welcome component that receives a name prop and renders <h1>Hello, {name}!</h1>. Use it as <Welcome name="Ricky" />. To support children: add {children} in the component body and use <Welcome name="Ricky">Extra text</Welcome>.\n\n**8. Additional information:** React docs: Introducing JSX, Components and Props. Use Create React App or Vite to scaffold. Prefer functional components and hooks over class components for new code. Common mistake: className vs class; use camelCase for event handlers (onClick). Key prop: always use unique key when mapping lists to avoid reconciliation bugs.',
          codeExample:
            '// Functional component with JSX\nfunction Welcome({ name }) {\n  return (\n    <div className="welcome">\n      <h1>Hello, {name}!</h1>\n    </div>\n  );\n}\n// Usage\n<Welcome name="Ricky" />',
          codeLanguage: "javascript",
          imageUrl:
            "https://placehold.co/800x400/0369a1/white?text=React+Components+%26+JSX",
        },
        {
          title: "Props & State",
          description:
            "Unidirectional data flow, lifting state, controlled components",
          order: 1,
          content:
            '**1. Learning flow:**\n\n(1) Read material and explanation so you understand the one-way data flow: data goes down via props, events go up via callbacks; state lives in one place (the component that "owns" it) and is updated only through setters. (2) Build the Counter from the code so you see useState(initial) and how clicking the button calls setCount to trigger a re-render. (3) Lift state: build two counters that share a total—put the two count values in the parent and pass them down plus the increment callbacks so you see how lifting keeps one source of truth. (4) Build a controlled input (value={text} and onChange that updates state) so the input is always driven by React state.\n\n**2. Material:**\n\nProps: read-only data from parent to child. Unidirectional: data down, events (callbacks) up. State: mutable data inside a component via useState. Lifting state: when two components need the same data, hold it in their common parent. Controlled components: input value = state, onChange updates state.\n\n**3. Explanation:**\n\nProps make components reusable; parent decides what the child shows. State is private to the component; updating it triggers re-render. Lifting state avoids duplication and keeps one source of truth. Controlled inputs tie the DOM value to React state so you can validate and transform.\n\n**4. Application:**\n\nUse props for configuration and display. Use state for user input, toggles, and anything that changes over time. Lift state when siblings need to share or when the parent needs to react to child data.\n\n**5. How to implement:**\n\n(1) Pass props from parent: <Child name={name} /> so the child receives name. (2) Receive in child: function Child({ name }) so you use name directly. (3) State: const [value, setValue] = useState(initial); call setValue(newValue) or setValue(prev => prev + 1) to update and trigger re-render. (4) Lifting state: hold the value in the parent and pass it down plus a callback, e.g. <Child count={count} onIncrement={() => setCount(c => c + 1)} /> so the child can request updates but the parent owns the state. (5) Controlled input: set value={text} and onChange={e => setText(e.target.value)} so the input always reflects state and every keystroke updates state. See code below.\n\n**6. Logic & how the code works:**\n\nuseState(initial) returns [value, setter]; when you call setCount, React re-renders the component with the new value. Lifting state to the parent means the parent holds the value and passes it down; children receive it via props and request updates via callbacks, keeping one source of truth.\n\n**7. Example problem & solution:**\n\nProblem: Two counters that show a shared total. Solution: Lift state to parent: const [a, setA] = useState(0); const [b, setB] = useState(0). Render <Counter value={a} onIncrement={() => setA(x=>x+1)} /> and same for b; display total as {a + b} in the parent.\n\n**8. Additional information:**\n\nReact docs: Lifting State Up, Forms. Never mutate props or state; always use setState with a new value or updater function. Use key when rendering lists so React can track identity.',
          codeExample:
            "// Props and state\nfunction Counter({ initialCount }) {\n  const [count, setCount] = useState(initialCount);\n  return (\n    <div>\n      <span>{count}</span>\n      <button onClick={() => setCount(c => c + 1)}>+1</button>\n    </div>\n  );\n}",
          codeLanguage: "javascript",
          imageUrl:
            "https://placehold.co/800x400/0d9488/white?text=Props+%26+State+Flow",
        },
        {
          title: "Hooks",
          description: "useState, useEffect, useMemo, useCallback, useRef",
          order: 2,
          content:
            "**1. Learning flow:**\n\n(1) Read material and when to use each hook—useState for local UI state, useEffect for side effects (fetch, subscription, DOM), useMemo for expensive derived values, useCallback for stable callbacks (e.g. passed to memoized children), useRef for DOM refs or values that don't trigger re-render. (2) Implement the fetch effect from the code with cleanup (cancelled flag) so you avoid setting state after unmount when the user navigates away quickly. (3) Use useMemo for an expensive filter or computation so it only runs when dependencies change; use useCallback for a handler that you pass to a child wrapped in React.memo so the child doesn't re-render unnecessarily. (4) Use useRef to hold a DOM element (e.g. inputRef) and call inputRef.current.focus() so you see how refs persist across renders without causing re-renders.\n\n**2. Material:**\n\nuseState(initial): [value, setter]; updates trigger re-render. useEffect(fn, deps): run side effects after render; [] = mount/unmount only, [x] = when x changes; return cleanup. useMemo(fn, deps): memoize value. useCallback(fn, deps): memoize callback. useRef(initial): mutable ref, no re-render; DOM nodes or value across renders.\n\n**3. Explanation:**\n\nEffects run after paint; cleanup runs before next effect or unmount. Always handle async cancellation in useEffect (e.g. cancelled flag) to avoid setting state after unmount. useMemo/useCallback keep referential equality so dependent components don't re-render unnecessarily.\n\n**4. Application:**\n\nuseState: any local UI state. useEffect: fetch, subscription, timer, DOM. useMemo: expensive derivation from props/state. useCallback: callbacks passed to memoized children or in deps. useRef: DOM reference, previous value, or mutable handle.\n\n**5. How to implement:**\n\n(1) Declare hooks at the top level only—never inside conditions or loops—so React can rely on the same order every render. (2) useEffect: put async logic (e.g. fetch) inside the effect; use a cancelled flag and return a cleanup that sets it so you don't set state after unmount; set deps = [url] (or [id]) so the effect re-runs when the dependency changes. (3) useMemo: const value = useMemo(() => compute(a, b), [a, b]) so the expensive computation runs only when a or b change. (4) useCallback: const fn = useCallback(() => doSomething(x), [x]) so the callback reference is stable and a memoized child won't re-render unnecessarily. See fetch example below.\n\n**6. Logic & how the code works:**\n\nuseEffect runs after the component paints. The dependency array [url] means the effect re-runs when url changes. The cleanup function (return () => { cancelled = true }) runs before the next effect or on unmount, so an in-flight fetch will not call setData after the component is gone, avoiding race conditions.\n\n**7. Example problem & solution:**\n\nProblem: Fetch data by id without race conditions. Solution: useEffect with [id]. Inside: let cancelled = false; fetch(...).then(r=>r.json()).then(data => { if (!cancelled) setData(data); }); return () => { cancelled = true };. If id changes before fetch resolves, cleanup sets cancelled so the old response is ignored.\n\n**8. Additional information:**\n\nReact docs: Rules of Hooks, useEffect. Don't put hooks in conditions or loops. For layout effects use useLayoutEffect. Custom hooks: extract logic into a function that calls other hooks.",
          codeExample:
            "// useEffect for data fetch\nuseEffect(() => {\n  let cancelled = false;\n  fetch(url).then(r => r.json()).then(data => {\n    if (!cancelled) setData(data);\n  });\n  return () => { cancelled = true; };\n}, [url]);",
          codeLanguage: "javascript",
          imageUrl:
            "https://placehold.co/800x400/7c3aed/white?text=React+Hooks",
        },
        {
          title: "Context API",
          description:
            "Share state across the tree without passing props through every level; createContext, Provider, useContext",
          order: 3,
          imageUrl:
            "https://placehold.co/800x400/0369a1/white?text=Context+API",
          content:
            "**1. Learning flow:**\n\n(1) Read material and when to use Context: when you need to pass data (e.g. theme, locale, current user) through many levels without every intermediate component accepting and forwarding the prop—Context lets any descendant read the value directly. (2) Implement the ThemeContext from the code: create a context with createContext, wrap the app (or a subtree) in a Provider that holds the theme state, and in a deep child use useContext to read the theme and apply it (e.g. to className). (3) Add a toggle (e.g. a button in the header) that calls setTheme; the Provider's value updates, so all consumers re-render with the new theme—no prop drilling. (4) Avoid putting data that changes very often (e.g. mouse position or every keystroke) in context, because every change will re-render all consumers; for that use local state or a store. Optionally split into ThemeContext (value) and SetThemeContext (setter) so components that only need to read the theme don't re-render when the setter reference is stable.\n\n**2. Material:**\n\n**What Context is:** Context lets you pass a value through the component tree without passing props at every level. You create a context with createContext(defaultValue). The default is used when a component calls useContext and there is no Provider above it (e.g. when you use the component in isolation in tests). You wrap a subtree in <MyContext.Provider value={someValue}>. Any descendant (no matter how deep) can call useContext(MyContext) to read the current value. When the Provider's value changes (by reference), all components that use that context re-render with the new value.\n\n**When to use it:** Theme (light/dark), locale (language), current user (after login), feature flags, or any \"global\" data that many components need to read. It is ideal for data that does not change on every user interaction—otherwise every consumer re-renders on each change. For data that changes frequently or that many components need to both read and update, consider state management (Zustand, Redux) or composition (lifting state, render props).\n\n**Prop drilling:** Without Context, you pass a prop from the root down through Header → Nav → Link → Icon. Every component in the chain must accept and forward the prop even if it does not use it. Context lets Icon (or any descendant) call useContext(ThemeContext) and get the theme without the middle components knowing about it.\n\n**Splitting context:** If you put both theme and setTheme in one context value object, that object is recreated every render (e.g. value={{ theme, setTheme }}), so all consumers re-render even if they only use setTheme (which is stable). You can split: one context for the value (theme) and one for the setter (setTheme). Components that only need to toggle pass setTheme from the second context and do not re-render when theme changes. Or memoize: value={useMemo(() => ({ theme, setTheme }), [theme])} so the reference only changes when theme changes.\n\n**3. Explanation:**\n\nContext is a subscription: when you call useContext(MyContext), React remembers that this component depends on that context. The Provider holds the current value; when the Provider re-renders with a new value (new reference), React schedules a re-render for all components that subscribed to that context. So the data flows from the Provider down to all consumers without going through props. The default value is only used when there is no Provider—useful for tests or when the component might be used outside the app tree.\n\n**4. Application:**\n\nTheme (light/dark) for the whole app. Locale for translations. Current user (id, name, role) after login. Feature flags. Avoid using Context for form state or high-frequency updates; use local state or a dedicated store.\n\n**5. How to implement:**\n\n(1) Create the context outside any component: const ThemeContext = createContext('light'); (so the default is 'light' when no Provider exists). (2) In the root (or a subtree where the value is known), hold state: const [theme, setTheme] = useState('light'); and wrap the tree: <ThemeContext.Provider value={theme}> ... </ThemeContext.Provider>. (3) In any descendant that needs the theme: const theme = useContext(ThemeContext); then use it (e.g. className={theme}). (4) To update from a child: pass setTheme in the Provider value (e.g. value={{ theme, setTheme }}) or in a separate context; the child calls setTheme('dark') and the Provider re-renders with the new theme, so all consumers see the update. (5) Optional: memoize the value with useMemo so the object reference does not change every render unless theme changes. See code below.\n\n**6. Logic & how the code works:**\n\nThe Provider component stores the value you pass (e.g. theme). When that value changes (because the parent re-rendered with a new state), React compares the new value to the previous one by reference. If the reference changed, every component that called useContext(ThemeContext) is marked as needing a re-render. On the next commit, those components re-render and receive the new value. So the flow is: user clicks toggle → setTheme('dark') in the Provider's parent → Provider re-renders with value=\"dark\" → all consumers re-render and useContext returns \"dark\". No prop drilling: the intermediate components do not need to know about theme at all.\n\n**7. Example problem & solution:**\n\nProblem: Theme (light/dark) must be available in header and footer without passing through the middle layout. Solution: Create ThemeContext with createContext('light'). In App, const [theme, setTheme] = useState('light'); wrap the app in <ThemeContext.Provider value={theme}>. In Header and Footer (and any deep child), const theme = useContext(ThemeContext); apply className={theme} or similar. Add a toggle button that calls setTheme(t => t === 'light' ? 'dark' : 'light'). No props need to be passed through the middle.\n\n**8. Additional information:**\n\nReact docs: Context. Memoize the value when it is an object: useMemo(() => ({ theme, setTheme }), [theme]). Splitting into value and setter contexts can reduce re-renders. For global app state (many keys, frequent updates) consider Zustand or Redux. Testing: wrap the component in a Provider with a test value.",
          codeExample:
            "const ThemeContext = createContext('light');\nfunction App() {\n  const [theme, setTheme] = useState('light');\n  return (\n    <ThemeContext.Provider value={theme}>\n      <Toolbar />\n    </ThemeContext.Provider>\n  );\n}\nfunction Button() {\n  const theme = useContext(ThemeContext);\n  return <button className={theme}>Click</button>;\n}",
          codeLanguage: "javascript",
        },
        {
          title: "React Router",
          description:
            "Declarative routing with Routes and Route; nested routes, URL params, and lazy loading for code splitting",
          order: 4,
          imageUrl:
            "https://placehold.co/800x400/0d9488/white?text=React+Router+%7C+Routes+%7C+Code+Splitting",
          content:
            '**1. Learning flow:**\n\n(1) Read material and the Route/Outlet model: Routes define path → component; nested routes mean the parent layout (e.g. sidebar) stays on screen and the child route renders inside an <Outlet />. (2) Build an app with Home, About, and a dynamic user/:id route from the code so you see how path matching and useParams work. (3) Add a nested layout: a parent Route with element that includes a sidebar or header and an <Outlet />; child routes (index for default, path "about", path "user/:id") render into the Outlet so the layout persists across navigation. (4) Add a lazy-loaded page with React.lazy(() => import(\'./Page\')) and wrap the route element in <Suspense fallback={<Spinner />}> so that page is loaded only when the user navigates to it, reducing initial bundle size.\n\n**2. Material:**\n\n**Setup:** Wrap the app in <BrowserRouter> (or HashRouter) so the rest of the tree can use routing. Define routes inside <Routes>: each <Route path="..." element={...} /> maps a URL path to a component. The router matches the current URL to the routes and renders the element of the first matching Route.\n\n**Navigation:** <Link to="/about"> renders an anchor that navigates to /about without a full page reload (client-side navigation). useNavigate() returns a function; call navigate(\'/path\') or navigate(-1) to go back. Programmatic navigation is useful after form submit or after checking auth.\n\n**URL params and query:** For a path like "user/:id", the segment after user/ is available as useParams().id. For query strings (?page=1&q=foo), use useSearchParams() to read and update the search params. useParams() and useSearchParams() are hooks that react to the current URL.\n\n**Nested routes:** A Route can have child Route elements. The parent\'s element should render an <Outlet /> where the matched child will be rendered. So the parent (e.g. a layout with sidebar) stays mounted and only the Outlet content changes when the URL changes. The full path of a nested route is the parent path + child path (e.g. "/" + "user/:id" = "/user/:id"). An index route (path index or index element) is the default child when the parent path is matched exactly.\n\n**Code splitting:** React.lazy(() => import(\'./Page\')) returns a component that loads the module when it is first rendered. Wrap it in <Suspense fallback={<Loading />}> so React shows the fallback until the lazy component is loaded. Use this for route-level splitting: lazy load each page component so the initial bundle is smaller.\n\n**3. Explanation:**\n\nThe router keeps the current URL in sync with the UI. When the URL changes (user clicks Link or calls navigate), the router finds the matching Route(s), renders the parent layout with the child rendered into Outlet, and any useParams/useSearchParams hooks in the tree return the new values so components can fetch data or render accordingly. Nested routes avoid duplicating the layout (sidebar, header) on every page. Lazy loading defers loading the component code until that route is visited.\n\n**4. Application:**\n\nMulti-page apps (Home, About, Contact). Dashboards: layout with sidebar, content area is <Outlet /> with child routes for each section. Detail pages: path "user/:id" or "product/:slug"; read id/slug with useParams and fetch data. Search or filters: useSearchParams for ?q=... or ?page=1. Protected routes: wrap in a component that checks auth and returns <Navigate to="/login" /> if not logged in. Redirects: <Navigate to="/new-path" replace />.\n\n**5. How to implement:**\n\n(1) Wrap app: <BrowserRouter><App /></BrowserRouter>. (2) Define routes: <Routes><Route path="/" element={<Layout />}> <Route index element={<Home />} /> <Route path="about" element={<About />} /> <Route path="user/:id" element={<User />} /> </Route></Routes>. (3) In Layout, render sidebar/header and <Outlet /> so the matched child appears there. (4) In User component: const { id } = useParams(); use id to fetch or display. (5) Links: <Link to="/about"> or <Link to={"/user/" + user.id}>; for relative paths inside a nested route use to="about" (relative to parent). (6) Programmatic: const navigate = useNavigate(); navigate(\'/path\'); or navigate(-1). (7) Lazy: const Page = React.lazy(() => import(\'./Page\')); then <Route path="page" element={<Suspense fallback={<Spinner />}><Page /></Suspense>} />. See code below.\n\n**6. Logic & how the code works:**\n\nWhen the URL is /user/42, the router matches the Route with path "user/:id". The parent Route (path "/") also matches, so React renders Layout (which includes the sidebar and <Outlet />), and inside the Outlet it renders the User component. User calls useParams() and gets { id: \'42\' }. So the component tree is App → Router → Layout (sidebar + Outlet) → User (with id=42). When the user clicks a Link to "/about", the URL changes, the same Layout stays (because path "/" still matches and Layout is the same Route), but the Outlet now renders About instead of User. useParams and useSearchParams read from the router\'s current match, so they update when the URL changes and cause a re-render with the new values.\n\n**7. Example problem & solution:**\n\nProblem: App with Home, About, and user detail page; layout with nav bar. Solution: <Routes><Route path="/" element={<Layout />}> <Route index element={<Home />} /> <Route path="about" element={<About />} /> <Route path="user/:id" element={<User />} /> </Route></Routes>. Layout has <nav> with <Link to="/">Home</Link>, <Link to="/about">About</Link>, and <Outlet />. User component: const { id } = useParams(); fetchUser(id) and display. From a list: <Link to={"/user/" + user.id}>{user.name}</Link>.\n\n**8. Additional information:**\n\nReact Router v6 docs. <Navigate to="/login" replace /> for redirects. Relative paths: to="about" from inside a route under "/" goes to "/about". Protected route: wrap in a component that checks auth and returns <Navigate to="/login" /> if not authenticated. useNavigate(-1) for back. Lazy load heavy pages to improve initial load.',
          codeExample:
            '// App with routes\n<Routes>\n  <Route path="/" element={<Layout />}>\n    <Route index element={<Home />} />\n    <Route path="about" element={<About />} />\n    <Route path="user/:id" element={<User />} />\n  </Route>\n</Routes>\n// In User component\nconst { id } = useParams();',
          codeLanguage: "javascript",
        },
        {
          title: "State Management",
          description:
            "When to use global state; Redux (actions, reducers, store) and Zustand for simpler global state",
          order: 5,
          imageUrl:
            "https://placehold.co/800x400/7c3aed/white?text=Redux+Zustand+%7C+When+Global+State",
          content:
            "**1. Learning flow:**\n\n(1) Read material and when to use global state: when many components across the tree need to read or update the same data (e.g. cart, current user, sidebar open) and passing props or Context would be cumbersome or cause unnecessary re-renders. (2) Implement the Zustand cart from the code: create a store with create((set) => ({ items: [], add: (item) => set(s => ({ items: [...s.items, item] })) })), then in the header use useCart(s => s.items) to show the count and in a product page use useCart().add(product) to add to cart—no props or Context needed. (3) Read and update the cart from both the header (display only) and a product page (add/remove) so you see how any component can subscribe and update. (4) Optionally try Redux Toolkit (createSlice, configureStore, Provider, useSelector, useDispatch) so you know the pattern for teams that use Redux; Zustand is simpler for small or medium apps.\n\n**2. Material:**\n\n**When to use global state:** Use when (a) many components in different parts of the tree need the same data, (b) prop drilling would require passing through many levels, or (c) the data is truly app-wide (user session, cart, theme, sidebar state). Prefer local state (useState) when only one component or a small subtree needs it. Prefer Context when the data is read-heavy and changes infrequently (theme, locale). Use global state (Zustand, Redux) when many components need to read and update the same data and you want a single source of truth outside the component tree.\n\n**Zustand:** A small library that lets you create a store with create((set) => ({ state, actions })). set is a function that updates the store (you pass a new state or a function (state) => newState). The return value of create() is a hook (e.g. useCart). Calling useCart() in a component subscribes it to the store: when the store updates, the component re-renders. You can select a slice: useCart(s => s.items) so the component only re-renders when items change. No Provider is needed; the store lives in a module. Actions can call set to update state; they can be used from anywhere (useCart.getState().add(item) or useCart(s => s.add)()). Persist middleware can sync the store to localStorage.\n\n**Redux:** Single store; you dispatch actions (plain objects) and the store is updated by pure reducers (state, action) => newState. Redux Toolkit provides createSlice (reducers + actions), configureStore, and createAsyncThunk for async logic. You wrap the app in <Provider store={store}> and use useSelector(selector) and useDispatch() in components. DevTools support time-travel and action logging. More boilerplate than Zustand but familiar in large teams.\n\n**3. Explanation:**\n\nGlobal state lives outside the React tree. When a component calls useCart(), it subscribes to the store; when the store updates (e.g. add() calls set()), Zustand notifies all subscribed components and they re-render with the new state. Selecting a slice (e.g. s => s.items) means the component only re-renders when that slice changes (shallow comparison). Redux works similarly: dispatch updates the store, and useSelector causes a re-render when the selected value changes. Both avoid prop drilling and keep state in one place.\n\n**4. Application:**\n\nShopping cart (header shows count, product pages add/remove). User session (name, role) after login. App-wide UI (sidebar open/closed, modal state). Cached API data shared across pages. Use local state for form inputs and component-local UI; use global state for what truly needs to be shared.\n\n**5. How to implement:**\n\n(1) Zustand: Create store with create((set) => ({ items: [], add: (item) => set(state => ({ items: [...state.items, item] })), remove: (id) => set(state => ({ items: state.items.filter(x => x.id !== id) })) })). (2) In components: const items = useCart(s => s.items); const add = useCart(s => s.add); then call add(product). (3) Optional selector: useCart(s => s.items.length) so the component only re-renders when the length changes. (4) Redux Toolkit: createSlice({ name: 'cart', initialState: { items: [] }, reducers: { add: (state, action) => { state.items.push(action.payload); } } }); configureStore({ reducer: { cart: cartSlice.reducer } }); wrap in Provider; in component useSelector(state => state.cart.items), useDispatch() to dispatch cartSlice.actions.add(product). See Zustand code below.\n\n**6. Logic & how the code works:**\n\nZustand's create() builds a store object and a hook. The hook uses React's useState/useEffect under the hood to subscribe to the store: when you call set(newState), the store updates and every component that called the hook re-renders (unless they use a selector that returns the same value as before). So add(item) calls set(s => ({ items: [...s.items, item] })); the store's items array is replaced; components that selected items (or items.length) get the new reference and re-render. No Provider is needed because the store is a module-level singleton.\n\n**7. Example problem & solution:**\n\nProblem: Cart visible in header (item count) and editable from product pages. Solution: Zustand store with items: [], add(item), remove(id). Header: const count = useCart(s => s.items.length); display count. Product page: const add = useCart(s => s.add); on the Add-to-cart button click call add(product). No props or Context; both read from and update the same store.\n\n**8. Additional information:**\n\nRedux Toolkit: createSlice, createAsyncThunk, configureStore. Zustand: persist middleware for localStorage; useCart.persist.rehydrate() if needed. Only put in global state what truly needs to be global; keep form state and local UI in useState. For very large apps or strict predictability, Redux and DevTools are valuable.",
          codeExample:
            "// Zustand example\nconst useCart = create((set) => ({\n  items: [],\n  add: (item) => set((s) => ({ items: [...s.items, item] })),\n}));\nfunction Cart() {\n  const { items, add } = useCart();\n  return <div>{items.length} items</div>;\n}",
          codeLanguage: "javascript",
        },
        {
          title: "Best Practices",
          description:
            "Component design (small, single responsibility), performance (memo, avoid inline objects), accessibility, and testing",
          order: 6,
          imageUrl:
            "https://placehold.co/800x400/059669/white?text=Component+Design+%26+Testing",
          content:
            "**1. Learning flow:**\n\n(1) Read material so you have a checklist: component design (one responsibility, composition, clear names), performance (avoid inline objects/functions that break memo, use memo/useMemo/useCallback where it matters), accessibility (semantic HTML, ARIA, keyboard, contrast), and testing (React Testing Library by role and label). (2) Refactor one large component into smaller ones: extract a list item, a form field group, or a card so each piece has one job and can be tested or reused. (3) Fix one performance pitfall: e.g. pass a stable style object (defined outside JSX or in useMemo) or a callback wrapped in useCallback to a memoized child so it does not re-render on every parent render. (4) Add one test with React Testing Library (e.g. getByRole('button', { name: /submit/i }), fireEvent.click, expect) and run an a11y check (e.g. eslint-plugin-jsx-a11y or axe) so you see how tests and accessibility fit in.\n\n**2. Material:**\n\n**Component design:** One component should have one clear responsibility (e.g. a Button, a UserCard, a FormField). Prefer composition (passing children or render props) over long prop lists. Name components by what they render (UserAvatar, not DataDisplay). Keep components small enough to understand at a glance; if a component is very long, split it into smaller pieces. This makes testing and reuse easier and keeps the tree readable.\n\n**Performance:** React re-renders a component when its state or props change. If you pass an inline object or function in JSX (e.g. style={{ color: 'red' }} or onClick={() => doSomething(id)}), a new reference is created on every render, so a child wrapped in React.memo will still re-render because the prop \"changed\" by reference. Fix: define the object or function outside the component, or wrap in useMemo/useCallback with the right dependencies. Use React.memo for list items or heavy components that receive stable props. Profile first (React DevTools Profiler) before optimizing; focus on components that render often or do expensive work.\n\n**Accessibility (a11y):** Use semantic HTML (button, nav, main, header, footer) so screen readers and keyboard users can navigate. Add aria-label for icon-only buttons or when the visible text is not enough. Ensure keyboard navigation works (tab order, Enter/Space to activate). Check color contrast (WCAG). Forms: associate labels with inputs (htmlFor and id), and show validation errors in a way that screen readers announce. Tools: eslint-plugin-jsx-a11y, axe DevTools.\n\n**Testing:** React Testing Library encourages testing behavior (what the user sees and does) rather than implementation. Query by role (getByRole('button')), label (getByLabelText('Email')), or text. Fire events (click, change), then assert on the outcome (text visible, callback called). Avoid testing state or internal functions; test the result. Use unit tests for pure logic; integration tests for components with hooks or context; e2e (Playwright, Cypress) for critical user flows.\n\n**3. Explanation:**\n\nSmall, single-responsibility components are easier to reason about and test. Inline objects/functions in JSX break referential equality: React.memo and useMemo/useCallback rely on comparing previous and next props or dependencies; when you pass a new object or function every time, the comparison fails and the component re-renders or the memoized value is recomputed. Semantic HTML and ARIA give structure and hints to assistive technologies; keyboard and contrast ensure the app is usable without a mouse and for low vision.\n\n**4. Application:**\n\nEvery production app: clear component structure, acceptable performance (no obvious jank), accessible forms and navigation, and tests for critical paths (login, checkout, main flows). Apply design and performance as you build; add a11y and tests before release or in a dedicated pass.\n\n**5. How to implement:**\n\n(1) Design: Extract subcomponents (e.g. ListItem from List); pass children or render props for flexibility; name by what is rendered. (2) Performance: Move inline objects out of JSX (const style = { color: 'red' }; or useMemo) and inline callbacks to useCallback (e.g. const onItemClick = useCallback((id) => { ... }, [])). Wrap expensive list items in React.memo. (3) A11y: Use <button> for actions, <nav> for navigation, <main> for main content; add aria-label on icon buttons; ensure focus order and contrast. (4) Testing: Import { render, screen, fireEvent } from '@testing-library/react'; render(<App />); const btn = screen.getByRole('button', { name: /submit/i }); fireEvent.click(btn); expect(screen.getByText('Success')).toBeInTheDocument();. See code below.\n\n**6. Logic & how the code works:**\n\nWhen the parent re-renders, it may pass new prop references (e.g. style={{ color: 'red' }} creates a new object each time). React.memo does a shallow comparison of props; if any prop reference changed, the child re-renders. So inline objects/functions defeat memo. useCallback(fn, deps) returns the same function reference until deps change; useMemo(() => value, deps) returns the same value reference until deps change. Passing those to a memoized child keeps props stable and allows the child to skip re-renders. Semantic HTML is parsed by the browser and exposed to the accessibility tree; screen readers use it to announce structure and content. getByRole and getByLabelText in Testing Library query that tree, so your tests align with how assistive tech and users see the page.\n\n**7. Example problem & solution:**\n\nProblem: List of 100 items re-renders entirely when parent state changes. Solution: Wrap the list item component in React.memo so it only re-renders when its props (e.g. item, onSelect) change. Ensure onSelect is stable: in the parent use useCallback for the handler (e.g. const onSelect = useCallback((id) => setSelected(id), [])). Avoid passing inline objects (e.g. pass item.id and item.name instead of style={{ fontWeight: 'bold' }} or use useMemo for the style). Then only the item that actually changed (if any) re-renders.\n\n**8. Additional information:**\n\nReact DevTools Profiler: record a session and see which components re-rendered and why. eslint-plugin-jsx-a11y for a11y rules in JSX. React Testing Library: query by role, label, or text; avoid getByTestId for user-facing behavior. Use data-testid only when necessary. For e2e use Playwright or Cypress.",
          codeExample:
            "// Avoid: inline object causes re-render every time\n<Child style={{ color: 'red' }} />\n// Prefer: stable reference\nconst style = { color: 'red' };\n<Child style={style} />\n// Or useMemo if style depends on state",
          codeLanguage: "javascript",
        },
      ],
    },
    {
      title: "Node.js",
      slug: "nodejs",
      description:
        "Backend with Node.js: event loop and non-blocking I/O, callbacks and Promises and async/await, Express for routing and middleware, REST API design and status codes, JWT and sessions and CORS, file streams and uploads, and deployment with PM2 and environment variables. Before you start: basic JavaScript and HTTP (what is a request/response). Database & SQL and Computer Networks help for the full picture.",
      order: 3,
      published: true,
      items: [
        {
          title: "Event Loop & Async",
          description: "Callback, Promise, async/await; non-blocking I/O",
          order: 0,
          content:
            "**1. Learning flow:**\n\n(1) Read the material and the explanation of the event loop below so you understand how Node.js handles many concurrent operations on a single thread: when you start an I/O operation (e.g. fetch, file read), the runtime hands it off and does not block; when the operation completes, a callback or Promise resolution is scheduled so the thread can run other code in between. (2) Implement the fetchUser example from the code: type it yourself (do not just copy-paste), then call it with try/catch so you see how await returns the value or throws and how errors are caught in one place. (3) Convert a callback-based API (e.g. fs.readFile with a callback) to Promise/async using util.promisify or fs.promises so you can use await instead of nested callbacks. (4) Chain two async operations (e.g. fetch user then fetch user's orders) using sequential await calls so you see how async/await makes async code read like synchronous code.\n\n**2. Material:**\n\nNode.js runs JavaScript on a single thread. To handle many concurrent operations (file reads, HTTP requests, database queries) without blocking, it uses an event loop and non-blocking I/O: when you start an I/O operation, the runtime hands it off to the operating system or a thread pool and does not wait; when the operation completes, a callback (or a Promise resolution) is scheduled to run. That way one thread can serve many requests: while one request is waiting for the network, the thread can run code for another request.\n\n**Callbacks:** The traditional pattern is to pass a function that will be called when the async operation finishes. For example, fs.readFile(path, (err, data) => { ... }). The problem with callbacks is nesting: when you chain several async steps, you get deeply nested \"callback hell.\" Error handling also becomes scattered (check err in every callback).\n\n**Promises:** A Promise represents a value that will be available (or an error) in the future. You create a Promise with new Promise((resolve, reject) => { ... }) or get one from APIs like fetch() or fs.promises.readFile(). You chain with .then(value => ...) and .catch(err => ...). Once a Promise is settled (fulfilled or rejected), it does not change. Chaining .then() returns a new Promise, so you can flatten async steps instead of nesting callbacks.\n\n**async/await:** An async function always returns a Promise. Inside it, await somePromise pauses the function until the Promise settles; if it fulfills, await returns the value; if it rejects, it throws so you can catch it with try/catch. This makes async code look like synchronous code: you write sequential steps and handle errors in one place. Under the hood, await is syntactic sugar over .then(): the engine suspends the function and resumes it when the Promise settles.\n\n**3. Explanation:**\n\nThe event loop continuously checks: are there pending timers? I/O callbacks? setImmediate? It runs one phase at a time, so your JavaScript runs in a single thread. When you await fetch(), the function is suspended and the thread is free to run other code (e.g. handling another request); when the fetch completes, your function is resumed with the result. That is why Node can handle many concurrent connections with one thread. async/await does not change this; it only makes the code easier to read and maintain. You must always handle errors: either try/catch around await or .catch() on the returned Promise, and in Express pass errors to next(err) so your error middleware can respond.\n\n**4. Application:**\n\nFile read/write, HTTP requests, DB queries, timers. Use async/await in Express route handlers (or wrap in a helper that forwards errors to next(err)).\n\n**5. How to implement:**\n\n(1) Declare async functions for any handler that uses await: e.g. async function fetchUser(id) { ... } or app.get('/user/:id', async (req, res, next) => { ... }). (2) Use await for every Promise so you get the value (or throw) and the code reads sequentially: const data = await fetch(url).then(r => r.json()); or const data = await readFile(path, 'utf-8');. (3) Wrap await in try/catch so you handle errors: try { const user = await fetchUser(id); res.json(user); } catch (e) { next(e); }. In Express, pass errors to next(err) so your error middleware can respond. (4) In Node for callback-based APIs use the promise version (fs.promises.readFile) or util.promisify(fs.readFile) so you can await them. (5) Never forget await: if you write const user = fetchUser(id) you get a Promise, not the user; and errors will not be caught by the surrounding try/catch. See code below.\n\n**6. Logic & how the code works:**\n\nWhen you call async function fetchUser(id) and inside it await fetch(url), the following happens. (1) fetch(url) starts an HTTP request and returns a Promise. (2) await sees that the Promise is not yet settled, so it suspends the fetchUser function and returns control to the caller (the caller gets a Promise that will settle when fetchUser finishes). (3) The single JavaScript thread is now free; the event loop can run other code (e.g. another request handler). (4) When the HTTP response arrives, the Promise from fetch is fulfilled; the engine schedules the resumption of fetchUser. (5) When the event loop runs that scheduled work, fetchUser continues from the await: the expression evaluates to the response object, and the next line (if (!res.ok) throw ...) runs. So the \"pause\" of await is cooperative: the thread is not blocked waiting; it does other work until the I/O completes. That is how one thread handles many concurrent I/O operations. try/catch around await works because a rejected Promise causes await to throw; the catch block runs and you can log, respond with 500, or call next(err) in Express. If you forget await, you get a Promise object instead of the value, and errors are not caught by that try/catch—a common bug.\n\n**7. Example problem & solution:**\n\nProblem: Fetch user by id and return name; handle not found. Solution: async function fetchUser(id) { const res = await fetch(url); if (!res.ok) throw new Error('Not found'); return res.json(); }. Call with try { const user = await fetchUser(1); console.log(user.name); } catch (err) { console.error(err); }.\n\n**8. Additional information:** Node docs: Event loop, async. In Express, use async (req, res, next) => { try { ... } catch (e) { next(e); } } so errors go to error middleware. Avoid blocking the event loop with CPU-heavy work; use worker threads if needed. Common mistake: Forgetting to await Promise; use try/catch for async errors. Unhandled rejection: add process.on('unhandledRejection', ...) for debugging.",
          codeExample:
            "// async/await example\nasync function fetchUser(id) {\n  const res = await fetch('/api/users/' + id);\n  if (!res.ok) throw new Error('Not found');\n  return res.json();\n}\n// Usage\ntry {\n  const user = await fetchUser(1);\n  console.log(user.name);\n} catch (err) {\n  console.error(err);\n}",
          codeLanguage: "javascript",
          imageUrl:
            "https://placehold.co/800x400/059669/white?text=Event+Loop+%26+Async",
        },
        {
          title: "Express.js",
          description:
            "Routing by method and path, middleware chain, error-handling middleware, req and res objects",
          order: 1,
          imageUrl:
            "https://placehold.co/800x400/059669/white?text=Express+Routes+Middleware+Error+Handling",
          content:
            "**1. Learning flow:**\n\n(1) Read the material and the explanation of middleware order below so you understand that Express processes each request through a pipeline: middleware and routes run in the order they are registered, and each middleware must call next() or send a response so the request does not hang. (2) Build the small API from the code: create an Express app, add express.json(), define GET /users/:id that reads req.params.id and returns a JSON object, and register an error-handling middleware (four arguments) last so any next(err) is caught and returns a 500 with a message. (3) Add GET and POST /items (e.g. an in-memory array): GET returns the list, POST pushes req.body to the array and returns 201; add a logger middleware that runs first and logs req.method and req.url then calls next(). (4) Ensure express.json() is registered before any route that reads req.body so the body is parsed; test with a POST request and confirm req.body contains the parsed JSON.\n\n**2. Material:**\n\nExpress is a minimal web framework for Node.js. You define routes (HTTP method + URL path) and middleware (functions that run in sequence for each request). The same request and response objects (req, res) flow through the pipeline, so middleware can add properties (e.g. req.user) or short-circuit by sending a response.\n\n**Routes:** You register handlers with app.get(path, handler), app.post(path, handler), app.put(path, handler), app.delete(path, handler). The path can be static (e.g. '/users') or include parameters (e.g. '/users/:id'). The first route that matches the request method and path runs; you can pass multiple handlers (e.g. auth then handler). req.params holds path parameters (e.g. req.params.id for '/users/:id'). req.query holds query string values (e.g. ?page=1 gives req.query.page). req.body holds the request body, but only after a body-parsing middleware like express.json() has run—without it, req.body is undefined.\n\n**Middleware:** A middleware function has the signature (req, res, next). It can read and modify req and res, and it must either call next() to pass control to the next middleware/route or end the request with res.send(), res.json(), res.status().send(), etc. If it does neither, the request hangs. Middleware is registered with app.use(fn) or app.use(path, fn); order matters: they run in the order they are added. Common middleware: express.json() to parse JSON bodies; express.urlencoded({ extended: true }) for form data; cors() for CORS headers; a logger that runs first; auth that runs before protected routes. Routers (express.Router()) are middleware that group routes under a path (e.g. app.use('/api/users', userRouter)).\n\n**Error-handling middleware:** A function with four arguments (err, req, res, next) is treated as error middleware. You register it last (after all routes and other middleware). When any handler calls next(err) or throws, Express skips to the next error middleware. There you can log the error and send a consistent error response (e.g. res.status(500).json({ error: err.message })). For async route handlers, you must pass errors to next (e.g. try { await ... } catch (e) { next(e); }) so they reach the error middleware.\n\n**3. Explanation:**\n\nEach request is processed by the middleware and route stack in order. If express.json() is not applied first, routes that read req.body will get undefined. Auth middleware that calls next() only when the user is valid should be placed before the routes it protects. The error middleware is the safety net: instead of crashing the process or leaving the client without a response, you centralize error handling and return a proper HTTP status and body.\n\n**4. Application:**\n\nREST APIs, static file serving, auth checks, logging, validation. Use router for modular routes (e.g. app.use('/api/users', userRouter)).\n\n**5. How to implement:**\n\napp.use(express.json()) first. Define routes with app.METHOD(path, handler). In handler: read req.params.id, req.query, req.body; send with res.json() or res.status(). Register error handler last with 4 args. See code below.\n\n**6. Logic & how the code works:**\n\nWhen a request comes in (e.g. GET /users/42), Express walks the list of registered middleware and routes in order. First, app.use(express.json()) runs: it reads the body stream, parses JSON if the Content-Type is application/json, and assigns the result to req.body; then it calls next(). No response is sent yet. Next, any other app.use() middleware runs (e.g. a logger that does console.log(req.method, req.url) and next()). Then Express checks route handlers: app.get('/users/:id', ...) matches method GET and path /users/42, so that handler runs. Inside it, req.params.id is '42' and req.body would have been set by the JSON middleware if the request had a body. The handler calls res.json({ id, name: 'User' }), which sets the status (default 200), sets Content-Type, and sends the body. The response is finished, so no further middleware runs for this request. If the handler had called next(err) instead (e.g. after a failed DB lookup), Express would skip to the first four-argument middleware (err, req, res, next), which can send a 500 or 404 response. So the pipeline is linear: order of registration determines order of execution, and either a handler sends a response or passes control with next(); error middleware catches next(err) and sends an error response.\n\n**7. Example problem & solution:**\n\nProblem: Small API with GET and POST /items and a logger. Solution: app.use((req, res, next) => { console.log(req.method, req.url); next(); }); app.get('/items', (req, res) => res.json(items)); app.post('/items', (req, res) => { items.push(req.body); res.status(201).json(req.body); }); Add error middleware at the end.\n\n**8. Additional information:**\n\nExpress docs: Routing, Middleware. Use router.get/post etc. and app.use('/prefix', router) to group routes. Always call next() or send a response to avoid hanging requests.",
          codeExample:
            "const express = require('express');\nconst app = express();\napp.use(express.json());\napp.get('/users/:id', (req, res) => {\n  const id = req.params.id;\n  res.json({ id, name: 'User' });\n});\napp.use((err, req, res, next) => {\n  res.status(500).json({ error: err.message });\n});\napp.listen(3000);",
          codeLanguage: "javascript",
        },
        {
          title: "REST API Design",
          description:
            "Resources as nouns in URL, HTTP methods as actions, status codes (2xx, 4xx, 5xx), versioning and idempotency",
          order: 2,
          imageUrl:
            "https://placehold.co/800x400/0d9488/white?text=REST+GET+POST+PUT+DELETE+%7C+Status+Codes",
          content:
            "**1. Learning flow:**\n\n(1) Read the material and the status code summary below so you know when to return 200, 201, 204, 400, 401, 403, 404, and 500—clients and caches rely on these codes to decide whether to retry, show an error, or update the UI. (2) Implement a small users API from the code: GET /users (list, 200), POST /users (create, validate input, return 201 with the new user and optionally a Location header), GET /users/:id (find by id, 404 if not found or 200 with user), PUT /users/:id (update, 404 or 200) so every handler uses the correct status and a consistent JSON shape. (3) Add 201 Created for POST with res.status(201).json({ data: newUser }) and optionally res.set('Location', '/users/' + newUser.id); add 400 Bad Request for validation errors with a list of field errors so the client can show field-level messages. (4) Use a consistent response shape for success ({ data: ... }) and errors ({ error: 'message', fields?: [...] }) so client code can handle all responses in one place.\n\n**2. Material:**\n\nREST is a style for designing HTTP APIs: you model the system as resources (nouns) and use HTTP methods to act on them. URLs identify resources (e.g. /users for the collection, /users/1 for one user). Clients and caches rely on methods and status codes to understand what happened.\n\n**Resources and methods:** Use nouns in the path: /users, /orders, /products/123. GET retrieves a resource (or list); it should not change server state and is cacheable. POST creates a new resource (e.g. POST /users with body); the server assigns an id and returns it. PUT replaces a resource at a known URL (e.g. PUT /users/1); it is idempotent—calling it multiple times with the same body has the same effect as once. PATCH applies a partial update (e.g. only change the email field). DELETE removes the resource. Idempotent methods (GET, PUT, DELETE) are safe for retries; POST is not idempotent (two POSTs may create two resources).\n\n**Status codes:** 2xx means success. 200 OK: request succeeded (e.g. GET or PUT). 201 Created: resource was created; include a Location header with the URL of the new resource (e.g. Location: /users/42). 204 No Content: success with no body (e.g. after DELETE). 4xx means client error. 400 Bad Request: invalid input (validation failed). 401 Unauthorized: authentication required or failed. 403 Forbidden: authenticated but not allowed. 404 Not Found: no such resource. 5xx means server error (e.g. 500 Internal Server Error when something unexpected failed). Using the right code helps clients show the right message and retry only when appropriate.\n\n**Response shape:** A consistent envelope (e.g. { data: ... } for success and { error: 'message', code?: 'VALIDATION_ERROR' } for errors) makes client code simpler: one place to check for data vs error, one place to read error messages. Optional meta (e.g. pagination: total, page, limit) keeps the payload predictable.\n\n**Versioning and idempotency:** When you need to change the API without breaking existing clients, use a version prefix (e.g. /v1/users) or an Accept header. For POST or PATCH, clients can send an Idempotency-Key header so duplicate requests are treated as one.\n\n**3. Explanation:**\n\nCorrect status codes let clients and proxies behave correctly (e.g. retry on 5xx but not on 4xx). 201 with Location tells the client where the new resource lives. A consistent response shape (data vs error) simplifies parsing and error handling. Idempotency and versioning support evolution and reliability.\n\n**4. Application:**\n\nAny HTTP API: CRUD resources, pagination (meta), filtering via query params. Use versioning when you need backward compatibility.\n\n**5. How to implement:**\n\nDesign URLs and methods first. In handlers: validate input; return 400 with error list if invalid. For create: 201 and res.set('Location', ...). For not found: 404. Use res.status(code).json({ data } or { error }). See code below.\n\n**6. Logic & how the code works:**\n\nIn your handler, after validating input or loading the resource, you choose the status and body. For create: const user = await createUser(req.body); res.status(201).set('Location', '/users/' + user.id).json({ data: user }). The 201 tells the client \"resource created\"; Location tells it where to fetch or link to the new resource. For not found: const user = await findUser(req.params.id); if (!user) return res.status(404).json({ error: 'User not found' }). The client can branch on status: if (res.status === 404) show \"Not found\"; if (res.status === 400) show validation errors from the body. For validation errors you collect a list (e.g. errors: [{ field: 'email', message: 'Invalid email' }]) and send res.status(400).json({ error: 'Validation failed', fields: errors }). So the logic is: one code path per outcome (success create, success read, not found, validation error, server error), and each path sets the appropriate status and a consistent JSON shape. That way the client always knows what happened and can display or log accordingly.\n\n**7. Example problem & solution:**\n\nProblem: Implement GET /users, POST /users, GET /users/:id, PUT /users/:id with correct codes. Solution: GET /users → 200 + list; POST → validate, create, 201 + newUser and Location; GET /users/:id → find by id, 404 or 200; PUT → validate, 404 or 200 with updated user. Use same JSON shape for all success/error responses.\n\n**8. Additional information:**\n\nREST is a style, not a standard. HATEOAS (links in response) is optional. Document with OpenAPI/Swagger. Rate limit and use HTTPS in production.",
          codeExample:
            "// POST create → 201\nres.status(201).json({ data: newUser });\n// Not found → 404\nres.status(404).json({ error: 'User not found' });\n// Validation error → 400\nres.status(400).json({ error: 'Invalid email', fields: ['email'] });",
          codeLanguage: "javascript",
        },
        {
          title: "Middleware & Auth",
          description:
            "JWT (sign and verify), session cookies, CORS headers, and request validation with express-validator",
          order: 3,
          imageUrl:
            "https://placehold.co/800x400/dc2626/white?text=JWT+OAuth+Sessions+CORS+Validation",
          content:
            "**1. Learning flow:**\n\n(1) Read the material and the JWT flow below so you understand how authentication works: the client sends credentials (e.g. email/password), the server verifies them and returns a signed JWT; on subsequent requests the client sends the token (e.g. in the Authorization header as Bearer &lt;token&gt; (replace &lt;token&gt; with the actual JWT)), and the server verifies the signature and reads the payload to identify the user. (2) Implement the auth middleware from the code: read the token from req.headers.authorization (split 'Bearer ' and take the second part), call jwt.verify(token, secret), set req.user to the payload and call next(); if there is no token or verification fails, return 401 with a clear message. (3) Add a login route (e.g. POST /login) that accepts email and password, checks them against your user store, and on success returns a signed JWT (e.g. jwt.sign({ userId, exp }, secret)); protect a route (e.g. GET /me) with the auth middleware so only authenticated requests receive the current user. (4) Add express-validator (or similar) for POST /users (or any input): validate required fields, email format, and length; call the validation, and if there are errors return 400 with a list of field-level messages so the client can show validation errors next to each input.\n\n**2. Material:**\n\n**Authentication** answers \"who is this user?\" so your API can allow or deny access. Two common approaches are JWT (stateless) and server-side sessions (stateful).\n\n**JWT (JSON Web Token):** A JWT is a signed payload (e.g. { userId: 42, exp: 1234567890 }). The server signs it with a secret (or private key); later it verifies the signature and reads the payload without looking up a database. The client must send the token on each request, usually in the Authorization header (Bearer <token>) or in an httpOnly cookie. Pros: no server-side session store; easy to scale horizontally. Cons: you cannot revoke a token before expiry (unless you maintain a blocklist). Use short-lived access tokens (e.g. 15 minutes) and optional refresh tokens for long-lived sessions; store refresh tokens securely and rotate them.\n\n**Sessions:** The server creates a session (e.g. in Redis or a database) and sends a session id in a cookie. On each request the server reads the cookie, looks up the session, and gets the user data. Pros: you can invalidate a session immediately (logout, revoke). Cons: you need a store and possibly sticky sessions or shared store for multiple servers.\n\n**CORS (Cross-Origin Resource Sharing):** Browsers restrict scripts on one origin (e.g. https://app.example.com) from reading responses from another (e.g. https://api.example.com) unless the API sends specific headers. The server sends Access-Control-Allow-Origin (and optionally Allow-Methods, Allow-Headers) to tell the browser which origins are allowed. Use the cors() middleware in Express; in production restrict the origin list (e.g. only your front-end origin) instead of using *.\n\n**Validation:** Never trust client input. Use express-validator (or similar) to check required fields, types (email, number, length), and ranges. Return 400 with a clear list of errors (e.g. { error: 'Validation failed', fields: [{ field: 'email', message: 'Invalid email' }] }) so the client can show field-level messages. Sanitize input to reduce injection risk.\n\n**3. Explanation:**\n\nJWT is stateless: the server only verifies the signature and expiry; it does not need to store the token. That simplifies deployment but means revocation requires extra mechanisms (blocklist or short expiry). Storing the token in an httpOnly cookie (instead of localStorage) reduces the risk of XSS stealing it. CORS is enforced by the browser; your API must send the right headers or the browser will block the response from the script. Validation ensures invalid or malicious input is rejected before it reaches your business logic or database.\n\n**4. Application:**\n\nLogin/logout, protected API routes, role-based access. CORS for SPA on different origin. Validation on every input (body, params, query).\n\n**5. How to implement:**\n\nLogin: verify credentials, jwt.sign({ userId, exp }, secret); return token. Auth middleware: read token from header or cookie; jwt.verify; set req.user; else 401. Apply auth to routes: app.get('/me', auth, handler). Validation: body('email').isEmail(), run(req), throw if !result.isEmpty(). See code below.\n\n**6. Logic & how the code works:**\n\nThe auth middleware runs before the route handler. It reads the token from req.headers.authorization (format \"Bearer <token>\") or from a cookie. If there is no token, it returns 401 and does not call next(). If there is a token, it calls jwt.verify(token, process.env.JWT_SECRET). Verify checks the signature (so the token was issued by this server and not tampered with) and optionally the exp claim (so the token has not expired). If verification succeeds, verify returns the payload (e.g. { userId: 42, exp: ... }); the middleware sets req.user = payload and calls next(), so the route handler can use req.user.userId. If verification fails (wrong signature, expired, or malformed), verify throws; the catch block returns 401. So the flow is: no token or invalid token → 401; valid token → req.user set and request continues. CORS works differently: it is not middleware that \"blocks\" the request; the browser sends the request, and the server responds. The browser then checks the response headers (Access-Control-Allow-Origin, etc.). If the origin is not allowed, the browser hides the response from the JavaScript that made the request. So the server must send the CORS headers on every response (including preflight OPTIONS) for the client script to read the body.\n\n**7. Example problem & solution:**\n\nProblem: Protected route that returns current user. Solution: Auth middleware that verifies JWT from Authorization header, sets req.user, calls next(); else 401. Route GET /me with auth middleware returns res.json(req.user). Client must send header: Authorization: Bearer <token>.\n\n**8. Additional information:**\n\nUse env for JWT_SECRET. Prefer short-lived access token + refresh token. express-validator: check required, isEmail, isLength; sanitize. Restrict CORS origin in production.",
          codeExample:
            "const jwt = require('jsonwebtoken');\nconst auth = (req, res, next) => {\n  const token = req.headers.authorization?.split(' ')[1];\n  if (!token) return res.status(401).json({ error: 'No token' });\n  try {\n    req.user = jwt.verify(token, process.env.JWT_SECRET);\n    next();\n  } catch (e) { res.status(401).json({ error: 'Invalid token' }); }\n};",
          codeLanguage: "javascript",
        },
        {
          title: "File Handling & Storage",
          description:
            "Streams for large files, multipart uploads (multer), serving static files, and loading config from env",
          order: 4,
          imageUrl:
            "https://placehold.co/800x400/ea580c/white?text=Streams+Upload+Static+Files+env",
          content:
            "**1. Learning flow:**\n\n(1) Read the material below so you understand streams (data in chunks instead of loading the whole file into memory), multipart uploads (how Multer parses form-data and gives you req.file), serving static files (express.static maps URL paths to a directory), and why environment variables (dotenv, process.env) are used for config and secrets. (2) Add the upload route from the code: configure Multer with a destination directory (e.g. uploads/) and a file size limit, use upload.single('file') in the route, and in the handler read req.file.path (or .filename) and return it in the response; add express.static('public') so files in the public folder are served at the root path. (3) Test the upload with a form or Postman: send a POST with enctype multipart/form-data and a field named 'file'; confirm the file appears in uploads/ and the response contains the path; request the uploaded file via the static route (if you serve uploads/) or via a dedicated route. (4) Load PORT and a secret (e.g. JWT_SECRET) from .env using require('dotenv').config(); at startup validate that required variables are set (e.g. if (!process.env.JWT_SECRET) throw new Error('JWT_SECRET required')) so the app fails fast instead of at the first request that needs the secret.\n\n**2. Material:**\n\n**Streams:** Reading a whole file into memory (e.g. fs.readFile) is simple but for large files it can exhaust memory. Streams process data in chunks: createReadStream(path) gives you a readable stream; createWriteStream(path) a writable one; you can .pipe() a readable to a writable so data flows without loading the whole file. Use streams for large file uploads, downloads, or log processing. The same idea applies to HTTP: res is a writable stream, so you can pipe a file stream to res for efficient file serving.\n\n**Multipart uploads (Multer):** When the client sends a form with enctype multipart/form-data (e.g. file input), the body is not JSON but a stream of parts (fields and files). Multer is middleware that parses this: you configure a destination (dest: 'uploads/') or custom storage (e.g. memoryStorage()), and optionally limits (fileSize, number of files). After the middleware runs, req.file (single file) or req.files (array) contains the uploaded file(s): path, originalname, mimetype, size. You should validate file type and size server-side; the client can lie about Content-Type, so for strict security check magic bytes or use a library. Limit file size to prevent DoS.\n\n**Serving static files:** express.static('public') serves files from the public directory. A request to /styles.css maps to public/styles.css; the middleware sets the right Content-Type and sends the file. Use this for your front-end build output (e.g. public or build folder) or for uploaded assets. Do not serve uploads from a user-writable directory without validation (path traversal risk); prefer storing uploads outside the web root or in cloud storage and serving via a controlled route.\n\n**Environment variables:** Use dotenv to load .env into process.env so you can read PORT, DATABASE_URL, JWT_SECRET, etc. Never commit .env or hardcode secrets. Validate required variables at startup (if process.env.JWT_SECRET is missing, exit with a clear message) so the app fails fast in production instead of at the first request.\n\n**3. Explanation:**\n\nStreaming keeps memory usage bounded when handling large data. Multer hides the complexity of multipart parsing and gives you req.file; you still must validate and store safely. express.static is a simple way to serve static assets. Env vars keep configuration and secrets out of the codebase and allow different values per environment (dev, staging, production).\n\n**4. Application:**\n\nLarge file download/upload, image upload, serving built frontend or assets. Env for all config and secrets in dev and production.\n\n**5. How to implement:**\n\nMulter: const upload = multer({ dest: 'uploads/', limits: { fileSize: 5*1024*1024 } }); route: upload.single('file'); req.file.path. Static: app.use(express.static('public')). Env: require('dotenv').config(); check process.env.PORT etc. See code below.\n\n**6. Logic & how the code works:**\n\nWhen a client POSTs with Content-Type multipart/form-data and a field named 'file', the request body is a stream of boundaries and parts. The Multer middleware (upload.single('file')) listens to the stream, finds the part with name 'file', writes the binary data to the configured destination (e.g. uploads/), and when done attaches an object to req.file with path (e.g. uploads/abc123), originalname (from the client), mimetype, size. Your route handler runs after the middleware, so it can read req.file.path and return a URL (e.g. /uploads/abc123). express.static('uploads') is registered with app.use; when a request comes in for GET /uploads/abc123, Express matches the path to the static middleware, which looks for the file uploads/abc123 on disk and streams it back with the appropriate Content-Type. So the flow is: client uploads → Multer writes to disk and sets req.file → handler returns URL → client (or browser) requests that URL → static middleware serves the file. Env vars are read at process start (require('dotenv').config() loads .env into process.env); your code reads process.env.PORT or process.env.JWT_SECRET so the same codebase can run with different config and no secrets in source control.\n\n**7. Example problem & solution:**\n\nProblem: Accept image upload and return URL. Solution: Multer with dest 'uploads/'; validate content-type or extension; limit size. After upload, res.json({ url: '/uploads/' + req.file.filename }). Serve uploads with express.static('uploads') so the URL is valid.\n\n**8. Additional information:**\n\nFor production use cloud storage (S3) and store URL in DB. Never commit .env. Use helmet and rate limiting. Validate file type server-side; consider virus scan for user uploads.",
          codeExample:
            "const multer = require('multer');\nconst upload = multer({ dest: 'uploads/', limits: { fileSize: 5*1024*1024 } });\napp.post('/upload', upload.single('file'), (req, res) => {\n  res.json({ path: req.file.path });\n});\napp.use(express.static('public'));",
          codeLanguage: "javascript",
        },
        {
          title: "Deployment",
          description:
            "Run with PM2 for process management, use env vars for config, and follow a production checklist (HTTPS, logs, health)",
          order: 5,
          imageUrl:
            "https://placehold.co/800x400/1d4ed8/white?text=PM2+Production+Deployment",
          content:
            "**1. Learning flow:**\n\n(1) Read the material and the production checklist below so you know what PM2 does (process manager: start, restart on crash, optional cluster mode), why environment variables are used for config and secrets, and what a production checklist includes (HTTPS, logging, health endpoint, security headers, rate limiting). (2) Add ecosystem.config.js from the code: define at least one app with name, script (e.g. server.js), and env (e.g. NODE_ENV: 'production'); start the app with pm2 start ecosystem.config.js and confirm it appears in pm2 list and keeps running after you close the terminal. (3) In your app add GET /health (or /ready) that returns 200 and optionally a body like { status: 'ok' } so load balancers and operators can check that the app is alive; ensure the app reads PORT and any secret from process.env and validates them at startup. (4) Run pm2 save to persist the current process list to disk, then pm2 startup and follow the printed command so PM2 starts on system boot and restores your app—document these steps for your deployment runbook so anyone can reproduce the setup.\n\n**2. Material:**\n\n**PM2** is a process manager for Node.js: it starts your app (e.g. pm2 start server.js or pm2 start ecosystem.config.js), restarts it if it crashes, and can run multiple instances (cluster mode). Commands: pm2 list (show processes), pm2 logs (stream logs), pm2 monit (dashboard), pm2 restart all. To keep the process list across server reboots: pm2 save (writes current list to disk) and pm2 startup (prints a command you run once to start PM2 on boot). In ecosystem.config.js you define apps with name, script, env (e.g. NODE_ENV: 'production'), instances (for cluster), and other options.\n\n**Environment:** Set NODE_ENV=production so libraries and your app can enable production behavior (e.g. less verbose logging, no stack traces to the client). All secrets and config (PORT, DATABASE_URL, JWT_SECRET, API keys) should come from environment variables; validate required vars at startup and exit with a clear error if any are missing. Never commit .env to version control.\n\n**Production checklist:** Use HTTPS (terminate SSL at a reverse proxy like nginx or use a PaaS that provides it). Use a structured logger (pino, winston) and avoid console.log for request logs. Expose a GET /health (or /ready) that returns 200 when the app is ready to serve (e.g. DB connected); load balancers and Kubernetes use this for liveness/readiness. Add security middleware: helmet for safe headers, rate limiting to reduce abuse. Validate and sanitize all input. Keep dependencies updated (npm audit, Dependabot, Renovate).\n\n**3. Explanation:**\n\nPM2 keeps your Node process running and restarts it on crash so you do not rely on a single run in a terminal. pm2 save and pm2 startup ensure the same processes come back after a reboot. Env vars keep config and secrets out of the codebase and allow different values per environment. A health route gives operators a simple way to check that the app is up; load balancers can stop sending traffic to an unhealthy instance. The checklist items (HTTPS, logging, helmet, rate limit, validation) address common production requirements for security, observability, and stability.\n\n**4. Application:**\n\nProduction servers, Docker (PM2 or node directly), PaaS (Heroku, Railway). Health check for Kubernetes or ELB.\n\n**5. How to implement:**\n\nCreate ecosystem.config.js with name, script, env. Run pm2 start ecosystem.config.js. In app: require('dotenv').config(); const port = process.env.PORT || 3000; app.get('/health', (req, res) => res.status(200).send('OK'). See code below.\n\n**6. Logic & how the code works:**\n\nWhen you run pm2 start server.js, PM2 spawns a child process that runs node server.js. PM2 watches that process; if it exits (crash or normal exit), PM2 can restart it (default behavior). So your app is not tied to your SSH session—it keeps running. pm2 save writes the current list of managed processes to a file (typically ~/.pm2/dump.pm2); pm2 startup prints a command (e.g. sudo env PATH=... pm2 startup systemd) that you run once. That command configures the system (e.g. systemd) to run PM2 at boot; when the system boots, PM2 starts and restores the saved process list, so your Node app starts automatically. The GET /health handler is a normal route: when a client (or a load balancer health check) requests GET /health, your app responds with 200 and maybe a body like { status: 'ok' }. The load balancer polls this URL; if it gets a non-2xx or timeout, it marks the instance unhealthy and stops sending traffic. So the logic is: PM2 keeps the process running and restores it after reboot; the app reads config from env and exposes a health endpoint so external systems can verify it is alive and ready.\n\n**7. Example problem & solution:**\n\nProblem: App dies on server reboot. Solution: Use PM2. After pm2 start server.js run pm2 save then pm2 startup and follow the printed command so PM2 runs on boot. Set NODE_ENV=production in ecosystem or env.\n\n**8. Additional information:**\n\nUse a proper logger (pino, winston) in production. Reverse proxy (nginx) for SSL and static files. Consider Docker for consistent environment. Keep dependencies updated (npm audit, renovate).",
          codeExample:
            "// ecosystem.config.js\nmodule.exports = {\n  apps: [{ name: 'api', script: 'server.js', env: { NODE_ENV: 'production' } }]\n};\n// pm2 start ecosystem.config.js",
          codeLanguage: "javascript",
        },
      ],
    },
    {
      title: "Database & SQL",
      slug: "database-sql",
      description:
        "Design and query relational databases: tables, primary and foreign keys, normalization (1NF–3NF), SELECT with WHERE and JOIN (INNER, LEFT), GROUP BY and HAVING and subqueries, when and how to index for performance, ACID and transactions and isolation levels, and stored procedures and functions for application logic. Before you start: basic programming and the idea of storing data in tables. No prior SQL required.",
      order: 4,
      published: true,
      items: [
        {
          title: "Relational Model & Normalization",
          description: "Tables, keys, 1NF–3NF, relationships",
          order: 0,
          content:
            '**1. Learning flow:**\n\n(1) Read material and normalization levels (1NF: atomic values and no repeating groups; 2NF: no partial dependency on the key; 3NF: no transitive dependency) so you understand why we split tables and how keys link them. (2) Create the users and orders tables from the code: define id as primary key, user_id in orders as foreign key referencing users(id), and optionally ON DELETE CASCADE so you see how the database enforces relationships. (3) Look at an existing schema (e.g. from a tutorial or your project) and identify which columns are primary keys and which are foreign keys and to which table they refer. (4) Take a denormalized table (e.g. one that has order_id, product_id, customer_name, product_name) and split it into normalized tables (customers, products, orders, order_items) with the right keys so each fact is stored once.\n\n**2. Material:**\n\nThe relational model stores data in tables (relations). Each row is a tuple (one record); each column is an attribute (one field). Tables relate to each other via keys so you can avoid duplicating data and keep updates consistent.\n\n**Primary key:** One or more columns that uniquely identify each row. No two rows can have the same primary key value. Common choices: a single id column (auto-increment or UUID) or a natural key (e.g. email in a users table). The primary key is used when other tables refer to this row.\n\n**Foreign key:** A column (or set of columns) in one table that references the primary key of another table. It enforces referential integrity: the database will reject a row if the foreign key value does not exist in the referenced table. For example, orders.user_id references users.id so you cannot have an order for a non-existent user. You can specify ON DELETE CASCADE (delete child rows when the parent is deleted) or ON DELETE SET NULL depending on your business rules.\n\n**1NF (First Normal Form):** Every column contains atomic (indivisible) values, and there are no repeating groups. For example, instead of one column "phones" with "555-1111, 555-2222", you have one row per phone or a separate phones table. Each cell holds exactly one value.\n\n**2NF (Second Normal Form):** 1NF plus no partial dependency on the primary key. Partial dependency means a non-key attribute depends on only part of a composite key. For example, if the primary key is (order_id, product_id) and you store product_name in the same table, product_name depends only on product_id, not on the full key. To satisfy 2NF, move product_name to a products table.\n\n**3NF (Third Normal Form):** 2NF plus no transitive dependency. Transitive dependency means a non-key attribute depends on another non-key attribute (which in turn depends on the key). For example, if you have (employee_id, department_id, department_name), department_name depends on department_id, not directly on employee_id. Move department_name to a departments table so each non-key attribute depends only on the primary key.\n\n**3. Explanation:**\n\nNormalization reduces redundancy: each fact (e.g. a customer name, a product price) is stored in one place. When the fact changes, you update it once and every query that joins to that table sees the new value. That avoids update anomalies (e.g. updating the product name in one row but forgetting another). Partial dependency in 2NF and transitive dependency in 3NF are the two main sources of redundancy when you have composite keys or multiple non-key attributes; removing them gives you a clean, maintainable schema. In practice, 3NF is often enough; you can denormalize selectively (e.g. add a cached column for read performance) when you have measured a need.\n\n**4. Application:**\n\nDesigning schemas for apps, reporting, and OLTP. Use normalization to avoid duplicate data; denormalize sparingly for read performance.\n\n**5. How to implement:**\n\n(1) Define each table with CREATE TABLE: list columns with types (INT, VARCHAR(n), DECIMAL(p,s), DATE, etc.). (2) Designate the primary key: PRIMARY KEY (id) or PRIMARY KEY (a, b) for composite; use SERIAL or AUTO_INCREMENT for a single auto-generated id. (3) Add foreign keys: FOREIGN KEY (user_id) REFERENCES users(id); optionally ON DELETE CASCADE (delete children when parent is deleted) or ON DELETE SET NULL. (4) Add NOT NULL and UNIQUE where appropriate (e.g. email UNIQUE NOT NULL for users). (5) Check normalization: each non-key attribute should depend on the whole key (2NF) and only on the key (3NF); if an attribute depends on another non-key attribute, move it to a separate table. See code below.\n\n**6. Logic & how the code works:**\n\nCREATE TABLE users: The id column is SERIAL (or AUTO_INCREMENT), so the database generates a unique integer for each new row. PRIMARY KEY (id) enforces that no two rows have the same id and creates an index for fast lookups. email UNIQUE NOT NULL means every user must have an email and no two users can share the same email; the database will reject an insert or update that violates this.\n\nCREATE TABLE orders: user_id INT REFERENCES users(id) declares a foreign key. When you insert an order, the database checks that the user_id value exists in users.id; if not, the insert fails. That keeps data consistent: you cannot have an order pointing to a user that does not exist. Optionally, ON DELETE CASCADE means that when a user is deleted, all their orders are automatically deleted; without it, the database would prevent deleting a user who has orders (or you would set user_id to NULL if the column allows it). This way, the relational structure and constraints do the work of maintaining integrity instead of application code.\n\n**7. Example problem & solution:**\n\nProblem: Table with (order_id, product_id, customer_name, product_name) has redundancy. Solution: Split into orders (order_id, customer_id), customers (customer_id, name), order_items (order_id, product_id, qty), products (product_id, name). Foreign keys link them. Now customer_name and product_name stored once.\n\n**8. Additional information:**\n\nBCNF and 4NF for advanced cases. In practice 3NF is often enough. Use ER diagrams to design before writing DDL.',
          codeExample:
            "-- users: PRIMARY KEY, email UNIQUE\nCREATE TABLE users (\n  id SERIAL PRIMARY KEY,\n  email VARCHAR(255) UNIQUE NOT NULL\n);\n-- orders: FOREIGN KEY user_id -> users(id)\nCREATE TABLE orders (\n  id SERIAL PRIMARY KEY,\n  user_id INT REFERENCES users(id),\n  total DECIMAL(10,2)\n);\n-- ON DELETE CASCADE: delete orders when user is deleted (optional)",
          codeLanguage: "sql",
          imageUrl:
            "https://placehold.co/800x400/1d4ed8/white?text=Relational+Model",
        },
        {
          title: "SQL Queries",
          description:
            "SELECT with WHERE and ORDER BY; INNER and LEFT JOIN; GROUP BY and HAVING; subqueries and common patterns",
          order: 1,
          imageUrl:
            "https://placehold.co/800x400/1d4ed8/white?text=SQL+Queries+JOIN+GROUP+BY",
          content:
            '**1. Learning flow:**\n\n(1) Read material and JOIN types: INNER JOIN (only matching rows), LEFT JOIN (all from left, match from right or NULL), and how GROUP BY with aggregates (COUNT, SUM, AVG) and HAVING work so you can answer "per group" questions. (2) Run the users-with-order-count query (LEFT JOIN users and orders, GROUP BY user, COUNT(orders)) and the highest-paid-per-department query (correlated subquery or JOIN with max salary per dept) from the code so you see the pattern. (3) Write both queries yourself: users with order count (including 0) and highest-paid employee per department so you practice JOIN, GROUP BY, and subqueries. (4) Try a correlated subquery (e.g. for each row in the outer query, the inner query uses a value from the outer row) so you understand when it is useful and how it can be rewritten with JOIN or window functions.\n\n**2. Material:**\n\n**SELECT basics:** SELECT column1, column2 FROM table WHERE condition ORDER BY column LIMIT n. WHERE filters rows before any grouping or ordering. ORDER BY sorts the result; add DESC for descending. LIMIT restricts how many rows are returned (useful for pagination or top-N).\n\n**JOINs:** JOINs combine rows from two (or more) tables based on a condition, usually equality on a key.\n\nINNER JOIN: Returns only rows where there is a match in both tables. If a user has no orders, that user does not appear when you join users INNER JOIN orders. Use when you only want rows that have a related row in the other table.\n\nLEFT JOIN (LEFT OUTER JOIN): Returns all rows from the left table and matching rows from the right; if there is no match on the right, the right columns are NULL. So every user appears once per order, and users with no orders appear once with NULL in the order columns. Use when you want to keep all left rows and optionally show related data (e.g. "all users with their order count" including zero).\n\nRIGHT JOIN: Same idea as LEFT but all rows from the right table. In practice LEFT JOIN is used more often; you can swap table order instead of using RIGHT.\n\n**GROUP BY and aggregates:** GROUP BY column(s) collapses rows that share the same value(s) into one row per group. You can then use aggregate functions: COUNT(*), SUM(amount), AVG(price), MIN(date), MAX(date). Only columns in GROUP BY or aggregate expressions can appear in the SELECT list. HAVING filters groups after aggregation (e.g. HAVING COUNT(*) > 1 to find duplicates). WHERE filters rows before grouping; HAVING filters groups after.\n\n**Subqueries:** A subquery is a SELECT inside another query. It can appear in WHERE (e.g. WHERE id IN (SELECT user_id FROM orders)) or in FROM as a derived table (e.g. FROM (SELECT dept_id, MAX(salary) AS max_sal FROM employees GROUP BY dept_id) AS t). Correlated subquery: the inner query references a column from the outer query (e.g. for each employee, find the max salary in the same department); it runs once per outer row.\n\n**3. Explanation:**\n\nJOINs connect related data: you store users in one table and orders in another to avoid repeating user data in every order; JOIN brings them together for a query. LEFT JOIN ensures you do not drop rows from the left table when there is no match—essential for "users with order count" where users with zero orders should still appear. GROUP BY plus aggregates answers questions like "how many orders per user?" or "total revenue per region." HAVING filters those groups (e.g. only users with more than 5 orders). Subqueries let you express multi-step logic in one statement: first compute a set or a value (e.g. max salary per department), then use it in the outer query. Correlated subqueries are powerful but can be slow on large tables; sometimes a JOIN or a window function is more efficient.\n\n**4. Application:**\n\nReporting, dashboards, API backends. Users with counts, top-N per group, existence checks (EXISTS subquery).\n\n**5. How to implement:**\n\n(1) JOIN: FROM table1 t1 JOIN table2 t2 ON t1.id = t2.foreign_id; use INNER JOIN for only matching rows, LEFT JOIN to keep all rows from the left. (2) GROUP BY: after FROM and JOIN, add GROUP BY column(s); in SELECT list only include columns that are in GROUP BY or wrapped in an aggregate (COUNT, SUM, AVG, MIN, MAX). (3) HAVING: use after GROUP BY to filter groups (e.g. HAVING COUNT(*) > 1 for duplicates). (4) Subquery in WHERE: WHERE id IN (SELECT user_id FROM orders WHERE ...) or WHERE value = (SELECT MAX(value) FROM t). (5) Correlated subquery: the inner SELECT references a column from the outer query (e.g. WHERE salary = (SELECT MAX(salary) FROM employees e2 WHERE e2.dept_id = e.dept_id)). See code below.\n\n**6. Logic & how the code works:**\n\nQuery 1 (users with order count): You LEFT JOIN users u with orders o ON u.id = o.user_id. For each user, you get one row per order; if a user has no orders, you still get one row for that user with all order columns NULL. Then GROUP BY u.id, u.name collapses to one row per user. COUNT(o.id) counts only non-NULL order ids, so users with no orders get count 0 (because o.id is NULL and COUNT ignores NULLs). The result is exactly one row per user with their order count.\n\nQuery 2 (highest-paid per department): For each row e in employees, the correlated subquery (SELECT MAX(salary) FROM employees e2 WHERE e2.dept_id = e.dept_id) computes the maximum salary in the same department. The outer WHERE salary = (that subquery) keeps only rows where the employee\'s salary equals that maximum—i.e. one or more employees per department who have the top salary in that department. So you get the highest-paid employee(s) per department in one query.\n\n**7. Example problem & solution:**\n\nProblem: List users with their order count (including 0). Solution: LEFT JOIN users-orders, GROUP BY user, COUNT(o.id).\n\nProblem: Employee with highest salary per department. Solution: Correlated subquery WHERE salary = (SELECT MAX(salary) FROM employees WHERE dept_id = e.dept_id).\n\n**8. Additional information:**\n\nUse meaningful aliases. Avoid SELECT * in production; list columns. Test with small data first. EXPLAIN to check performance.',
          codeExample:
            "-- Users + order count (LEFT JOIN: users with no orders still appear)\nSELECT u.name, COUNT(o.id) AS order_count\nFROM users u\nLEFT JOIN orders o ON u.id = o.user_id\nGROUP BY u.id, u.name;\n\n-- Highest-paid per department (correlated subquery)\nSELECT * FROM employees e\nWHERE salary = (SELECT MAX(salary) FROM employees e2 WHERE e2.dept_id = e.dept_id);",
          codeLanguage: "sql",
        },
        {
          title: "Indexing & Performance",
          description:
            "When to add an index; B-tree and composite indexes; EXPLAIN to read query plans and avoid full table scans",
          order: 2,
          imageUrl:
            "https://placehold.co/800x400/2563eb/white?text=SQL+Indexing+%26+Performance",
          content:
            '**1. Learning flow:**\n\n(1) Read the material below so you understand when to add an index: index columns that appear in WHERE (filter), JOIN ON (join key), and ORDER BY (sort), because the database can use the index to find or sort rows in O(log n) steps instead of scanning the whole table; balance this with the cost of writes (every INSERT/UPDATE/DELETE that touches indexed columns must update the index). (2) Create the indexes from the code (single-column and composite) and run EXPLAIN (or EXPLAIN ANALYZE in PostgreSQL) on a query that uses those columns so you see in the plan that the index is used (e.g. Index Scan or Index Seek) and the estimated row count is reasonable. (3) Add an index on a column you often filter on; run EXPLAIN before and after adding it so you observe the plan change from a full table scan to an index scan and the estimated rows drop. (4) Try a composite index for a query that filters on two columns (e.g. user_id and created_at); remember the left-prefix rule—the index on (a, b, c) can be used for WHERE a = ?, or WHERE a = ? AND b = ?, but not for WHERE b = ? alone.\n\n**2. Material:**\n\nAn index is a data structure that the database uses to find rows quickly instead of scanning the whole table. The most common type is a B-tree index: it keeps column values in sorted order so the engine can do equality lookups (find rows where user_id = 5) and range scans (find rows where created_at between ... and ...) in O(log n) steps instead of reading every row.\n\n**When to add an index:** Index columns that appear in WHERE (filter), JOIN ON (join key), and ORDER BY (sort). For example, if you often run SELECT * FROM orders WHERE user_id = ? ORDER BY created_at DESC, an index on (user_id, created_at) lets the database find the matching rows and return them already sorted without a separate sort step. The cost of indexes is write performance: every INSERT, UPDATE, or DELETE that touches indexed columns must update the index, so too many indexes on a write-heavy table can slow down writes. Balance: index what you query; avoid indexing every column.\n\n**Composite index and left-prefix:** A composite index on (a, b, c) is stored in sorted order: first by a, then by b, then by c. The database can use this index for WHERE a = ?, or WHERE a = ? AND b = ?, or WHERE a = ? AND b = ? AND c = ? (left-prefix). It cannot use it for WHERE b = ? or WHERE c = ? alone, because the rows are not sorted by b or c globally. So column order matters: put the most selective or most frequently filtered column first, and include ORDER BY columns in the index when you want to avoid a sort.\n\n**EXPLAIN:** Running EXPLAIN SELECT ... (or EXPLAIN ANALYZE in PostgreSQL) shows the query plan: which indexes are used, whether there is a full table scan (type=ALL or seq scan), and the estimated number of rows. Look for "Index Scan" or "Index Seek" (good) vs "Seq Scan" on a large table (often a sign you need an index or that the planner chose a full scan because it expects to read most rows anyway). The rows estimate helps you see how much work the query does.\n\n**3. Explanation:**\n\nB-trees give logarithmic lookup and support range queries. Composite indexes extend that to multiple columns but only in left-prefix order. EXPLAIN shows you what the planner decided so you can add or adjust indexes and verify they are used.\n\n**4. Application:**\n\nHigh-read tables: index filter and join columns. Avoid over-indexing write-heavy tables. Use EXPLAIN when queries are slow.\n\n**5. How to implement:**\n\n(1) Identify slow or frequent queries; note which columns appear in WHERE, JOIN ON, and ORDER BY. (2) Create an index on those columns: CREATE INDEX idx_name ON table(col) for a single column, or (col1, col2) for composite (order matters—left-prefix rule). (3) Run EXPLAIN SELECT ... (or EXPLAIN ANALYZE) before and after; check that the plan uses the index (type ref or range, not ALL/seq scan) and that estimated rows drop. (4) For composite index, put the most selective or most frequently filtered column first; include ORDER BY columns to avoid a sort step. See code below.\n\n**6. Logic & how the code works:**\n\nWhen you create CREATE INDEX idx_orders_user_id ON orders(user_id), the database builds a B-tree over the user_id column. For a query SELECT * FROM orders WHERE user_id = 1, the planner can use this index: it walks the B-tree to find the first row with user_id = 1 and then follows the leaf chain for all rows with that value, instead of scanning the whole table. So the work is proportional to the number of matching rows (and the log of the table size for the lookup), not the full table size. For CREATE INDEX idx_orders_user_date ON orders(user_id, created_at), the index is ordered by (user_id, created_at). A query WHERE user_id = 1 ORDER BY created_at DESC can use the index to find the segment for user_id = 1 and read rows in created_at order (or reverse), so no separate sort is needed. A query WHERE created_at > \'2024-01-01\' cannot use this index for the filter alone, because the index is not sorted by created_at globally. When you run EXPLAIN SELECT * FROM orders WHERE user_id = 1 ORDER BY created_at DESC, the plan should show an index scan on idx_orders_user_date (or similar) and a low estimated row count; if you see a sequential scan and a high row count, the index may be missing or the planner may be choosing a full scan (e.g. if it estimates that most rows match).\n\n**7. Example problem & solution:**\n\nProblem: Query orders WHERE user_id=1 ORDER BY created_at DESC is slow. Solution: CREATE INDEX idx_orders_user_date ON orders(user_id, created_at). EXPLAIN should show index usage and lower rows.\n\n**8. Additional information:**\n\nCovering index includes all columns needed so the engine doesn\'t touch the table. Partial index (WHERE condition) for subset of rows. Monitor index usage; drop unused indexes.',
          codeExample:
            "-- Index single column\nCREATE INDEX idx_orders_user_id ON orders(user_id);\n-- Composite: left-prefix for WHERE + ORDER BY\nCREATE INDEX idx_orders_user_date ON orders(user_id, created_at);\n-- Check plan: type=ref/range=index, type=ALL=full scan\nEXPLAIN SELECT * FROM orders WHERE user_id = 1 ORDER BY created_at DESC;",
          codeLanguage: "sql",
        },
        {
          title: "Transactions",
          description:
            "ACID properties; BEGIN, COMMIT, ROLLBACK; isolation levels (read uncommitted to serializable) and when to use them",
          order: 3,
          imageUrl:
            "https://placehold.co/800x400/16a34a/white?text=ACID+COMMIT+ROLLBACK+Isolation+Levels",
          content:
            "**1. Learning flow:**\n\n(1) Read material and ACID. (2) Run the transfer example from the code; try COMMIT and then ROLLBACK in a test. (3) Implement transfer in app code: begin, two updates, commit or rollback on error. (4) Read about isolation levels and when to set them.\n\n**2. Material:**\n\nA transaction groups multiple SQL statements into one unit: either all of them take effect (COMMIT) or none do (ROLLBACK). That way you can do multi-step operations (e.g. deduct from one account and add to another) without leaving the data in an inconsistent state if something fails in the middle.\n\n**ACID:** Atomicity: the transaction is all-or-nothing; if any statement fails or you call ROLLBACK, every change in the transaction is undone. Consistency: the database enforces constraints (e.g. foreign keys, unique) so after a committed transaction the data is in a valid state. Isolation: concurrent transactions do not see each other's uncommitted changes in a way that breaks the rules of the isolation level. Durability: once you COMMIT, the changes are persisted to disk (via WAL or similar) so a crash after commit does not lose them.\n\n**Using transactions:** In SQL you start with BEGIN (or START TRANSACTION), run your statements (e.g. two UPDATEs for a transfer), then COMMIT to make the changes permanent or ROLLBACK to cancel. In application code you use the driver or ORM: beginTransaction(), run your queries, then commit() or rollback() in a try/catch so that on any error you roll back and optionally rethrow.\n\n**Isolation levels:** They control what one transaction can see of other concurrent transactions. Read uncommitted: can see uncommitted changes (dirty reads); rarely used. Read committed: sees only committed data; another transaction's uncommitted changes are invisible; most databases default to this. Repeatable read: within the same transaction, repeated reads of the same row see the same data even if another transaction committed changes in between (no non-repeatable read); some databases use snapshot isolation here. Serializable: full isolation as if transactions ran one after another; prevents phantoms (new rows appearing in a range you read before). Higher isolation reduces anomalies but can increase locking and contention; use the lowest level that your application correctness allows.\n\n**3. Explanation:**\n\nAtomicity gives you the guarantee that a transfer either fully applies or fully rolls back, so you never have money disappearing without appearing elsewhere. Isolation levels let you trade off between consistency and performance; read committed is the default and is enough for many apps; use serializable only when you need strict guarantees (e.g. preventing double-booking).\n\n**4. Application:**\n\nMulti-step updates (transfer, order + inventory), reporting with consistent snapshot. Use serializable only when necessary (e.g. strict consistency); otherwise read committed or repeatable read.\n\n**5. How to implement:**\n\n(1) In SQL: Start with BEGIN (or START TRANSACTION); run your statements (e.g. two UPDATEs for a transfer); then COMMIT to make changes permanent or ROLLBACK to cancel. (2) In application code: Call beginTransaction() (or equivalent), run your queries in a try block, then commit() on success; in catch call rollback() and rethrow so no partial state is left. (3) Optionally set isolation level before BEGIN (e.g. SET TRANSACTION ISOLATION LEVEL READ COMMITTED) when you need a specific guarantee. (4) Keep transactions short to reduce locking and deadlock risk. See code below.\n\n**6. Logic & how the code works:**\n\nWhen you execute BEGIN, the database starts a transaction: subsequent statements see a consistent snapshot (depending on isolation level) and their changes are not visible to others until COMMIT. The first UPDATE (balance = balance - 100 WHERE id = 1) reduces account 1's balance; the second UPDATE adds 100 to account 2. Both changes are only in the transaction's temporary state. When you execute COMMIT, the database writes the changes to the WAL and makes them visible to other transactions; if the process crashes before COMMIT, on recovery the transaction is rolled back so no partial state is applied. If you execute ROLLBACK (or an error occurs and you roll back in app code), both updates are undone and the balances are as they were before BEGIN. So the logic is: one unit of work (debit + credit), one commit; any failure or explicit rollback cancels the whole unit. In app code you typically do: start transaction; try { update account1; update account2; commit(); } catch (e) { rollback(); throw e; } so that exceptions (constraint violation, deadlock, connection loss) result in rollback and no partial transfer.\n\n**7. Example problem & solution:**\n\nProblem: Transfer 100 from account 1 to 2 without inconsistency. Solution: BEGIN; two UPDATEs; COMMIT if success, ROLLBACK on error. In app: try { queries; commit(); } catch { rollback(); }.\n\n**8. Additional information:**\n\nKeep transactions short to reduce locking. Use savepoints for partial rollback if supported. Most ORMs support transactions (e.g. await prisma.$transaction([...])).",
          codeExample:
            "BEGIN;\nUPDATE accounts SET balance = balance - 100 WHERE id = 1;\nUPDATE accounts SET balance = balance + 100 WHERE id = 2;\n-- If any error: ROLLBACK; else:\nCOMMIT;\n\nSET TRANSACTION ISOLATION LEVEL READ COMMITTED;",
          codeLanguage: "sql",
        },
        {
          title: "Stored Procedures & Real-World Use",
          description:
            "Writing procedures and functions in SQL; when to use them; designing schema and queries for real applications",
          order: 4,
          imageUrl:
            "https://placehold.co/800x400/0d9488/white?text=Stored+Procedures+Functions+App+Design",
          content:
            "**1. Learning flow:**\n\n(1) Read the material below so you understand when to use stored procedures: when you want multiple statements and a transaction in a single round-trip from the application (e.g. create an order, update inventory, write an audit row), when several applications share the same database and you want the logic in one place, or when you want to move heavy logic closer to the data; weigh this against the downsides (harder to unit test from the app, versioning via migrations, debugging). (2) Create and call the place_order procedure from the code: define it with CREATE PROCEDURE and IN parameters, put the INSERT and UPDATE inside, and call it from your app or a SQL client with CALL place_order(1, 5, 2) so you see one round-trip executing the whole workflow. (3) Write a procedure that creates an order and updates stock (or a similar multi-step workflow); call it from your application so you practice the pattern of encapsulating atomic logic in the database. (4) Review real-world design: use indexing for the columns you filter and join on (see the Indexing section), connection pooling (in the app or with a proxy like PgBouncer) so you do not open a new connection per request, and caching (e.g. Redis) for hot or rarely changing data when the database is the bottleneck.\n\n**2. Material:**\n\n**Stored procedures** are blocks of SQL (and often procedural extensions like variables, conditionals, loops) stored in the database and invoked with CALL procedure_name(args). They can have IN parameters (input), OUT parameters (output), or INOUT. You use them to encapsulate multi-step logic (e.g. create an order, update inventory, write an audit row) in one round-trip from the application: the client sends CALL place_order(1, 5, 2) and the server runs the whole block, including transaction boundaries (BEGIN/COMMIT/ROLLBACK inside the procedure). That reduces network round-trips and keeps the atomic workflow in one place. **Stored functions** return a single value and can be used in SELECT (e.g. SELECT my_func(id) FROM t); they are suited for computations or lookups that you want to use inside queries.\n\n**When to use procedures:** Use when you want (1) multiple statements and a transaction in a single round-trip, (2) logic shared by several applications or services that all talk to the same database, or (3) moving heavy logic closer to the data. Downsides: procedures are harder to unit test from the app, version with migrations (you need to deploy DDL), and debug; many teams prefer to keep business logic in the application and use the database for queries and constraints (foreign keys, triggers for simple rules).\n\n**Real-world design:** Normalize your schema to avoid redundancy; denormalize selectively (e.g. cached counts or copied fields) when you have measured a read-performance need. Index filter and join columns; use EXPLAIN to verify. Use connection pooling (in the app or with a proxy like PgBouncer) so you do not open a new connection per request. Cache hot or rarely changing data (e.g. in Redis) when the database is the bottleneck.\n\n**3. Explanation:**\n\nProcedures run inside the database, so you can do several statements and a commit/rollback in one call from the app. Functions are for single-value expressions in SELECT. Choosing procedures vs app-side logic is a trade-off: procedures reduce round-trips and centralize logic; app-side logic is easier to test and version with your application code.\n\n**4. Application:**\n\nComplex workflows (order + inventory + audit), reporting pipelines, shared rules across services. Use when benefit (consistency, performance) outweighs ops and versioning cost.\n\n**5. How to implement:**\n\n(1) Define the procedure with CREATE PROCEDURE name(IN p1 type, IN p2 type) BEGIN ... END; use variables (DECLARE, SET) and conditionals (IF/ELSE) if needed. (2) Wrap multi-step logic in a transaction: BEGIN; your INSERT/UPDATE statements; COMMIT; (and handle errors with ROLLBACK if your DB supports it in procedures). (3) Call from the application via the driver: e.g. connection.execute('CALL place_order(?, ?, ?)', [userId, productId, qty]). (4) Document parameters and behavior; version procedures in migrations like schema changes. See code below.\n\n**6. Logic & how the code works:**\n\nplace_order(p_user_id, p_product_id, p_qty): Parameter IN = input. INSERT INTO orders: create a new order row. UPDATE products: decrease stock by qty. Both statements in one procedure = one round-trip to the DB. For atomicity: wrap with BEGIN; ... COMMIT; or ROLLBACK on error. All clients call CALL place_order(?,?,?); logic and transaction in one place.\n\n**7. Example problem & solution:**\n\nProblem: Create order and deduct stock atomically from multiple clients. Solution: Stored procedure place_order. INSERT orders + UPDATE stock in one transaction. Client calls CALL place_order(user_id, product_id, qty).\n\n**8. Additional information:**\n\nDocument procedures and version them (migrations). Consider idempotency for retries. Connection pooling (e.g. PgBouncer, app pool) limits connections and improves throughput.",
          codeExample:
            "CREATE PROCEDURE place_order(\n  IN p_user_id INT, IN p_product_id INT, IN p_qty INT\n)\nBEGIN\n  INSERT INTO orders (user_id, product_id, qty)\n  VALUES (p_user_id, p_product_id, p_qty);\n  UPDATE products SET stock = stock - p_qty\n  WHERE id = p_product_id;\nEND;\n-- Call: CALL place_order(1, 5, 2);",
          codeLanguage: "sql",
        },
      ],
    },
    {
      title: "Computer Science Theory",
      slug: "cs-theory",
      description:
        "Core software design: four pillars of OOP (encapsulation, inheritance, polymorphism, abstraction), SOLID principles, DRY/KISS/YAGNI, common design patterns (Factory, Singleton, Strategy, Observer), monolith vs microservices and layered design, when to use which data structure, clean code and refactoring, and discrete math and probability for CS. Before you start: one programming language and basic experience writing classes and functions; Competitive Programming helps for data structures.",
      order: 5,
      published: true,
      items: [
        {
          title: "OOP",
          description: "Encapsulation, inheritance, polymorphism, abstraction",
          order: 0,
          imageUrl:
            "https://placehold.co/800x400/4f46e5/white?text=OOP+4+Pillars",
          content:
            "**1. Learning flow:**\n\n(1) Read material and the four pillars so you know what each means and when to use it: encapsulation (hide data, expose behavior), inheritance (reuse and extend), polymorphism (same interface, different behavior), abstraction (contracts via interfaces). (2) Design a small system (e.g. shapes with area/perimeter or vehicles with move()) using all four: private fields and public methods (encapsulation), a base class and subclasses (inheritance), code that calls methods on the base type and gets the right implementation (polymorphism), and an interface or abstract class that defines the contract (abstraction). (3) Implement it in code; then refactor so that the code that uses shapes depends on an interface (e.g. Shape) not on concrete Circle or Rectangle—so adding a new shape does not require changing that code. (4) Explain to a peer when you would use each pillar so you solidify the concepts.\n\n**2. Material:**\n\n**OOP (object-oriented programming)** means organizing code around objects that bundle data (fields) and behavior (methods). The four pillars guide how to design classes and their relationships.\n\n**Encapsulation:** Hide the internal state (fields) and expose only what is needed through methods (getters, setters, or higher-level operations). That way the class can enforce invariants (e.g. radius must be positive) and change its internal representation without breaking callers. Avoid public fields; use private (or protected) and methods for access.\n\n**Inheritance:** A subclass extends a superclass and reuses its code (is-a relationship). The subclass can override methods to change or extend behavior. Use when there is a clear hierarchical relationship (e.g. Dog and Cat extend Animal). Avoid very deep inheritance trees (prefer composition or shallow hierarchies) and inheritance just to reuse code when composition would be clearer.\n\n**Polymorphism:** The same interface (e.g. method name) can have different implementations in different classes. Code that works with the base type (e.g. Shape) automatically works with any subtype (Circle, Rectangle) because the runtime chooses the correct implementation (dynamic dispatch). That lets you add new types without changing existing code that uses the interface.\n\n**Abstraction:** Focus on what an object does (its contract), not how it does it. Interfaces and abstract classes define that contract: a list of methods that implementers must provide. Callers depend on the abstraction, so you can swap implementations (e.g. different payment providers) without changing the caller.\n\n**3. Explanation:**\n\nEncapsulation protects invariants because the only way to change state is through methods that can validate input. Inheritance should model real is-a relationships; if you find yourself overriding everything or forcing a square peg into a round hole, composition may be better. Polymorphism lets you code against abstractions so new implementations (e.g. a new shape, a new payment method) plug in by implementing the interface; the existing code does not need to change (Open/Closed principle). Abstraction hides implementation details so callers are not coupled to concrete classes and you can test or swap implementations easily.\n\n**4. Application:**\n\nDomain modeling (entities like User, Order with their behavior). Frameworks (you override hooks or extend base classes). Plugins (each plugin implements an interface the framework calls). Use OOP when the problem has clear entities and behavior that belong together; use interfaces so the system stays open for extension. In interviews, you may be asked to design a small system (e.g. parking lot, shapes) using these concepts.\n\n**5. How to implement:**\n\n(1) Define classes with private fields and public methods that operate on that data; avoid exposing fields directly so you can enforce rules (e.g. setRadius checks r > 0). (2) Use extends for inheritance when you have a clear is-a relationship; override methods in the subclass to customize behavior; call super() when you need the parent's behavior. (3) Program to interfaces: declare variables and parameters as the interface type (e.g. List, Shape) not the concrete type (ArrayList, Circle) so you can pass any implementation. (4) Extract an interface (or abstract class) for key behaviors (e.g. area(), perimeter()); have each concrete class implement it so callers depend on the interface. (5) See the code below for a full Shape example with Circle and Rectangle.\n\n**6. Logic & how the code works:**\n\nShape interface: Contract for area() and perimeter(). Circle and Rectangle implement Shape; each has a different implementation (polymorphism). calculateTotalArea(Shape[] shapes): Loop and call s.area()—runtime chooses the correct implementation (dynamic dispatch). Encapsulation: radius and width/height are private; access via getter. Adding a new shape = add a new class; do not change code that uses Shape (Open/Closed).\n\n**7. Example problem & solution:**\n\nProblem: Model shapes (area, perimeter). Solution: Interface Shape with area() and perimeter(). Classes Circle, Rectangle implement Shape. Code that accepts Shape[] works for any implementation. Adding a new shape = add a class; do not change existing code.\n\n**8. Additional information:**\n\nComposition over inheritance when behavior can be composed (e.g. a Car has an Engine, not extends Engine). Prefer shallow hierarchies. Design Patterns (Gang of Four) for common OOP solutions. Practice: Refactor one class to use an interface; explain encapsulation and polymorphism in your own words.",
          codeExample:
            "// OOP: Shape interface + polymorphism\ninterface Shape { double area(); double perimeter(); }\nclass Circle implements Shape {\n  private double r;\n  Circle(double r) { this.r = r; }\n  double area() { return Math.PI * r * r; }\n  double perimeter() { return 2 * Math.PI * r; }\n}\nclass Rectangle implements Shape {\n  private double w, h;\n  Rectangle(double w, double h) { this.w = w; this.h = h; }\n  double area() { return w * h; }\n  double perimeter() { return 2 * (w + h); }\n}\n// Polymorphism: s.area() chooses implementation at runtime\ndouble totalArea(Shape[] shapes) {\n  double sum = 0;\n  for (Shape s : shapes) sum += s.area();\n  return sum;\n}",
          codeLanguage: "java",
        },
        {
          title: "SOLID Principles",
          description:
            "Single responsibility, Open/Closed, Liskov, Interface segregation, Dependency inversion",
          order: 1,
          imageUrl:
            "https://placehold.co/800x400/7c3aed/white?text=SOLID+Principles",
          content:
            '**1. Learning flow:**\n\n(1) Read the material below and each of the five SOLID principles in turn: Single Responsibility (one reason to change per class), Open/Closed (extend via new code, avoid modifying working code), Liskov Substitution (subtypes must be usable wherever the base type is used), Interface Segregation (small, focused interfaces), and Dependency Inversion (depend on abstractions and inject implementations) so you can name and apply them in design and refactoring. (2) In your next feature or code review, consciously name which SOLID principle you are applying (e.g. "I\'m splitting this class for SRP" or "We depend on an interface here for DIP") so the vocabulary becomes natural. (3) Refactor one class to satisfy Single Responsibility (split a class that does two things into two classes) and one module to depend on an interface instead of a concrete class (Dependency Inversion) so high-level code does not depend on low-level details and you can test with mocks. (4) Review an existing codebase for Open/Closed (can you add a new variant without changing existing code?) and Liskov Substitution (can you pass any subtype where the base type is expected without the caller breaking?) so you see where SOLID is followed or violated.\n\n**2. Material:**\n\nSOLID is five principles that guide object-oriented design so that code stays maintainable, testable, and easy to extend.\n\n**S — Single Responsibility:** A class should have only one reason to change. If one class both parses input and sends reports, then a change to the report format or to the parsing logic forces you to touch the same file. Splitting into a Parser class and a Sender class gives each a single responsibility.\n\n**O — Open/Closed:** Software should be open for extension (you can add new behavior via new classes or plugins) but closed for modification (you avoid changing existing, working code). For example, instead of adding if/else for each new payment type, you add a new class that implements PaymentStrategy; the checkout code does not change.\n\n**L — Liskov Substitution:** Subtypes must be usable wherever the base type is used, without breaking callers. If a function expects a Shape, passing a Circle or Rectangle should not require the caller to know the concrete type or to add special cases. Subclasses must not weaken preconditions or strengthen postconditions.\n\n**I — Interface Segregation:** Prefer many small, focused interfaces over one large interface. Clients should not depend on methods they do not use. If a class needs only save(), do not force it to implement delete() and list(); split into smaller interfaces.\n\n**D — Dependency Inversion:** High-level modules should not depend on low-level modules; both should depend on abstractions (e.g. interfaces). Depend on interfaces, not concrete classes; inject the implementation (via constructor or setter) so you can swap or mock it in tests.\n\n**3. Explanation:**\n\nSRP reduces coupling: when one class has one job, changes are local and tests are focused. Open/Closed lets you add features (new payment type, new export format) by adding new code, not by editing existing code, which reduces regression risk. Liskov Substitution ensures that polymorphism is safe: code that works with the base type works with any subtype. Interface Segregation keeps interfaces small so implementers and callers are not burdened with unused methods. Dependency Inversion makes high-level logic independent of concrete details (e.g. which database or which payment gateway), so you can test with mocks and swap implementations without changing the core logic.\n\n**4. Application:**\n\nEvery feature and refactor: ask which principle applies. Use DIP for tests (mock interfaces). Use O/C when adding new formats or strategies.\n\n**5. How to implement:**\n\n(1) Single Responsibility: Identify classes that do more than one thing (e.g. parse + send); split into separate classes (e.g. Parser and Sender) so each has one reason to change. (2) Open/Closed: When adding a new variant (e.g. new payment type), add a new class that implements the existing interface instead of editing the caller with if/else; the caller depends on the interface and receives the new implementation at runtime. (3) Liskov Substitution: When writing or refactoring subclasses, ensure they honor the contract of the base type (no weaker preconditions, no stronger postconditions); test by passing a subtype where the base is expected and verifying behavior. (4) Interface Segregation: If a class implements an interface with methods it does not use, split the interface into smaller ones (e.g. Readable and Writable) so clients depend only on what they need. (5) Dependency Inversion: In high-level modules, depend on abstractions (interfaces); receive the concrete implementation via constructor or setter (dependency injection) so you can swap or mock in tests. Do not instantiate concrete DB or HTTP clients inside the service; inject them.\n\n**6. Logic & how the code works:**\n\nSingle Responsibility works because each class has one job: the Parser only knows how to parse, the Sender only knows how to send. When the report format changes, you change only the Parser; when the delivery mechanism changes (e.g. add FTP), you change only the Sender. That way, changes do not ripple into unrelated code and tests can target one behavior at a time.\n\nDependency Inversion works by inverting the usual direction of dependency: instead of the high-level ReportService importing and calling EmailSender directly, the ReportService depends on an interface (e.g. ReportSender). The caller (e.g. main or a factory) creates the concrete EmailSender or FileSender and passes it in. So ReportService never mentions EmailSender; it only calls send(report) on the interface. That allows you to swap implementations (e.g. FileSender in tests, EmailSender in production) or mock the sender in unit tests without touching ReportService. The same idea applies to databases, HTTP clients, and any external dependency: depend on an abstraction, inject the concrete type.\n\n**7. Example problem & solution:**\n\nProblem: One class parses and sends reports; changes for parsing break sending. Solution: Apply SRP — separate Parser and Sender. Callers depend on interfaces (DIP); add new parser without changing Sender (O/C).\n\n**8. Additional information:**\n\nClean Architecture and Hexagonal Architecture apply SOLID at the module level. Use dependency injection containers when the graph is large.',
        },
        {
          title: "DRY, KISS, YAGNI",
          description:
            "Don't Repeat Yourself; Keep It Simple; You Aren't Gonna Need It—three practical principles for maintainable code",
          order: 2,
          imageUrl:
            "https://placehold.co/800x400/0d9488/white?text=DRY+KISS+YAGNI",
          content:
            '**1. Learning flow:**\n\n(1) Read the material below so you understand DRY (one source of truth for logic and data—extract repeated blocks into a function or constant), KISS (prefer the simplest correct solution and avoid unnecessary abstraction), and YAGNI (do not add features or flexibility for hypothetical future needs; refactor when a second real use case appears). (2) In your next coding task, consciously name one place you applied DRY (e.g. extracted a validation function used in three endpoints) and one where you avoided adding something for YAGNI (e.g. skipped an optional parameter that had no current requirement). (3) Simplify one piece of code using KISS: replace a clever or over-engineered solution with a straightforward loop or condition that does the same thing and is easier to read. (4) Find one repeated block (same logic in two or more places), extract it into a function or shared constant, and replace all copies so one future change updates every call site.\n\n**2. Material:**\n\n**DRY (Don\'t Repeat Yourself):** If the same logic or the same data appears in more than one place, you have duplication. When the rule or data changes, you must remember to update every copy; if you miss one, you get bugs and inconsistency. The remedy is to extract the logic into a single function, constant, or module and reuse it everywhere. Then one change updates all call sites. Note: duplicate by coincidence (two similar-looking blocks that do different things) may be fine until you need to change both; then consider abstracting. The "rule of three" says consider abstracting when you have three similar pieces, not at two.\n\n**KISS (Keep It Simple, Stupid):** Prefer the simplest solution that correctly solves the problem. Avoid unnecessary layers, clever one-liners that are hard to read, and patterns applied "just in case." Simple code is easier to read, debug, and change. If you have a choice between a straightforward loop and a complex generic abstraction, start with the loop unless the abstraction clearly pays off.\n\n**YAGNI (You Aren\'t Gonna Need It):** Do not add features or abstractions for hypothetical future needs. Build only what the current requirement asks for; when a second, real requirement appears that would benefit from an abstraction, refactor then. Adding flexibility too early often results in the wrong abstraction (you guessed wrong about the future) and more code to maintain.\n\n**3. Explanation:**\n\nDRY reduces bugs because there is one source of truth: when a validation rule or a constant changes, you change it in one place and all callers get the update. KISS improves readability and speed of change because simple code has fewer branches and assumptions. YAGNI avoids wasted work: code you write for "maybe later" often never gets used or gets replaced when the real requirement turns out different; refactoring when the second use case appears gives you better information about what to abstract.\n\n**4. Application:**\n\nEvery codebase: remove duplication when it causes real coupling; keep code as simple as the requirements allow; add abstraction only when a second use case appears.\n\n**5. How to implement:**\n\n(1) DRY: Search for repeated logic or data (same validation, same constant, same 5-line block in two places); extract into a single function, constant, or module and use it everywhere so one change updates all call sites. (2) KISS: When you have two solutions—one simple (e.g. a loop) and one clever (e.g. a generic abstraction)—choose the simple one unless the abstraction clearly pays off; remove unnecessary layers and conditional branches. (3) YAGNI: For each new parameter, feature, or abstraction ask: "Is there a current requirement for this?" If it is only "might need later," skip it; add it when a second concrete use case appears and refactor then. (4) Rule of three: When you have three similar pieces, consider abstracting; with two, duplication may be acceptable until the third appears. (5) After refactoring run tests to ensure behavior is unchanged.\n\n**6. Logic & how the code works:**\n\nDRY works by centralizing logic: if validateRequest(req) is the only place that checks email format and password length, then when the product owner says "passwords must be 12 characters," you change one function and all three endpoints that call it automatically get the new rule. If instead each endpoint had its own copy of the checks, you would have to find and update all three, and it would be easy to miss one.\n\nKISS works because every extra branch, layer, or abstraction is a place where bugs can hide and where future changes must be applied. A straightforward if/else or a simple loop is easier to verify and modify than a chain of strategy objects when the requirement is simple. You can always refactor to a more structured design when complexity actually appears.\n\nYAGNI works because the future is uncertain. When you add a parameter "for future use" or a generic validator "in case we need it for another field," you are guessing. When the real second requirement arrives, it often differs slightly (e.g. different error messages or a different rule), and the abstraction you built does not fit well. Refactoring when you have two concrete use cases gives you the right abstraction and less dead code.\n\n**7. Example problem & solution:**\n\nProblem: Same validation in three endpoints. Solution: Extract validateRequest(req) and call it from each endpoint (DRY). Problem: Complex generic validator for one field. Solution: Use a simple check for now; generalize when a second field needs it (YAGNI).\n\n**8. Additional information:**\n\nDuplicate by coincidence is fine until you need to change both. Rule of three: consider abstracting when you have three similar pieces, not at two.',
        },
        {
          title: "Design Patterns",
          description:
            "Creational (Factory, Singleton), behavioral (Strategy, Observer), and when each pattern helps",
          order: 3,
          imageUrl:
            "https://placehold.co/800x400/ea580c/white?text=Design+Patterns",
          content:
            '**1. Learning flow:**\n\n(1) Read the material below and understand when each pattern helps: Factory when creation logic is complex or you want callers to depend on abstractions; Singleton sparingly when you truly need one instance (e.g. connection pool) but prefer dependency injection; Strategy when you have interchangeable algorithms (e.g. sort, payment method) and want to add new ones without changing the caller; Observer when one producer must notify many consumers without coupling. (2) Implement the Strategy example from the code: define an interface (e.g. SortStrategy with sort(arr)), implement it in two concrete classes (e.g. QuickSort and MergeSort), and write a caller that holds a reference to the interface and calls strategy.sort(arr) so you see how the behavior is swapped by passing a different object. (3) Identify one pattern in code you already use (e.g. Observer in React\'s state updates or event emitters, Factory in a library that creates connections or clients) so you connect the pattern name to real usage. (4) Apply Strategy to a real case (e.g. payment methods: Card, PayPal, BankTransfer) by defining a PaymentStrategy interface and implementing it for each method; the checkout code receives a strategy and calls pay(amount) so adding a new payment type is adding a new class, not editing the checkout logic.\n\n**2. Material:**\n\nDesign patterns are recurring solutions to common design problems. They give you a shared vocabulary and a proven structure, but use them only when they simplify your code—not for their own sake.\n\n**Factory:** A function or class that creates objects so that callers do not depend on concrete classes. The caller asks the factory for "a Sender" or "a Parser"; the factory decides whether to return EmailSender or FileSender. Use when creation logic is complex (e.g. different config or environment), when you want to swap implementations without changing callers, or when you need a single place to enforce creation rules.\n\n**Singleton:** Ensures only one instance of a class exists for the whole application (e.g. a database connection pool or a logger). Use sparingly: singletons can make testing hard (you cannot easily replace the instance with a mock) and can hide dependencies. Often dependency injection—passing the single instance in from the top—is a better choice.\n\n**Strategy:** Defines a family of interchangeable algorithms (e.g. different sort algorithms, payment methods, or validation rules). You define an interface (e.g. SortStrategy with sort(array)); each algorithm is a class that implements it. The caller holds a reference to the interface and receives the concrete strategy at runtime (e.g. QuickSort or MergeSort). Adding a new algorithm means adding a new class; the caller code does not change.\n\n**Observer:** One subject (or publisher) maintains a list of listeners (observers) and notifies them when its state changes. The subject does not need to know what the observers do; it just calls notify() or update(). This decouples the producer of events from the consumers. Event emitters, pub/sub systems, and React\'s state updates follow this idea.\n\n**3. Explanation:**\n\nStrategy lets you swap algorithms without changing the code that uses them: the same checkout flow can run with CardPayment or PayPalPayment by passing a different strategy object. Observer decouples producers from consumers: the button that fires "click" does not know whether a logger, an analytics module, or a modal is listening. Factory centralizes creation so callers depend on abstractions and you can change or mock the created objects in one place. Use patterns when the problem clearly fits; avoid introducing a pattern where a simple function or a direct call would be clearer.\n\n**4. Application:**\n\nStrategy: sort algorithms, payment methods, validation rules. Observer: React state, event emitters, pub/sub. Factory: DB connection, config loaders. Singleton: logger, connection pool (use with care).\n\n**5. How to implement:**\n\n(1) Strategy: Define an interface for the behavior (e.g. SortStrategy with sort(arr)); implement it in concrete classes (QuickSort, MergeSort); the caller holds a reference to the interface and receives the concrete strategy at construction or from a factory so it never branches on type—just calls strategy.sort(arr). (2) Observer: The subject maintains a list of listeners (callbacks or observer objects); when an event occurs the subject calls notify() or update() on each listener; listeners register (add themselves) and unregister when done. (3) Factory: Create a function or class that returns the appropriate implementation based on config or input so callers depend on the abstraction (e.g. getSender()) not on concrete classes. (4) Singleton (use sparingly): Ensure one instance (e.g. static getInstance()); prefer injecting that single instance from the top so tests can replace it. See code below.\n\n**6. Logic & how the code works:**\n\nStrategy works by polymorphism: the caller\'s code talks only to the interface (e.g. SortStrategy). At runtime, someone (e.g. a factory or configuration) provides a concrete implementation (QuickSort or MergeSort). When the caller invokes s.sort(arr), the actual implementation that runs depends on which object was passed in. So you never write "if (type === \'quick\') quickSort(arr); else if (type === \'merge\') mergeSort(arr);"—you just have s.sort(arr) and the strategy object determines the behavior. Adding a new algorithm is adding a new class and wiring it in; no change to the caller.\n\nObserver works by maintaining a list of callbacks (or listener objects) in the subject. When something meaningful happens (e.g. the user clicks, or data is loaded), the subject iterates over the list and calls each listener\'s update method (or the callback). The subject does not know or care what each listener does—it might log, send analytics, update the UI, or trigger another action. That way, you can add or remove listeners without changing the subject, and the subject stays focused on its core logic (e.g. "button was clicked") instead of knowing about every possible reaction. This one-to-many, decoupled notification is why event emitters and pub/sub are so common.\n\n**7. Example problem & solution:**\n\nProblem: App supports Card, PayPal, and Bank transfer. Solution: Strategy. Interface PaymentStrategy { pay(amount: number): boolean; }. Classes CardPayment, PayPalPayment implement it. Checkout receives PaymentStrategy; calls pay(amount). Add new payment = add new class, no change to Checkout.\n\n**8. Additional information:**\n\nOthers: Adapter (wrap incompatible interface), Decorator (add behavior without subclassing), Command (encapsulate request as object). Learn one at a time and apply when the problem fits. Gang of Four book for full catalog.',
          codeExample:
            "// Strategy: interchangeable sort algorithms\ninterface SortStrategy { sort(arr: number[]): number[]; }\nclass QuickSort implements SortStrategy { sort(arr) { /* ... */ return arr; } }\nclass MergeSort implements SortStrategy { sort(arr) { /* ... */ return arr; } }\nlet s: SortStrategy = new QuickSort(); s.sort([3,1,2]);",
          codeLanguage: "typescript",
        },
        {
          title: "Software Architecture",
          description:
            "Monolith vs microservices trade-offs; layered architecture (API, service, data); modular design within a codebase",
          order: 4,
          imageUrl:
            "https://placehold.co/800x400/dc2626/white?text=Architecture+Patterns",
          content:
            '**1. Learning flow:**\n\n(1) Read material and trade-offs. (2) Draw a layered diagram of a small app; label API, service, and data layers. (3) Compare monolith vs microservices for a scenario. (4) Identify modules in an existing codebase.\n\n**2. Material:**\n\nArchitecture is how you split and organize code and services. Your choices depend on team size, how much you need to scale, and whether you need to deploy parts of the system independently.\n\n**Monolith:** One codebase and one deployable artifact. All features (user, order, payment, etc.) live in the same process. Pros: simpler to develop (one repo, one deploy, one place to debug), no network hops between "modules," transactions are straightforward. Cons: as the codebase grows it can become hard to navigate; scaling means scaling the whole app; one bug can bring down everything. Mitigate by using clear layers and modules inside the monolith so the code is organized even if deployment is not split. Good for small teams and early-stage products.\n\n**Microservices:** The system is split into many small services, each owning a bounded domain (e.g. user service, order service, notification service). Each service has its own codebase, deployment, and often its own database. Pros: teams can own services and deploy independently; you can scale one service (e.g. the one under load) without scaling others. Cons: distributed complexity (network failures, latency, debugging across services), eventual consistency when data spans services, and more operational overhead (monitoring, deployment pipelines, service discovery). Use when you have clear domain boundaries and a real need for independent scaling or team autonomy.\n\n**Layered architecture:** Within one application (monolith or a single service), organize code into layers. Presentation layer: API handlers (HTTP, REST) or UI components—they only parse input and format output. Business layer: services or use cases that contain the core logic (e.g. create order, validate payment). Data layer: repositories or data access that talk to the database. Dependencies point inward: presentation depends on business, business depends on data; data does not depend on business or presentation. That way you can test business logic without HTTP or a real database, and you can swap the data layer (e.g. different DB) without touching business rules.\n\n**Modular design:** Within one codebase, split by feature or domain (e.g. user module, order module, payment module). Each module has a clear boundary: it exposes a small public API and keeps implementation details private. Minimize cross-module coupling: modules should not depend on each other\'s internals. This keeps the monolith maintainable and makes it easier to extract a module into a microservice later if needed.\n\n**3. Explanation:**\n\nA monolith is simpler to run and reason about until the team or the scale makes it painful (e.g. too many people touching the same repo, or one part needs to scale differently). Microservices trade that simplicity for flexibility and independence, but you pay with distributed systems problems (network, consistency, ops). Layered and modular design give you structure inside any deployment unit: even in a monolith, handlers only parse and call services, services contain logic and use repositories, and modules keep features from tangling. That way you get testability and clarity without necessarily splitting into many services.\n\n**4. Application:**\n\nStart with monolith and clear layers; split to microservices when boundaries and scaling justify it. Use modular design within any deployment unit.\n\n**5. How to implement:**\n\n(1) Define layers: Create folders or modules for routes (or API handlers), services (business logic), and repositories (data access); API handlers only parse request and call a service method; services contain rules and call repositories; repositories run SQL or use an ORM. (2) Dependencies point inward: Routes depend on services; services depend on repositories; repositories do not depend on services or routes so you can test services with mock repositories. (3) Split by feature: Within each layer, group by domain (e.g. user/, order/, payment/) so each feature has its own handlers, services, and repositories with minimal cross-module coupling. (4) Document with a simple C4 or box-and-arrow diagram showing clients, app, DB, and optionally cache or queue. (5) For microservices, extract one bounded context at a time and define clear API or events between services. See code below.\n\n**6. Logic & how the code works:**\n\nThe handler (e.g. in routes/users.js) receives the HTTP request and extracts parameters (req.params.id, req.body). It does not contain business logic; it only calls a service method (e.g. userService.getById(id)) and returns the result as JSON. The service (e.g. userService.js) contains the business rules: it may validate input, apply logic, and call a repository to load or save data. The repository (e.g. userRepository.js) knows how to talk to the database: it runs the SQL or uses an ORM. So when you unit-test the service, you mock the repository and never touch HTTP or the real DB. When you change how data is stored (e.g. switch from MySQL to PostgreSQL), you change only the repository; the service and handlers stay the same. A monolith is one deployable; this layered structure keeps it organized and testable. Microservices take the same idea but split by service: each service has its own layers inside, and they communicate over the network (with the added complexity of failures and consistency).\n\n**7. Example problem & solution:**\n\nProblem: All logic in API handlers. Solution: Extract service layer (e.g. OrderService.createOrder); handlers only parse request and call service. Add repository layer for DB access. Now business logic is testable without HTTP.\n\n**8. Additional information:** C4 model, Hexagonal Architecture. When splitting to microservices, define contracts (API, events) and ownership. Prefer monolith until you feel the pain.',
          codeExample:
            "// Layered architecture: API -> Service -> Repository\n// routes/users.js\napp.get('/users/:id', (req, res) => {\n  const user = userService.getById(req.params.id);\n  res.json(user);\n});\n// services/userService.js\nconst user = userRepository.findById(id);\n// repositories/userRepository.js\ndb.query('SELECT * FROM users WHERE id = ?', [id]);",
          codeLanguage: "javascript",
        },
        {
          title: "Data Structures",
          description:
            "Array, linked list, stack, queue, hash map, heap, tree, graph—operations, complexity, and when to use which",
          order: 5,
          imageUrl:
            "https://placehold.co/800x400/16a34a/white?text=Data+Structures",
          content:
            '**1. Learning flow:**\n\n(1) Read material and complexity. (2) For "find top K frequent elements" and "shortest path in unweighted graph," name the best structure and why. (3) Implement a small stack and queue; use a hash map for a lookup. (4) Review when to use heap vs sorted structure.\n\n**2. Material:**\n\nChoose the data structure that matches how you access and update data: random access by index, sequential order, lookup by key, priority (smallest or largest first), hierarchy (parent-child), or relationships (nodes and edges).\n\n**Array:** O(1) access by index; fixed or dynamic size. Good for contiguous data, iteration in order, and when you need index-based access. No fast search by value (linear scan) unless sorted.\n\n**Linked list:** O(1) insert/delete at head or when you have a pointer to the node; no random access by index (must traverse). Good for queues (enqueue at tail, dequeue at head), and when you frequently insert or remove in the middle without shifting the rest.\n\n**Stack:** LIFO (last in, first out); push and pop in O(1). Use for undo stacks, parenthesis or bracket matching, and depth-first search (DFS) where you backtrack.\n\n**Queue:** FIFO (first in, first out); enqueue and dequeue in O(1). Use for breadth-first search (BFS), task queues, and any "fair" ordering where the first request is processed first.\n\n**Hash map (dictionary):** O(1) average get and put by key; no inherent order. Use for lookups ("is this key present?"), counting (key → count), and storing key-value data when order does not matter.\n\n**Heap (priority queue):** O(log n) insert and O(log n) extract-min (or extract-max). The smallest (or largest) element is always at the root. Use for priority queues, top-K problems (keep a min-heap of size K), and Dijkstra\'s algorithm.\n\n**Tree:** Hierarchical structure. A binary search tree (BST) gives O(log n) search, insert, and delete when balanced. Use for sorted data, range queries, and when the problem has a natural hierarchy (e.g. file system, org chart).\n\n**Graph:** Nodes and edges; models relationships (social network, dependencies, map). Represent with an adjacency list (list of neighbors per node) or an adjacency matrix. Use for shortest path, connected components, and any "network" or "relationship" problem.\n\n**3. Explanation:**\n\nArrays and hash maps cover most day-to-day needs (lists and lookups). Stacks and queues encode order of operations (LIFO vs FIFO). Heaps give you "best" element quickly without fully sorting. Trees give hierarchy and ordered access; graphs model arbitrary relationships. In interviews and in code, naming the right structure and its complexity (e.g. "hash map for O(1) lookup") shows you understand the trade-offs.\n\n**4. Application:**\n\nInterviews: identify access pattern and name the structure. In code: choose from standard library (list, dict, heap, etc.) by operation cost.\n\n**5. How to implement:**\n\n(1) For lists and lookups use your language primitives: array/list for indexed access and iteration, dict/map for O(1) lookup by key, set for uniqueness and membership. (2) For FIFO/LIFO use queue (collections.deque, Queue) or stack (array push/pop or deque); for priority use priority_queue (C++), heapq (Python), or PriorityQueue (Java). (3) For trees use node structures (left/right or children list) or a library; for graphs use adjacency list (e.g. map from node to list of neighbors) or adjacency matrix when dense. (4) When solving a problem, name the access pattern first (e.g. "need to look up by id" → hash map; "need smallest each time" → heap; "need shortest path unweighted" → BFS with queue). (5) See Competitive Programming and CS Theory sections for full implementations (e.g. segment tree, Dijkstra).\n\n**6. Logic & how the code works:**\n\nFor top K frequent elements: first, use a hash map to count how many times each element appears in one pass over the array. Then you need the K keys with the largest counts. One approach is to keep a min-heap of size K: you iterate over the (element, count) pairs; for each pair you push it into the heap, and if the heap size exceeds K you pop the smallest (by count). The heap always keeps the K largest counts seen so far; at the end, the root is the K-th largest by frequency, and the heap contains the top K. So you get the answer in O(n log K) time. Another approach is bucket sort by frequency: buckets[i] = list of elements with frequency i; then scan from the highest bucket down until you have K elements.\n\nFor shortest path in an unweighted graph: BFS explores the graph layer by layer (all nodes at distance 1, then all at distance 2, and so on). You use a queue: start with the source in the queue; repeatedly dequeue a node and enqueue its unvisited neighbors, and mark them as visited with distance = current + 1. The first time you reach a node, you have found a shortest path to it, because BFS explores in increasing order of distance. The queue ensures you process nodes in the correct order (level by level).\n\n**7. Example problem & solution:**\n\nProblem: Find top K frequent elements. Solution: Hash map to count; then min-heap of size K (keep K largest by frequency). Or bucket sort by frequency. Problem: Shortest path unweighted. Solution: BFS with queue; graph as adjacency list.\n\n**8. Additional information:** Big O cheat sheet. Balanced BST gives O(log n) insert/delete/search; heap gives O(log n) insert/extract-min but no arbitrary lookup. Trie for string prefix. Interview tip: Name structure and complexity before coding; justify choice ("Hash map for O(1) lookup" vs "Array for O(1) index"). Real case: LRU cache = hash map (key→node) + doubly linked list (order); get O(1), put O(1).',
          codeExample:
            "# Top K frequent: dict + heap (Python)\nfrom collections import Counter\nimport heapq\ndef top_k_frequent(nums, k):\n  count = Counter(nums)\n  return heapq.nlargest(k, count.keys(), key=count.get)\n# Or: min-heap of size k\nheap = []\nfor num, freq in count.items():\n  heapq.heappush(heap, (freq, num))\n  if len(heap) > k: heapq.heappop(heap)\nreturn [x[1] for x in heap]",
          codeLanguage: "python",
        },
        {
          title: "Clean Code",
          description:
            "Meaningful names, small functions, useful comments, consistent formatting; refactoring steps",
          order: 6,
          imageUrl: "https://placehold.co/800x400/059669/white?text=Clean+Code",
          content:
            '**1. Learning flow:**\n\n(1) Read the material below so you understand why clean code matters: code is read more often than it is written, so names and structure should make intent obvious and the next developer (or you in six months) should be able to understand and change it safely. (2) Pick one function in a project you work on: rename one variable to be more descriptive (e.g. x → pendingRequestCount), and extract one small logical block into a well-named function so the main flow is easier to follow. (3) Run tests after each change so you never leave the codebase broken; refactor in small steps and keep the tests green. (4) Add or improve one comment that explains why something is done (e.g. "Retry up to 3 times because the API can be flaky") rather than restating what the code does (e.g. "Loop 3 times").\n\n**2. Material:**\n\nCode is read more often than it is written; names and structure should make intent obvious so that the next developer (or you in six months) can understand and change it safely. Refactor in small steps and keep tests green so you never leave the codebase broken.\n\n**Names:** Use descriptive names for variables, functions, and classes so that reading the name tells you what the thing is or does. Avoid single letters except for loop indices (i, j) or very local, obvious contexts. For booleans, names that read well in conditionals help: isValid, hasPermission, canEdit. Constants are often UPPER_SNAKE_CASE to distinguish them from variables. Avoid abbreviations unless they are universal (e.g. id, url); prefer full words when in doubt.\n\n**Functions:** Each function should do one thing and do it well; keep functions small (a few lines to a screen). Prefer few parameters; if you need many, consider passing an object or breaking the function. If the name suggests a query (e.g. getTotal(), isValid()), the function should not have side effects like modifying state or sending a request; callers assume "get" is safe to call repeatedly.\n\n**Comments:** Comments should explain why something is done, not what the code does (the code itself should show what). Keep comments in sync with the code or remove them; stale comments mislead. Prefer deleting commented-out code; version control keeps history if you need it.\n\n**Formatting:** Use consistent indentation, spacing, and naming style; a formatter (Prettier, Black, etc.) automates this. Use blank lines to separate logical blocks. Keep related code close together so the reader does not have to jump around.\n\n**Refactoring:** Refactoring means changing the structure of the code without changing its behavior. Do it in small steps (rename one variable, extract one function) and run tests after each step. That way you can stop at any time with a working codebase. When you touch an area, take the chance to fix obvious tech debt (rename, extract duplication) so the code improves over time.\n\n**3. Explanation:**\n\nGood names act as documentation: getTotalRevenue() and isEligibleForDiscount() tell you what the code does without reading the body. Small, single-purpose functions are easier to test (one behavior per test), easier to reuse, and easier to change. Refactoring in small steps keeps the code working at every step and makes it safe to improve the design incrementally.\n\n**4. Application:**\n\nEvery commit: leave code cleaner than you found it. Before adding a feature, refactor so the change fits naturally.\n\n**5. How to implement:**\n\n(1) Rename: Use your IDE rename refactor (F2 or right-click Rename) so all references update; choose a name that reveals intent (e.g. getTotalRevenue instead of getData). (2) Extract function: Select a block of code that does one thing, extract it into a function named by what it does (e.g. validateEmail, formatCurrency); pass needed parameters and return the result so the original site becomes a single call. (3) Remove dead code and commented-out blocks; rely on version control for history. (4) Add or fix comments only when they explain why (e.g. "Cache for 5 min to avoid rate limit"), not what the code does. (5) Use a formatter (Prettier, Black, gofmt) and run it so formatting is consistent. (6) After each small change run tests so refactoring does not break behavior.\n\n**6. Logic & how the code works:**\n\nGood names work as live documentation: when you see a function named getTotalRevenue() or a variable named eligibleDiscountPercent, you understand intent without reading the implementation. That reduces the need for comments and makes bugs easier to spot (e.g. if the name says "total" but the code returns an average). Small functions work because each one has one responsibility: when a requirement changes (e.g. "exclude refunded orders from total"), you know which function to change, and you can write a unit test that targets just that behavior. Refactoring in small steps works because you never introduce a big, untested change: you rename one thing, run tests; extract one block into a function, run tests; move one block, run tests. So the code stays green and you can pause at any moment with a cleaner design and no regressions.\n\n**7. Example problem & solution:**\n\nProblem: Function does three things and is 50 lines. Solution: Extract each logical block into a function with a descriptive name. Main function becomes a short sequence of calls. Each extracted function is easier to test.\n\n**8. Additional information:** Clean Code (Robert Martin). Boy Scout rule. Code review checklist: names, length, duplication.',
          codeExample:
            "// Before: unclear, does 3 things\nfunction p(d) { let r = 0; for (let i = 0; i < d.length; i++) r += d[i].v; return r / d.length; }\n// After: extract, rename\ndata.reduce((sum, x) => sum + x.value, 0) / data.length\n// Or: const avgValue = items => items.reduce((s, x) => s + x.value, 0) / items.length;",
          codeLanguage: "javascript",
        },
        {
          title: "Discrete Math & Probability",
          description:
            "Sets, propositional logic, counting (permutations, combinations); basic probability for algorithms and ML",
          order: 7,
          imageUrl:
            "https://placehold.co/800x400/4338ca/white?text=Sets+Logic+Counting+Probability",
          content:
            '**1. Learning flow:**\n\n(1) Read the material below so you understand sets (union, intersection, difference; hash sets in code for membership and uniqueness), propositional logic (AND, OR, NOT, implications; how conditions in code combine), counting (permutations, combinations, n choose k), and basic probability (probability of an event, independence, P(at least one success)). (2) Compute by hand how many ways there are to choose 2 items from 5 (answer: C(5,2) = 10) and write the formula for P(at least one success in n independent trials) when each trial has success probability p (answer: 1 - (1-p)^n). (3) Apply sets and logic to a simple condition in code: e.g. express "user has role Admin or (has role Editor and resource is owned by user)" using boolean variables and AND/OR so you see how logic translates to readable conditions. (4) Use the n-choose-k formula (or a small program) in a probability calculation—e.g. how many ways to get exactly 3 heads in 5 coin flips—so you practice connecting counting to probability.\n\n**2. Material:**\n\nSets, logic, counting, and probability are the mathematical foundations for data structures, conditions in code, and many algorithms and ML concepts.\n\n**Sets:** A set is an unordered collection of distinct elements (no duplicates). Union A ∪ B: all elements in A or B. Intersection A ∩ B: elements in both. Difference A \\ B: elements in A but not in B. In code, hash sets (Set in JavaScript/Java, set in Python) implement membership in O(1) average and enforce uniqueness. They are used whenever you need "has this been seen?" or "unique list of items."\n\n**Logic:** Propositional logic deals with statements that are true or false and how they combine. AND (conjunction): both must be true. OR (disjunction): at least one true. NOT (negation): flip the value. Implication (if A then B): false only when A is true and B is false. Truth tables list all combinations of inputs and the result. De Morgan\'s laws: NOT(A AND B) = (NOT A) OR (NOT B), and NOT(A OR B) = (NOT A) AND (NOT B). These help simplify conditions in code and reason about predicates (e.g. when is a condition false?).\n\n**Counting:** Permutations: the number of ways to arrange n distinct items in a row is n! (n factorial). Combinations: the number of ways to choose k items from n without regard to order is "n choose k," written C(n,k) or (n choose k), and equals n! / (k!(n-k)!). You use this when order does not matter (e.g. choosing a committee of 3 from 10 people). These counts appear in probability (e.g. how many ways can 5 heads occur in 10 coin flips?) and in analyzing algorithm outcomes (e.g. how many subsets of size k?).\n\n**Probability:** Probability P(A) of an event A is a number between 0 and 1. P(A and B) is the probability both occur; for independent events P(A and B) = P(A)·P(B). P(A or B) = P(A) + P(B) - P(A and B). Conditional probability P(A|B) = P(A and B) / P(B): the probability of A given that B happened. Bayes\' rule: P(A|B) = P(B|A)·P(A) / P(B); it updates belief in A after observing B. Expected value E[X] is the long-run average of a random variable. These concepts appear in randomized algorithms (expected running time), hashing (collision probability), and ML (naive Bayes classifier, loss functions, sampling).\n\n**3. Explanation:**\n\nSets give you the model for unordered unique collections; hash sets in code are the practical implementation. Logic gives you the rules for combining conditions (and for simplifying and debugging complex if/else). Combinations count subsets and arrangements; when you need "how many ways" or "probability of k successes in n trials," you use these formulas. Probability ties counting to real-world uncertainty and to ML (e.g. Bayes for classification, expectation for evaluating algorithms).\n\n**4. Application:**\n\nHash sets, boolean logic, combinatorics in algorithms, probability in ML (Bayes, expectation), randomized algorithms.\n\n**5. How to implement:**\n\n(1) Sets: Use the set type (Set in JS/Java, set in Python) for membership and uniqueness; add, delete, has; union/intersection/difference when needed. (2) Logic: Express conditions with AND, OR, NOT; simplify with De Morgan (not(A and B) = (not A) or (not B)); use truth tables to check equivalence when in doubt. (3) Combinations: Implement n choose k as factorial(n)/(factorial(k)*factorial(n-k)) or with a loop using C(n,k)=C(n-1,k-1)+C(n-1,k); watch overflow for large n (use BigInt or iterative formula). (4) P(at least one success in n trials): 1 - (1-p)^n; use when you need probability of at least one hit in n independent trials with success probability p. (5) Bayes: P(A|B) = P(B|A)*P(A)/P(B); use when updating belief given evidence. See code below.\n\n**6. Logic & how the code works:**\n\n**Sets in code:** A hash set (Set in JavaScript, set in Python) stores elements in a way that membership check is O(1) on average: the implementation uses a hash function to map each element to a bucket; to check "is x in the set?" you hash x, look at that bucket, and compare. So duplicate detection ("have we seen this value?") and uniqueness ("unique list of ids") are efficient. Union, intersection, and difference can be implemented by iterating and checking membership; many standard libraries provide these.\n\n**Combinations:** To count how many ways we can choose k items from n without order: first imagine we choose an ordered sequence of k items—there are n choices for the first, n−1 for the second, ... so n×(n−1)×...×(n−k+1) = n!/(n−k)! arrangements. But each set of k items appears in k! different orders (permutations of that set), so the number of distinct subsets of size k is [n!/(n−k)!] / k! = n! / (k!(n−k)!). That is C(n,k). In code, you can compute it with factorials (watch overflow for large n) or with a loop using C(n,k) = C(n−1,k−1) + C(n−1,k) (Pascal\'s triangle).\n\n**P(at least one success):** If you run n independent trials and each has probability p of success, the probability that at least one succeeds is 1 minus the probability that all fail. Each trial fails with probability (1−p); by independence, P(all fail) = (1−p)^n. So P(at least one success) = 1 − (1−p)^n. You use this when asking "probability we get at least one hit in n attempts" or "probability at least one request fails in n requests" (with p = failure probability).\n\n**7. Example problem & solution:**\n\nProblem: How many ways to choose 2 from 5? Solution: C(5,2) = 5!/(2!3!) = 10. Problem: P(at least one success in n trials) with success probability p. Solution: 1 - P(all fail) = 1 - (1-p)^n.\n\n**8. Additional information:** De Morgan: not(A and B) = (not A) or (not B). Bayes: P(A|B) = P(B|A)P(A)/P(B). Useful for algorithms (expected case) and ML (naive Bayes classifier).',
          codeExample:
            "# n choose k and P(at least one)\ndef nCr(n, k):\n  from math import factorial\n  return factorial(n) // (factorial(k) * factorial(n - k))\n# C(5,2) = 10\n# P(at least one success in n trials, p each) = 1 - (1-p)**n",
          codeLanguage: "python",
        },
      ],
    },
    {
      title: "Data Analytics",
      slug: "data-analytics",
      description:
        "Turn data into insight: descriptive statistics and exploratory data analysis (EDA), cleaning (missing values, duplicates, types), Pandas and NumPy for manipulation and vectorization, visualization with Matplotlib and Seaborn, feature engineering and selection, and dashboards with Power BI or Tableau for KPIs and storytelling. Before you start: basic programming (variables, loops, functions) and comfort with spreadsheets or tables; Python is used in examples.",
      order: 6,
      published: true,
      items: [
        {
          title: "Statistics & EDA",
          description:
            "Mean, median, variance, distributions; exploratory data analysis and correlation; spotting outliers",
          order: 0,
          imageUrl:
            "https://placehold.co/800x400/1d4ed8/white?text=Stats+Mean+Median+Distributions+EDA",
          content:
            "**1. Learning flow:**\n\n(1) Read material so you know what descriptive statistics (mean, median, variance) and EDA are for—they summarize the data and reveal patterns and problems before you model or report. (2) Load a dataset (e.g. from Kaggle or a CSV); compute mean and median for numeric columns so you see how they can differ when data is skewed; plot histograms to see the shape of each variable and one correlation heatmap to see relationships between pairs. (3) Document your findings and one or two hypotheses in a few sentences—this habit makes your analysis reproducible and helps you decide what to do next (e.g. which features to use, whether to transform or remove outliers). (4) Spot and note outliers (e.g. with IQR or z-score) and decide whether they are errors or genuine; document your choice.\n\n**2. Material:**\n\nDescriptive statistics summarize the data with numbers and tables; EDA (exploratory data analysis) uses visualizations and summaries to reveal patterns, relationships, and data quality issues before you build models or draw conclusions. Doing EDA first helps you choose features, spot outliers and missingness, and form hypotheses.\n\n**Descriptive statistics:** The mean (average) is the sum of values divided by count; it is sensitive to extreme values, so one very large or small value can pull it away from the \"typical\" value. The median is the middle value when sorted (or the average of the two middle values for even count); it is robust to outliers because it depends only on the order of values, not their magnitude. The mode is the most frequently occurring value; useful for categorical or discrete data. Variance measures how spread out the values are (average squared deviation from the mean); standard deviation is the square root of variance and has the same units as the data. Quantiles divide the sorted data: the 25th percentile (Q1), 50th (median), and 75th (Q3) are common; they appear in box plots and in df.describe().\n\n**Distributions:** A histogram or density plot shows the shape of the distribution—symmetric (e.g. normal, bell curve), left-skewed (long tail on the left), or right-skewed (long tail on the right). Skewness is a number that summarizes this asymmetry. For many models and interpretations we care whether the distribution is roughly normal or heavily skewed.\n\n**Correlation:** Correlation (e.g. Pearson) measures the linear relationship between two numeric variables, from -1 (perfect negative) to +1 (perfect positive); 0 means no linear relationship. Correlation does not imply causation: two variables can be correlated because a third factor causes both. Scatter plots show the relationship visually; a correlation heatmap shows pairwise correlations for many columns at once.\n\n**Outliers:** Outliers are points that lie far from the rest of the data. They can be genuine (e.g. a very high sale) or errors (e.g. typo). Common rules: IQR = Q3 - Q1; points below Q1 - 1.5*IQR or above Q3 + 1.5*IQR are often flagged; or z-score (e.g. |z| > 3). Use domain knowledge to decide whether to remove, cap, or keep them; document your choice.\n\n**EDA workflow:** Load the data and check shape (rows, columns), dtypes (numeric vs object vs datetime), and missing counts per column. Run summary stats (describe()) and plot histograms or box plots per column to see distributions. Build a correlation matrix and heatmap for numeric columns; plot scatter plots for important pairs. Note any skewness, outliers, or surprising relationships and write short hypotheses or next steps.\n\n**3. Explanation:**\n\nThe mean is sensitive to outliers; the median is robust and often better for skewed data. Correlation captures linear association only and does not imply causation. EDA guides feature choice, cleaning (what to do with missing and outliers), and model selection (e.g. log transform for right-skewed targets).\n\n**4. Application:**\n\nBefore any modeling: summarize, plot distributions, check correlation and outliers. Use in reports and dashboards.\n\n**5. How to implement:** (1) Load data and inspect: df = pd.read_csv('data.csv'); check df.shape, df.dtypes, and df.isna().sum() so you know size, types, and missingness before summarizing. (2) Use df.describe() to get mean, std, min, quartiles, and max for all numeric columns in one view; for a single column use df['col'].median() or df['col'].skew() when you care about robustness or asymmetry. (3) Use df.corr() to get the correlation matrix and sns.heatmap(df.corr(), annot=True) to visualize it so you see which variables move together; note that correlation does not imply causation. (4) Plot histograms (df.hist() or sns.histplot(df['col'])) and box plots (sns.boxplot(data=df, x='cat', y='val')) to see distributions and outliers; use IQR (Q3 - Q1) or z-score to flag outliers and document your choice. (5) Write 2–3 sentences summarizing the main finding (e.g. \"Sales is right-skewed; strong correlation between marketing and revenue; 5% missing in age\") so your EDA is reproducible and guides the next step (cleaning, feature choice, or model). (6) Save key plots with plt.savefig() and optional dpi; use a notebook or script so others can rerun. See the code below.\n\n**6. Logic & how the code works:**\n\ndf.describe(): summary of mean, std, min, quartiles, max for numeric columns. df.corr(): Pearson correlation matrix between numeric columns; values -1 to 1. sns.heatmap(corr, annot=True): correlation visualization; annot=True shows numbers. sns.boxplot: median, quartiles, outliers. Histogram: distribution of values per column.\n\n**7. Example problem & solution:**\n\nProblem: Understand distribution of sales per region. Solution: groupby('region')['sales'].describe(); boxplot or histogram per region; check correlation with marketing spend.\n\n**8. Additional information:** IQR = Q3-Q1; outlier if outside [Q1-1.5*IQR, Q3+1.5*IQR]. Pearson for linear relationship; Spearman for monotonic. Document EDA steps in a notebook. Real datasets: Kaggle (Titanic, House Prices), UCI ML Repository, OpenML. Common mistake: using mean for skewed data—use median. EDA guides feature engineering and model choice.",
          codeExample:
            "import pandas as pd\nimport seaborn as sns\ndf = pd.read_csv('data.csv')\ndf.shape; df.dtypes; df.isna().sum()\ndf.describe()  # mean, std, min, 25%, 50%, 75%, max\ndf['col'].median(); df['col'].skew()\ndf.corr(); sns.heatmap(df.corr(), annot=True)\ndf.hist(figsize=(12,8)); sns.boxplot(df['col'])",
          codeLanguage: "python",
        },
        {
          title: "Data Cleaning",
          description:
            "Handle missing values, remove or merge duplicates, fix types, and normalize or scale as needed",
          order: 1,
          imageUrl:
            "https://placehold.co/800x400/2563eb/white?text=Missing+Duplicates+Types+Normalize",
          content:
            "**1. Learning flow:**\n\n(1) Read material so you know the main issues (missing values, duplicates, wrong types, scaling) and the options for each (drop, fill, impute; drop_duplicates; to_datetime, type conversion; StandardScaler or MinMaxScaler). (2) Take a messy CSV; report missing % per column (e.g. df.isna().sum()/len(df)) so you see where the gaps are; then drop or fill missing based on your assumption (e.g. drop if small and random, fill with median if numeric); remove duplicates using a clear business key (e.g. user_id + date); convert one column to datetime with pd.to_datetime(..., errors='coerce'). (3) Document what you did (which columns you dropped or filled, and why) so others can reproduce and you can justify decisions later. (4) Decide whether you need normalization for modeling—distance-based or gradient-based models usually do; tree-based models often do not.\n\n**2. Material:**\n\nClean data before analysis or modeling; missing values, duplicates, wrong types, and inconsistent units or scales cause errors, biased estimates, or failed runs. Always document what you did so others (or you later) can reproduce and justify decisions.\n\n**Missing values:** Identify with isna() or isnull(); report the count or percentage per column. Options: (1) Drop rows with missing in key columns if the fraction is small and missing is random (dropna(subset=['key_col'])). (2) Fill with a constant: mean or median for numeric (fillna(median)), mode or \"Unknown\" for categorical. (3) Impute with a model (e.g. KNN or regression) when missingness may be informative—but fit the imputer on the training set only to avoid leakage. For time series, forward fill (ffill) or backward fill (bfill) is common. If missing is not at random (MNAR), dropping or simple fill can bias results; consider a missingness indicator or a model that accounts for it. Document your assumption (e.g. \"missing at random\") and method.\n\n**Duplicates:** Exact duplicate rows: drop_duplicates() removes them. You must decide the business key: e.g. (user_id, date) should be unique; then drop_duplicates(subset=['user_id','date']). Sometimes \"duplicates\" are multiple records that should be aggregated (e.g. same user-date with different amounts); then groupby and sum or merge instead of dropping.\n\n**Types:** Convert strings to datetime with pd.to_datetime(..., errors='coerce') so invalid values become NaT. Convert numeric strings to int/float after removing commas or currency symbols; handle \"-\", \"N/A\", \" \" consistently. Fix categorical columns: strip whitespace, standardize categories (e.g. \"Male\" vs \"M\" vs \"male\"). Keep currency and units consistent (e.g. all in USD, all in kg).\n\n**Normalization and scaling:** When you use distance-based models (KNN, SVM with RBF kernel) or gradient-based optimization (linear regression, neural nets), features on very different scales can dominate or slow training. Min-max scaling maps values to [0, 1]; standard (z-score) scaling centers to mean 0 and std 1. Fit the scaler on the training set only and use it to transform both train and test to avoid data leakage. Tree-based models (random forest, XGBoost) often do not require scaling.\n\n**3. Explanation:**\n\nMissing values and duplicates can bias statistics and models if ignored or handled poorly. Wrong types cause runtime errors or wrong results (e.g. sorting strings instead of numbers). Scaling ensures no single feature dominates by magnitude and helps gradient descent converge; fit on train only to keep evaluation honest.\n\n**4. Application:**\n\nEvery dataset: assess missing, duplicates, types; clean before modeling. Normalize when using KNN, SVM, or neural nets.\n\n**5. How to implement:**\n\n(1) Find missing: isna().sum() or isna().sum()/len(df) for percentage per column. (2) Drop or fill: dropna(subset=['key_col']) to drop rows with missing in key column; fillna({'col': value}) to fill with constant or median. (3) Remove duplicates: drop_duplicates(subset=['user_id','date']) after defining the business key. (4) Fix types: pd.to_datetime(..., errors='coerce') for dates; convert numeric strings after stripping commas or handling placeholders. (5) For modeling: fit StandardScaler or MinMaxScaler on the training set only, then transform both train and test to avoid leakage. See the code below.\n\n**6. Logic & how the code works:**\n\ndf.isna().sum()/len(df): percentage of missing per column. dropna(subset=['key_col']): drop rows with missing in key column. fillna({'age': median, 'cat': 'Unknown'}): fill missing with default values. drop_duplicates(subset=['user_id','date']): remove duplicates by columns. pd.to_datetime(..., errors='coerce'): convert to datetime; invalid becomes NaT.\n\n**7. Example problem & solution:**\n\nProblem: 30% missing in age. Solution: If missing at random, fill with median. If not, add missing indicator or drop. Document your assumption.\n\n**8. Additional information:** Imputation can leak; use pipeline and fit on train only. Time series: forward/backward fill. Validate after cleaning (sanity checks). Troubleshooting: High missing—check if MCAR (random) vs MNAR (non-random); MNAR may need separate model. Duplicates—define business key (e.g. user_id + date) before drop. Type errors—inspect unique values; handle \"-\", \"N/A\", \" \" before converting.",
          codeExample:
            "df.isna().sum() / len(df)  # missing % per column\ndf.dropna(subset=['key_col'], how='any')\ndf.fillna({'age': df['age'].median(), 'category': 'Unknown'})\ndf.drop_duplicates(subset=['user_id', 'date'])\ndf['date'] = pd.to_datetime(df['date_col'], errors='coerce')\n# Scale for modeling: from sklearn.preprocessing import StandardScaler",
          codeLanguage: "python",
        },
        {
          title: "Pandas & NumPy",
          description:
            "DataFrames and Series; indexing, filtering, groupby, and aggregations; vectorization for speed",
          order: 2,
          imageUrl:
            "https://placehold.co/800x400/16a34a/white?text=Pandas+NumPy+DataFrame+Vectorization",
          content:
            "**1. Learning flow:**\n\n(1) Read material so you understand that Pandas is for tabular data (DataFrame = table, Series = column) and NumPy is for numeric arrays; vectorized operations (whole column or array at once) are much faster than Python loops. (2) Load data into a DataFrame with read_csv(); filter rows with a boolean mask (e.g. df[df['col'] > 0]); group by a column and compute mean of another with groupby('col')['other'].mean(); create a new column with vectorized ops (e.g. df['c'] = df['a'] * df['b']). (3) Use NumPy for array math (np.array(), shape, sum, mean, element-wise ops) when you need numeric computation or broadcasting. (4) Avoid Python loops over rows; use vectorized operations (df['a'] + df['b'], groupby, merge) so Pandas/NumPy can use optimized C code.\n\n**2. Material:**\n\n**Pandas:** For tabular data (rows and columns). DataFrame is a table; Series is a single column (a 1D labeled array). Read CSV with pd.read_csv('file.csv'). Select columns: df['col'] (one column, Series) or df[['a','b']] (multiple, DataFrame). Filter rows: df[df['col'] > 0] (boolean mask) or df.query('col > 0'). groupby('col') groups rows that share the same value in 'col'; then you aggregate: .mean(), .sum(), .agg({'revenue': 'mean', 'count': 'count'}). merge(left, right, on='key') joins two DataFrames. pivot_table() reshapes for aggregation. Vectorized operations: df['c'] = df['a'] + df['b'] runs the addition for every row without a Python loop—fast.\n\n**NumPy:** Arrays of the same type, stored contiguously; fast math. np.array([1,2,3]), arr.shape, arr.reshape(...). Indexing and slicing (arr[1:5]). Math: np.sum(arr), np.mean(arr), arr + 1 (element-wise), arr * arr2, broadcasting (different shapes). Random: np.random.rand(n). Use NumPy when you need array math, linear algebra, or when Pandas is too slow for a tight loop (then use .values to get the underlying array).\n\n**Vectorization:** Applying an operation to a whole column or array at once (e.g. df['a'] * 2, df['a'] + df['b']) lets Pandas/NumPy run optimized C code. A Python for loop over rows is slow; prefer built-in methods (groupby, merge, string methods, arithmetic) and only use .apply() when there is no vectorized alternative.\n\n**3. Explanation:**\n\nVectorization avoids the Python interpreter for each row: the operation is dispatched to compiled code that runs over the whole column. groupby splits the DataFrame by the grouping column(s), applies an aggregation per group, and combines the results (split-apply-combine). So groupby('segment')['revenue'].mean() gives one mean per segment in one pass. Creating a column with df['c'] = df['a'] * df['b'] is a single vectorized operation, not n multiplications in Python.\n\n**4. Application:**\n\nData wrangling (filter, join, reshape), aggregation (sum, mean, count per group), feature computation (ratios, differences, date parts). NumPy for matrix operations, custom math, or when you need raw speed on arrays.\n\n**5. How to implement:**\n\n(1) Load: df = pd.read_csv('data.csv'); inspect with df.head(), df.dtypes, df.shape. (2) Filter: df[df['a'] > 1] or df.query('a > 1'); multiple conditions with & and | (and parentheses). (3) Group and aggregate: df.groupby('segment')['revenue'].mean() or df.groupby('segment').agg({'revenue': 'mean', 'orders': 'count'}). (4) New column: df['ratio'] = df['a'] / df['b'] (vectorized). (5) Merge: pd.merge(df1, df2, on='key', how='left'). (6) NumPy: arr = df['col'].values; then np.mean(arr), arr * 2, etc. See the code below.\n\n**6. Logic & how the code works:**\n\ndf[df['a']>1] creates a boolean Series (True where a>1); indexing with it returns only the rows where the mask is True; this is a single vectorized comparison. groupby('a')['b'].mean(): the DataFrame is split into groups by column 'a'; for each group the mean of 'b' is computed; the result is a Series indexed by the group keys. df['c'] = df['a'] * df['b'] multiplies the two columns element-wise in one operation; no Python loop. NumPy arr.mean() is a reduction over the array.\n\n**7. Example problem & solution:**\n\nProblem: Average revenue per segment. Solution: df.groupby('segment')['revenue'].mean(). Problem: New column = ratio of two columns. Solution: df['ratio'] = df['a'] / df['b'] (vectorized). Problem: Filter to rows where status is 'active' and amount > 100. Solution: df[(df['status'] == 'active') & (df['amount'] > 100)].\n\n**8. Additional information:**\n\nUse .apply() only when necessary (e.g. custom function per row); prefer built-in vectorized methods. NumPy broadcasting: smaller array is \"stretched\" to match the larger (e.g. arr + 1 adds 1 to every element). read_csv options: usecols, dtype, parse_dates, nrows for large files.",
          codeExample:
            "import pandas as pd\nimport numpy as np\ndf = pd.DataFrame({'a': [1,2,3], 'b': [4,5,6]})\ndf[df['a'] > 1]\ndf.groupby('a')['b'].mean()\ndf['c'] = df['a'] * df['b']  # vectorized\narr = np.array([1,2,3]); arr.mean()",
          codeLanguage: "python",
        },
        {
          title: "Visualization",
          description:
            "Matplotlib and Seaborn; bar charts, line plots, scatter, heatmaps; when to use which chart",
          order: 3,
          imageUrl:
            "https://placehold.co/800x400/ea580c/white?text=Matplotlib+Seaborn+Charts+Heatmaps",
          content:
            "**1. Learning flow:**\n\n(1) Read material so you know how to match the chart type to the question: distribution (histogram, box plot), relationship (scatter, line), comparison (bar), composition (stacked bar), or correlation (heatmap). (2) Plot a histogram of one column (df['col'].hist() or sns.histplot(df['col'])); a scatter of two columns with hue by category (sns.scatterplot(data=df, x='a', y='b', hue='category')); and a correlation heatmap of numeric columns (sns.heatmap(df.corr(), annot=True)). (3) Always label axes and title (plt.xlabel(), plt.ylabel(), plt.title()) and save with plt.savefig('name.png') so the plot is self-explanatory and reusable. (4) For a new question (e.g. \"how does revenue vary by region?\") choose the chart type (e.g. bar chart or box plot) and implement it with the right columns.\n\n**2. Material:**\n\n**Choosing the right chart:** Match the chart to the question. **Distribution** (how is one variable distributed?): histogram (counts per bin) or box plot (quartiles, median, outliers). **Relationship** (how do two variables relate?): scatter plot (two numeric variables) or line plot (numeric over time or ordered x). **Comparison** (compare values across categories): bar chart (one bar per category). **Composition** (part of whole): stacked bar or pie (use pie sparingly; bar is often clearer). **Correlation** (many variables at once): heatmap of the correlation matrix (sns.heatmap(df.corr(), annot=True)).\n\n**Matplotlib:** Low-level control. plt.figure() creates a figure; plt.plot(), plt.bar(), plt.hist(), plt.scatter() add plots; plt.xlabel(), plt.ylabel(), plt.title() add labels; plt.legend() for multiple series; plt.show() displays; plt.savefig('file.png') saves. You build the figure step by step. Good when you need full control or custom layouts.\n\n**Seaborn:** Built on matplotlib; higher-level and good for statistical plots. sns.histplot(data=df, x='col'), sns.boxplot(data=df, x='cat', y='val'), sns.scatterplot(data=df, x='a', y='b', hue='cat'), sns.lineplot(data=df, x='date', y='sales', hue='region'), sns.heatmap(df.corr(), annot=True). It accepts DataFrames and maps columns to x, y, hue, etc., so one call produces a complete plot. Use for EDA and reports.\n\n**Best practices:** Label axes and title so the reader knows what they are seeing. Add a legend when you have multiple series (hue). Avoid 3D plots (hard to read) and too many colors or categories. Use a consistent style (e.g. sns.set_theme()). Save with plt.savefig() with a descriptive filename and dpi if needed.\n\n**3. Explanation:**\n\nThe right chart makes the message obvious: a histogram shows shape and spread; a scatter shows correlation and outliers; a bar chart compares categories; a heatmap shows many correlations at once. Seaborn wraps matplotlib and uses the DataFrame structure (column names for x, y, hue) so you write less code and get consistent styling. annot=True on a heatmap adds the numeric value in each cell so you can read the exact correlation.\n\n**4. Application:**\n\nEDA: plot distributions of each variable, scatter plots for pairs of interest, correlation heatmap. Reports and dashboards: trend lines, bar charts by segment, box plots for comparisons. Match chart to question; avoid chart types that obscure the message.\n\n**5. How to implement:**\n\n(1) Histogram: plt.hist(df['col'], bins=20) or sns.histplot(data=df, x='col', bins=20). (2) Scatter with grouping: sns.scatterplot(data=df, x='a', y='b', hue='category'). (3) Line plot (e.g. over time): sns.lineplot(data=df, x='date', y='sales', hue='region'). (4) Bar chart: sns.barplot(data=df, x='category', y='value') or df.groupby('cat')['val'].mean().plot(kind='bar'). (5) Correlation heatmap: sns.heatmap(df.corr(), annot=True, fmt='.2f'). (6) Labels and save: plt.xlabel('X'); plt.ylabel('Y'); plt.title('Title'); plt.tight_layout(); plt.savefig('plot.png'). See code below.\n\n**6. Logic & how the code works:**\n\nMatplotlib builds the figure step by step: create figure, add one or more plots (each call adds to the current axes), set labels and title, show or save. Seaborn functions accept data=df and column names for x, y, hue; they create the figure and axes, map the columns to visual channels (position, color), and draw the plot. For a heatmap, you pass a 2D structure (e.g. correlation matrix); each cell is colored by value; annot=True writes the value in the cell so you can read the number.\n\n**7. Example problem & solution:**\n\nProblem: Show sales trend over time by region. Solution: sns.lineplot(data=df, x='date', y='sales', hue='region'). Each region is a line; the x-axis is date, y is sales. Add plt.xlabel('Date'); plt.ylabel('Sales'); plt.title('Sales by region over time'); plt.legend(title='Region').\n\n**8. Additional information:**\n\nMatplotlib for full control (subplots, custom layouts). Seaborn for styled stats plots. Use consistent colors and fonts across reports. Save as PNG for slides, SVG for scalability. plt.tight_layout() before save to avoid cut-off labels.",
          codeExample:
            "import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.hist(df['col'], bins=20)\nplt.xlabel('Value'); plt.title('Distribution')\nsns.scatterplot(data=df, x='a', y='b', hue='category')\nsns.heatmap(df.corr(), annot=True)\nplt.show()",
          codeLanguage: "python",
        },
        {
          title: "Feature Engineering",
          description:
            "Encoding categories (one-hot, label); scaling (min-max, standard); creating and selecting features",
          order: 4,
          imageUrl:
            "https://placehold.co/800x400/7c3aed/white?text=Encoding+Scaling+Features+Selection",
          content:
            "**1. Learning flow:**\n\n(1) Read material so you know why we encode categories (models need numbers), when to use one-hot vs label vs target encoding, why we scale (distance and gradient), and how to create and select features. (2) One-hot encode a categorical column (pd.get_dummies or OneHotEncoder); standard-scale numeric columns (StandardScaler fit on train only, then transform train and test); create one new feature (e.g. ratio = df['a']/df['b']); run a simple model (e.g. RandomForest or LogisticRegression) and check feature_importances_ or coef_. (3) Remove low-importance or redundant features (drop low variance, or drop one of highly correlated pairs, or drop by feature_importances_ threshold). (4) Try target encoding (replace category with mean of target per category) with proper cross-validation or leave-one-out to avoid leakage when the same category appears in train and test.\n\n**2. Material:**\n\nModels need numeric input; you must encode categorical variables and often scale numeric ones. You also create features that capture domain knowledge and remove redundant or noisy ones to improve generalization and speed.\n\n**Encoding:** Categorical to numbers. **Label encoding** assigns one integer per category (e.g. red=0, blue=1, green=2). Tree-based models can use it (they split on the value); linear and neural models may interpret the order (0 < 1 < 2), so use only when order is meaningful. **One-hot encoding** creates one binary column per category (e.g. is_red, is_blue, is_green); the model sees no ordering. Use for linear models and when categories have no order; use drop_first=True to avoid multicollinearity. **Target encoding** replaces each category with the mean of the target for that category (e.g. mean conversion rate per country); powerful but risky—you must avoid leakage by computing the mean only on the training fold (e.g. in cross-validation) or using smoothing.\n\n**Scaling:** Min-max scales to [0,1]; standard (z-score) centers to mean 0 and std 1. Needed for distance-based models (KNN, SVM with RBF) and gradient-based optimization (linear regression, neural nets) so no single feature dominates by magnitude. **Fit the scaler on the training set only** and use it to transform both train and test; otherwise you leak test information. Tree-based models (RF, XGBoost) often do not need scaling.\n\n**Feature creation:** Combine columns (ratio, difference, product); extract date parts (year, month, day of week); bin continuous variables; domain-specific (revenue per user, time since last purchase). Often more impactful than model choice.\n\n**Selection:** Remove low-variance features, one of highly correlated pairs, or low-importance features (from tree feature_importances_ or permutation importance). Reduces overfitting and training time.\n\n**3. Explanation:**\n\nLabel encoding implies an order; tree models split on the value so they can still learn; linear models may treat the encoding as numeric so use one-hot when there is no order. One-hot avoids that but increases dimension for high-cardinality categories. Scaling puts features on a comparable scale so distance and gradients are not dominated by one column. Fit scaler on train only so test is never used to compute mean/std (data leakage). Feature creation encodes domain knowledge; selection removes noise and redundancy.\n\n**4. Application:**\n\nEvery ML pipeline: encode categories, scale numerics (if needed), create domain features, optionally select. Tree models often need less scaling; linear and neural need it. High-cardinality categories: target encoding with CV or embedding in neural nets.\n\n**5. How to implement:**\n\n(1) One-hot: pd.get_dummies(df, columns=['category'], drop_first=True) or OneHotEncoder from sklearn (fit on train, transform train and test). (2) Scaling: scaler = StandardScaler(); X_train_scaled = scaler.fit_transform(X_train); X_test_scaled = scaler.transform(X_test)—never fit on test. (3) New feature: df['ratio'] = df['a'] / df['b'] or df['revenue_per_user'] = df['revenue'] / df['users']. (4) Feature importance: after fitting a tree model, model.feature_importances_; for linear, model.coef_. (5) Selection: drop columns with variance below threshold, or drop by importance, or use RFE. See code below.\n\n**6. Logic & how the code works:**\n\nOne-hot creates one binary column per category so the model sees no ordering. StandardScaler fits mean and std on the training set only; you transform both train and test with those same values to avoid data leakage. Feature importance from trees shows which columns the model relied on most; permutation importance is more reliable (shuffle column and see drop in score).\n\n**7. Example problem & solution:**\n\nProblem: Category with 100 levels; one-hot blows up dimension. Solution: Target encoding (mean of target per category) with CV to avoid leakage, or reduce dimensions (embed in neural net, or group rare categories). Problem: Model sensitive to feature scale. Solution: StandardScaler fit on train, transform train and test.\n\n**8. Additional information:** Fit scaler and encoder on train; transform train and test. Correlation and VIF for redundancy. Recursive feature elimination or L1 for selection. Real case: High-cardinality category (100+ levels)—target encoding with CV or embed in neural net. Common mistake: fitting scaler on full data (leakage)—always fit on train only. Feature importance from trees: use permutation importance for reliability.",
          codeExample:
            "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n# One-hot (linear models) vs label (trees)\npd.get_dummies(df, columns=['category'], drop_first=True)\ndf['ratio'] = df['a'] / df['b']  # domain feature\nscaler = StandardScaler(); X_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)  # transform, not fit!\nmodel.feature_importances_; model.coef_  # linear",
          codeLanguage: "python",
        },
        {
          title: "Dashboards",
          description:
            "Power BI and Tableau; KPIs, filters, and telling a story with data; when to use a dashboard vs a report",
          order: 5,
          imageUrl:
            "https://placehold.co/800x400/0d9488/white?text=Power+BI+Tableau+KPIs+Dashboards",
          content:
            '**1. Learning flow:**\n\n(1) Read material so you know what KPIs, filters, and storytelling mean in a dashboard—KPIs answer "how are we doing?", filters let users slice the data, and storytelling is the order and wording that make the main message clear. (2) Build a simple dashboard with 2–3 KPIs (e.g. total sales, % change) and one chart (e.g. bar by region or line over time); add a date filter so users can change the range; write one sentence that states the main insight (e.g. "Sales up 10% vs last month; Region X leads") so the viewer does not have to guess. (3) Use Power BI, Tableau, or a Python dashboard library (Dash, Streamlit) so you see how tools connect to data and publish. (4) Review the storytelling order of your visuals: KPIs first, then the chart that explains why, then detail—this order guides the eye and makes the message easy to get.\n\n**2. Material:**\n\nDashboards show key metrics and trends at a glance so decision-makers can see the state of the business without opening raw data. Design for the audience (executive vs operational) and the decision you support (e.g. "Should we invest in region X?" or "Is conversion dropping?"). Use filters and drill-downs so the same dashboard can answer many questions.\n\n**KPIs (key performance indicators):** One number per metric (e.g. total revenue, conversion rate, active users, churn rate). Show trend next to the number: a sparkline (mini line chart) or comparison to previous period (e.g. "+12% vs last month"). Use conditional formatting (e.g. red if below target, green if above) so problems stand out. Choose 2–5 KPIs per screen; too many dilutes focus.\n\n**Filters:** Let users filter by date range, region, segment, or product. Linked filters mean one click (e.g. "Region = Asia") updates all charts on the page so the view stays consistent. Keep the default view meaningful (e.g. last 30 days, all regions) so the first load answers the most common question.\n\n**Storytelling:** Order visuals so the narrative is clear: e.g. KPIs first (the headline), then the chart that explains why (e.g. revenue by region), then detail (e.g. top products). Use a title and one short sentence that states the main insight. Avoid clutter: one main message per screen; move secondary details to a second page or tooltip.\n\n**Tools:** Power BI and Tableau connect to databases and CSVs; you build charts with drag-and-drop and publish to the web or internal portal. Use them when stakeholders need self-serve exploration and refresh. For one-off analysis or custom logic, scripts (Python, R) and notebooks are often better; for ongoing monitoring, dashboards are better.\n\n**3. Explanation:**\n\nKPIs answer "how are we doing?"; filters let users slice the data without building new reports; storytelling guides the eye to the main takeaway so the viewer does not have to interpret from scratch. Avoid clutter so the message is clear.\n\n**4. Application:**\n\nOperational dashboards (real-time), executive summary (KPIs + trends), self-serve exploration. Reports for one-off; dashboards for ongoing.\n\n**5. How to implement:**\n\n(1) Define 2–3 KPIs that answer the main question (e.g. total revenue, conversion rate, active users); show each as one number plus a trend (sparkline or % vs previous period). (2) Add one chart per metric or comparison (e.g. bar by region, line over time) so users can see why the KPI is what it is. (3) Add date and segment filters and link them so one click updates all visuals. (4) Use conditional formatting (e.g. red/green vs target) so problems stand out. (5) Add a title and one short sentence that states the main insight so the "so what?" is explicit.\n\n**6. Logic & how the code works:**\n\nKPIs are single numbers (e.g. total revenue, conversion rate) that answer "how are we doing?"; they are computed from the same data source (e.g. a data warehouse or CSV) and updated when the dashboard refreshes. Filters (e.g. date range, region) are applied before aggregation, so when a user selects "Q4" and "Europe," every chart and KPI on the page uses only that subset; linked filters ensure one selection updates all visuals so the view stays consistent. One clear sentence (e.g. "Sales up 10% vs last month; Region X leads") states the main takeaway so the viewer does not have to compare charts mentally—as an educator would, you are answering the "so what?" explicitly.\n\n**7. Example problem & solution:**\n\nProblem: Stakeholders want to see sales by region and trend. Solution: Dashboard with KPI cards (total sales, % change); bar chart by region; line chart over time; date range filter. One sentence: "Sales up 10% vs last month; Region X leads."\n\n**8. Additional information:**\n\nPower BI, Tableau, Metabase, or Python (Dash, Streamlit). Connect to DB or CSV; refresh schedule. Design for the decision: what will the user do after viewing?',
        },
      ],
    },
    {
      title: "AI & Machine Learning",
      slug: "ai-ml",
      description:
        "From basics to practice: supervised vs unsupervised vs reinforcement learning, regression and classification and clustering, train/test split and cross-validation and metrics (accuracy, F1, AUC), neural networks and CNN/RNN/Transformers with PyTorch or TensorFlow, computer vision and NLP pipelines, and implementing real projects with scikit-learn and deep learning frameworks. Before you start: basic Python, linear algebra and statistics (mean, variance, distributions), and Data Analytics section helpful for data handling.",
      order: 7,
      published: true,
      items: [
        {
          title: "ML Fundamentals",
          description:
            "Supervised (labels), unsupervised (no labels), reinforcement (rewards); regression, classification, clustering",
          order: 0,
          imageUrl:
            "https://placehold.co/800x400/4f46e5/white?text=Supervised+Unsupervised+Regression+Classification",
          content:
            "**1. Learning flow:**\n\n(1) Read material so you understand the three families (supervised, unsupervised, reinforcement) and when to use each—supervised when you have labels and want to predict, unsupervised when you want to find structure or segments, RL when you have sequential decisions and rewards. (2) Train a classifier (e.g. sklearn LogisticRegression) on a small dataset; use train_test_split so you evaluate on held-out data; report accuracy so you see the fit/predict flow. (3) Run K-means on the same (or similar) data and plot clusters so you see how unsupervised grouping works without labels. (4) Compare: with labels you get one \"correct\" grouping (from the classifier); without labels you get segments (from K-means) that you must interpret and name.\n\n**2. Material:**\n\nMachine learning is often split into three families: supervised (learn from labeled examples to predict), unsupervised (find structure in data without labels), and reinforcement learning (learn from rewards when acting in an environment). The choice depends on whether you have labels and whether the problem is one-shot prediction or sequential decision-making.\n\n**Supervised learning:** You have input X and label Y (target). The model learns a function from X to Y from training examples. Regression: Y is continuous (e.g. house price, temperature). Classification: Y is discrete (e.g. spam vs not spam, or multiple classes). You train by minimizing a loss (e.g. mean squared error for regression, cross-entropy for classification) on the training set; you evaluate on a held-out test set to estimate real-world performance. Examples: linear regression, logistic regression, decision trees, random forest, XGBoost, neural networks. Always split data (e.g. 80% train, 20% test) so you never evaluate on the same data you trained on.\n\n**Unsupervised learning:** No labels. The goal is to find structure: clusters (group similar points, e.g. K-means, hierarchical clustering), dimensionality reduction (PCA, t-SNE for visualization or fewer features), or anomaly detection (points that do not fit the rest). Used for exploration, segmentation, or as a preprocessing step.\n\n**Reinforcement learning (RL):** An agent takes actions in an environment and receives rewards (or penalties). The goal is to learn a policy that maximizes cumulative reward over time. Used in games, robotics, recommendation (e.g. bandits), and control. RL is a different paradigm from supervised learning because feedback is delayed and you must balance exploration (trying new actions) and exploitation (using what works).\n\n**3. Explanation:**\n\nSupervised learning minimizes a loss on (X, Y) pairs so the model predicts Y from X. Unsupervised learning finds structure (clusters, low-dim representation) without a target. RL maximizes long-term reward by trial and error. Splitting data (train/test) is critical so you measure generalization, not memorization.\n\n**4. Application:**\n\nTabular: classification/regression (trees, linear). Clustering for segmentation. RL for sequential decisions.\n\n**5. How to implement:** (1) Split data: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) so you never evaluate on the same data you trained on and the split is reproducible. (2) Supervised: create the model (e.g. LogisticRegression(), RandomForestClassifier()); call fit(X_train, y_train) to train; then predict(X_test) and compare with y_test to compute accuracy, F1, or MSE; use classification_report or confusion_matrix for classification. (3) Clustering: call fit(X) only (no y); use predict(X) or model.labels_ to get cluster assignments; choose K (e.g. elbow method or domain knowledge) and interpret clusters. (4) Regression: use LinearRegression(), Ridge(), or tree-based; fit and predict; evaluate with mean_squared_error or R². (5) Always use a metric (score, accuracy, MSE, or classification_report) to summarize performance; never report only training metric—report test (or cross-validation) so you see generalization. (6) For quick experiments use a pipeline (e.g. Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression())])) so preprocessing and model are fitted together and you can save/load one object. See code below.\n\n**6. Logic & how the code works:**\n\nIn supervised learning, fit(X_train, y_train) passes the training data to the model; the model adjusts its parameters (e.g. weights in a linear model or splits in a tree) to minimize the loss on that data. When you call predict(X_test), the model applies the learned function to new inputs; you compare with y_test to compute accuracy or MSE. If you evaluated on the training set, you would overestimate performance (the model has already seen those examples); the test set is held out so it simulates unseen data. In clustering, fit(X) has no labels: the algorithm (e.g. K-means) groups similar rows by distance (e.g. Euclidean); predict(X) or labels_ assigns each row to a cluster. The number of clusters (e.g. K=3) is a hyperparameter you choose or estimate (e.g. elbow method).\n\n**7. Example problem & solution:**\n\nProblem: Segment customers. Solution: Unsupervised. Features: recency, frequency, amount; K-means or hierarchical; interpret clusters and name segments.\n\n**8. Additional information:**\n\nscikit-learn: linear_model, ensemble, cluster. Start with LogisticRegression and RandomForest for classification. PCA for visualization.",
          codeExample:
            "from sklearn.linear_model import LogisticRegression\nfrom sklearn.cluster import KMeans\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nclf = LogisticRegression(); clf.fit(X_train, y_train)\nprint(clf.score(X_test, y_test))\nkmeans = KMeans(n_clusters=3); kmeans.fit(X)\nlabels = kmeans.predict(X)",
          codeLanguage: "python",
        },
        {
          title: "Model Evaluation",
          description:
            "Train/test split and cross-validation; accuracy, precision, recall, F1, ROC-AUC; overfitting and underfitting",
          order: 1,
          imageUrl:
            "https://placehold.co/800x400/7c3aed/white?text=Train+Test+CV+Accuracy+F1+AUC",
          content:
            "**1. Learning flow:**\n\n(1) Read material so you know why we use train/test split and cross-validation (to estimate real-world performance and avoid overfitting) and what the main metrics mean (accuracy, precision, recall, F1, ROC-AUC). (2) Run 5-fold CV on a classifier with cross_val_score(..., scoring='f1_macro'); report mean and std of F1 so you see how stable the model is across folds; plot confusion matrix on the test set so you see where the model errs (false positives vs false negatives). (3) Choose the right metric for an imbalanced task—accuracy is misleading when one class is rare; use F1 or precision-recall and consider class_weight or oversampling. (4) Use cross-validation for hyperparameter tuning (e.g. GridSearchCV) so you pick parameters based on out-of-fold performance, not on the test set.\n\n**2. Material:**\n\nNever evaluate on training data; use a held-out test set or cross-validation. Choose metrics that match the business goal (e.g. F1 for imbalanced classes).\n\nSplit: train_test_split(X, y, test_size=0.2, random_state=42). Train on train; evaluate on test once at the end. For tuning, use cross-validation on train (e.g. 5-fold): average metric across folds.\n\nClassification metrics: Accuracy = correct / total (misleading if imbalanced). Precision = TP/(TP+FP); Recall = TP/(TP+FN); F1 = harmonic mean of P and R. ROC-AUC: overall ranking quality; use when you care about threshold. Confusion matrix: TP, TN, FP, FN.\n\nOverfitting: Model fits train too well, poor on test. Fix: more data, simpler model, regularization, early stop. Underfitting: Poor on both; need more capacity or features.\n\n**3. Explanation:**\n\nTrain/test split avoids overfitting to the same data you evaluate on. CV gives more stable metric estimate. Precision/recall trade-off: threshold choice.\n\n**4. Application:**\n\nAlways hold out test; use CV for model selection and tuning. F1 for imbalanced; ROC-AUC for ranking; confusion matrix for diagnosis.\n\n**5. How to implement:**\n\n(1) Split once: train_test_split(X, y, test_size=0.2) and keep the test set untouched until final evaluation. (2) For model selection or tuning use cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_macro') so you get an estimate that averages over folds; report mean and std. (3) After choosing the model, fit on full training set (or refit with best params from GridSearchCV), then predict on X_test and compute confusion_matrix(y_test, y_pred) and classification_report to see precision, recall, F1 per class. (4) For imbalanced data use scoring='f1' or 'precision'/'recall' and consider class_weight='balanced' or oversampling. See code below.\n\n**6. Logic & how the code works:**\n\nCross-validation splits the training set into k folds; each fold is used once as validation while the rest train the model, so you get k metric values and can report mean and std. Confusion matrix shows TP, TN, FP, FN so you can see whether errors are false positives or false negatives; for imbalanced data, accuracy is misleading and F1 or precision-recall is more informative.\n\n**7. Example problem & solution:**\n\nProblem: Imbalanced classes (1% positive). Solution: Use F1 or precision-recall curve; consider class_weight or oversampling; report precision and recall, not just accuracy.\n\n**8. Additional information:**\n\nStratified k-fold for classification. Early stopping in deep learning. Calibration for probability outputs.",
          codeExample:
            "from sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.metrics import f1_score, confusion_matrix\nscores = cross_val_score(clf, X, y, cv=5, scoring='f1_macro')\nprint(scores.mean(), scores.std())\ny_pred = clf.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))",
          codeLanguage: "python",
        },
        {
          title: "Deep Learning",
          description:
            "Neural networks (layers, activation, backprop); CNN for images; RNN/LSTM for sequences; Transformers; PyTorch/TensorFlow basics",
          order: 2,
          imageUrl:
            "https://placehold.co/800x400/dc2626/white?text=CNN+RNN+Transformers+PyTorch+TF",
          content:
            "**1. Learning flow:** (1) Read material on neural network basics (layers, activation, loss, backprop, optimizer) and when to use MLP vs CNN vs RNN vs Transformer—MLP for tabular, CNN for images, RNN/LSTM for sequences, Transformer for NLP and often vision. (2) Build a small MLP in PyTorch or Keras for a tabular task (e.g. classification on a small dataset): define layers (Linear, ReLU, Dropout), loss (cross-entropy), and optimizer (Adam); run a training loop for a few epochs and observe loss going down. (3) Add one conv layer and run on small image data (e.g. MNIST or CIFAR) so you see how conv2d and pooling work; then try a pretrained CNN (e.g. ResNet) with the final layer replaced for your classes. (4) Train for a few epochs; log loss and accuracy so you can spot overfitting (train loss keeps dropping, val loss rises). (5) Try different optimizers (SGD vs Adam) and learning rates so you see how they affect convergence. (6) Real case: use a framework’s DataLoader for batching and move the model and data to GPU (.to(device)) when available so training is fast.\n\n**2. Material:**\n\nNeural networks are layers of weighted sums and non-linear activations; trained with gradient descent and backpropagation. CNN for spatial data (images); RNN/LSTM for sequences; Transformers for both and dominant in NLP/CV.\n\nBasics: Layer: input × weights + bias; activation (ReLU, sigmoid, softmax). Loss (e.g. cross-entropy); backprop computes gradients; optimizer (SGD, Adam) updates weights. Epoch = one pass over data.\n\nCNN: Convolutional layers extract local features; pooling reduces size; stack for hierarchy. Use for image classification, object detection. Architectures: ResNet, VGG, EfficientNet.\n\nRNN/LSTM: Process sequence step by step; hidden state carries context. LSTM avoids vanishing gradients. Use for time series, text (before Transformers).\n\nTransformers: Self-attention over tokens; parallel; no recurrence. BERT, GPT, ViT. Standard for NLP and often for vision.\n\nFrameworks: PyTorch (dynamic graph, Pythonic); TensorFlow/Keras (static or eager). Define model, loss, optimizer; loop over batches; backward and step.\n\n**3. Explanation:**\n\nBackprop computes gradients of loss w.r.t. weights; optimizer updates weights. ReLU avoids vanishing gradient. Batch norm and dropout improve training.\n\n**4. Application:**\n\nTabular: MLP. Images: CNN. Sequences: RNN/LSTM or Transformer. Use pretrained when possible.\n\n**5. How to implement:** (1) Define the model: in PyTorch create an nn.Module with __init__ (layers: Linear, Conv2d, ReLU, Dropout, etc.) and forward(x) that returns logits or predictions; for Keras use Sequential or Functional API. (2) Choose loss: nn.CrossEntropyLoss() for classification, nn.MSELoss() for regression; and optimizer: torch.optim.Adam(model.parameters(), lr=1e-3) or SGD. (3) Training loop: for each epoch, iterate over DataLoader (for batch_x, batch_y in loader); set model.train(); zero_grad(); output = model(batch_x); loss = criterion(output, batch_y); loss.backward(); optimizer.step(). (4) Use DataLoader(dataset, batch_size=32, shuffle=True) so you process batches and shuffle each epoch; move model and data to device (e.g. .to('cuda')) for GPU. (5) Validation: model.eval(); with torch.no_grad(): run the same forward on val data and compute metric (accuracy or MSE). (6) Save the best checkpoint (model.state_dict() or full model) when validation improves; use learning rate scheduling (e.g. ReduceLROnPlateau) if loss plateaus. See code below.\n\n**6. Logic & how the code works:**\n\nForward pass computes predictions and loss; backward() computes gradients of the loss with respect to every weight; the optimizer then updates weights (e.g. weight -= lr * gradient). DataLoader batches samples so you process many inputs at once; this speeds up training and improves gradient estimates.\n\n**7. Example problem & solution:**\n\nProblem: Image classification with few samples. Solution: Use pretrained CNN (e.g. ResNet); replace last layer; freeze early layers, fine-tune last few. Data augmentation (flip, crop) to reduce overfitting.\n\n**8. Additional information:** PyTorch: nn.Module, torch.optim. TensorFlow: Sequential or Functional API. Mixed precision (AMP) and GPU for speed. Learning rate schedule (CosineAnnealing) often improves convergence.",
          codeExample:
            "# PyTorch: simple MLP and training loop\nimport torch.nn as nn\nmodel = nn.Sequential(\n  nn.Linear(784, 256), nn.ReLU(), nn.Dropout(0.2),\n  nn.Linear(256, 10)\n)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nfor x, y in dataloader:\n  loss = nn.functional.cross_entropy(model(x), y)\n  loss.backward(); optimizer.step(); optimizer.zero_grad()",
          codeLanguage: "python",
        },
        {
          title: "Computer Vision",
          description:
            "Image classification and object detection pipelines; data augmentation; transfer learning",
          order: 3,
          imageUrl:
            "https://placehold.co/800x400/059669/white?text=Image+Classification+Object+Detection",
          content:
            "**1. Learning flow:** (1) Read material on image classification (one label per image), transfer learning (pretrained CNN + replace final layer), and data augmentation (flip, crop, color jitter). (2) Use a pretrained ResNet (or EfficientNet) from torchvision; replace the final fully connected layer with nn.Linear(512, num_classes) for your number of classes; optionally freeze the backbone and train only the head first. (3) Prepare a small dataset (e.g. CIFAR-10 or custom 5 classes, 100+ images each) with folders per class or a CSV; apply transforms (Resize, RandomCrop, ToTensor, Normalize) for training. (4) Train for a few epochs; evaluate with accuracy and confusion matrix; then unfreeze and fine-tune with a lower learning rate if needed. (5) Real case: product image classifier—train on 500 images per class, deploy as an API that loads the model and returns the top class. (6) For object detection (multiple objects per image) use a library like Ultralytics YOLO after you are comfortable with classification.\n\n**2. Material:** Image classification assigns one label per image; object detection finds multiple objects and their bounding boxes. Use transfer learning (pretrained CNN) when you have limited data (<10K images).\n\nClassification: Input image (224×224 typically) → CNN (ResNet, EfficientNet, ViT) → feature vector → FC layer → class scores → softmax → label. Data augmentation: horizontal flip, random crop, color jitter (brightness, contrast, saturation) to increase effective data and reduce overfitting. Transfer learning: take pretrained model (ImageNet); replace last FC layer for your num_classes; freeze backbone (early layers) and fine-tune last 1–2 blocks; or unfreeze all with lower learning rate.\n\nObject detection: Output: list of (bbox, class, confidence). Two-stage (R-CNN, Faster R-CNN: region proposals then classify) vs one-stage (YOLO, SSD: predict boxes and classes in one pass). YOLO is faster; use for real-time. Metrics: IoU (intersection over union) for overlap; mAP (mean average precision) at IoU threshold 0.5.\n\nPipeline: Dataset (folders per class or COCO format) → DataLoader with transforms → model → CrossEntropyLoss → backward → optimizer.step. Validation loop; early stopping if val loss plateaus.\n\n**3. Explanation:** Early CNN layers learn edges and textures; later layers learn high-level features (parts, objects). Pretrained weights encode general visual knowledge; fine-tuning adapts to your domain. Augmentation increases effective data without labeling more images. Freezing early layers prevents forgetting; fine-tuning last layers adapts to your task.\n\n**4. Application:** Real case: E-commerce product classifier. 5 classes: shirt, shoe, bag, watch, other. 500 images per class. Use ResNet18 pretrained; replace fc with Linear(512, 5); freeze conv layers for 5 epochs; unfreeze all, lr=1e-5 for 10 epochs. Augment: RandomHorizontalFlip, RandomResizedCrop, ColorJitter. Accuracy ~92%. Deploy as API: load model, preprocess image, predict.\n\n**5. How to implement:** (1) Load a pretrained model: from torchvision import models; model = models.resnet18(weights='IMAGENET1K_V1'); replace the final layer with nn.Linear(512, num_classes) for your number of classes. (2) Freeze the backbone so only the new head trains: for p in model.parameters(): p.requires_grad = False; model.fc.requires_grad = True; use a smaller learning rate (e.g. 1e-3) for the head. (3) Define transforms: transforms.Compose([Resize(256), RandomCrop(224), ToTensor(), Normalize(mean, std)]) for training; for validation use Resize(256), CenterCrop(224), ToTensor(), Normalize. (4) DataLoader: batch size 32 (or 16 if OOM); num_workers for loading. (5) Training loop: for each batch compute loss = criterion(output, target), loss.backward(), optimizer.step(), zero_grad; run validation every epoch and save best checkpoint. (6) After a few epochs you can unfreeze all layers and fine-tune with a lower lr (e.g. 1e-5). See code below.\n\n**6. Logic & how the code works:**\n\nPretrained weights already encode edges, textures, and object parts from ImageNet; replacing the final layer and fine-tuning only that layer (or the last few) adapts the model to your classes without forgetting. Data augmentation (flip, crop, color) creates variations so the model sees more effective data and overfits less.\n\n**7. Example problem & solution:** Problem: Classify 5 flower types; 100 images each; overfitting. Solution: (1) Transfer learning: ResNet18, replace fc. (2) Augmentation: flip, crop, color jitter. (3) Freeze backbone 5 epochs; unfreeze with lr 1e-5. (4) Early stop at epoch 15 when val loss stops improving. Result: 85% accuracy; without transfer learning ~60%.\n\n**8. Additional information:** Datasets: CIFAR-10, ImageNet, Kaggle. torchvision.datasets, ImageFolder for folder-per-class. ViT (Vision Transformer) for larger datasets. YOLO with Ultralytics for object detection. Model export: ONNX, TorchScript for deployment.",
          codeExample:
            "# PyTorch: Transfer learning for image classification\nimport torch.nn as nn\nfrom torchvision import models\nmodel = models.resnet18(weights='IMAGENET1K_V1')\nmodel.fc = nn.Linear(512, num_classes)\nfor p in model.parameters(): p.requires_grad = False\nmodel.fc.requires_grad = True\noptimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-3)",
          codeLanguage: "python",
        },
        {
          title: "NLP",
          description:
            "Tokenization, word embeddings, sequence models; Transformers for text (BERT, GPT); practical pipelines",
          order: 4,
          imageUrl:
            "https://placehold.co/800x400/0d9488/white?text=NLP+Tokenization+Embeddings+Transformers",
          content:
            "**1. Learning flow:** (1) Read material on tokenization (text → tokens → ids), embeddings, and transformer-based models (BERT for encoding, [CLS] or pooling for classification). (2) Load a pretrained model (e.g. DistilBERT) and tokenizer from Hugging Face; run on a sentiment or intent dataset (e.g. IMDB, SST-2, or custom tickets); fine-tune with Trainer for 2–3 epochs and a small learning rate (2e-5). (3) Practice tokenization: call tokenizer(texts, padding=True, truncation=True, max_length=128) and inspect input_ids and attention_mask. (4) Use the pipeline API for zero-shot classification (predefined labels, no training). (5) Real case: support ticket routing—classify intent (billing, technical, refund, etc.) from 500 labeled tickets; deploy so new tickets get a suggested label. (6) For production: save model and tokenizer with save_pretrained; load in inference and batch requests for throughput.\n\n**2. Material:** Text → tokens (words/subwords) → ids → embeddings → model → output. Tokenization: split into tokens; vocabulary maps token → id; padding and truncation to max_length (e.g. 512). BPE and WordPiece handle rare words. Hugging Face: AutoTokenizer.from_pretrained('bert-base-uncased').\n\nEmbeddings: Dense vectors (e.g. 768-dim) per token. Pretrained (BERT, RoBERTa) capture semantics. Transformer: BERT (encoder, bidirectional, masked LM + NSP); GPT (decoder, left-to-right, next-token). For classification: take [CLS] token output or mean of last hidden state; add linear layer → num_classes.\n\nTasks: Classification (sentiment, intent): encode, pool, linear. NER: token-level classification. QA: span extraction from context. Generation: autoregressive (GPT). Use Hugging Face Trainer for fine-tuning.\n\n**3. Explanation:** [CLS] token aggregates sentence meaning; pooling over tokens gives alternative. Masked LM pretrains BERT to predict masked tokens; fine-tuning adds task head. max_length truncates long texts; attention_mask tells model to ignore padding. Lower lr (2e-5) for fine-tuning to avoid forgetting.\n\n**4. Application:** Real case: Support ticket routing. 5 intents: billing, technical, refund, general, complaint. 500 labeled tickets. Use DistilBERT (faster than BERT). Tokenize with max_length=128; batch 32. Fine-tune 3 epochs, lr=2e-5. Accuracy ~88%. Deploy: load model + tokenizer; predict on new ticket; route to correct queue.\n\n**5. How to implement:** (1) Load tokenizer and model: from transformers import AutoTokenizer, AutoModelForSequenceClassification; tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased'); model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=5). (2) Prepare data: tokenize texts with tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors='pt'); create a Dataset that returns input_ids, attention_mask, labels. (3) Training args: set num_epochs=3, per_device_train_batch_size=32, learning_rate=2e-5 (small for fine-tuning); use Trainer(model=model, args=args, train_dataset=train_ds). (4) Train: Trainer.train(); then save with model.save_pretrained('path') and tokenizer.save_pretrained('path'). (5) Inference: load model and tokenizer; tokenizer(text, return_tensors='pt'); model(**inputs).logits; argmax for class. (6) For zero-shot use pipeline('zero-shot-classification', model=model, tokenizer=tokenizer) with candidate labels. See code below.\n\n**6. Logic & how the code works:**\n\nThe tokenizer turns text into input_ids and attention_mask; the model runs the transformer and outputs logits per class. For classification you take the [CLS] output or mean over tokens and add a linear layer to num_classes. Fine-tuning uses a small learning rate (e.g. 2e-5) so the pretrained weights are not destroyed while the head learns your task.\n\n**7. Example problem & solution:** Problem: Sentiment on 2K reviews; 3 classes (pos/neg/neutral). Solution: DistilBERT, num_labels=3. Tokenize max_length=256. Train 3 epochs, lr=2e-5, batch 16. Use class weights if imbalanced. F1 macro ~0.82. Pipeline: pipeline('sentiment-analysis', model=model, tokenizer=tokenizer) for inference.\n\n**8. Additional information:** Hugging Face Hub: thousands of models. Datasets: IMDB, SST-2, AG News. Zero-shot: pipeline('zero-shot-classification') with predefined labels. Quantization for smaller models. max_length: 128 for short texts (tweets); 512 for docs.",
          codeExample:
            "# Hugging Face: BERT for sequence classification\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\ntokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\nmodel = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\ninputs = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors='pt')\noutputs = model(**inputs)\nlogits = outputs.logits",
          codeLanguage: "python",
        },
        {
          title: "Implementation & Real Projects",
          description:
            "End-to-end ML with scikit-learn and PyTorch/TensorFlow; from data to deployed model; example projects",
          order: 5,
          imageUrl:
            "https://placehold.co/800x400/16a34a/white?text=sklearn+TF+PyTorch+Real+Projects",
          content:
            "**1. Learning flow:** (1) Read material on end-to-end ML: problem definition, data loading and cleaning, feature engineering, model choice and training, evaluation, and saving/loading for inference. (2) Build one complete project from raw data to a trained model and a small script (or API) that loads the model and predicts on new input—e.g. tabular (sklearn Pipeline) or vision/NLP (PyTorch). (3) Use sklearn Pipeline (scaler + model) for tabular so fit/predict and save/load are consistent; or use a PyTorch training loop (DataLoader, forward, loss, backward, optimizer.step) and save state_dict. (4) Evaluate on a held-out test set and document the metric (accuracy, F1, etc.); then save the pipeline or model and write a minimal inference script. (5) Real case: churn prediction or product classifier—from CSV or images to a single command or API that returns a prediction. (6) Document: data source, features, model, metric, and how to run so someone else can reproduce.\n\n**2. Material:**\n\nReal projects involve data loading and cleaning, feature engineering, model choice and training, evaluation, and often deployment or integration. Start small and iterate.\n\nscikit-learn: Fit/predict API. Pipeline for preprocessing + model. GridSearchCV for hyperparameters. Good for tabular data, classical ML. Save with joblib or pickle.\n\nPyTorch/TensorFlow: For deep learning. Datasets and DataLoader for batching. Training loop: forward, loss, backward, step. Save checkpoint (state_dict or SavedModel).\n\nProject flow: Define problem and metric. Get data; explore and clean. Split; engineer features. Train baseline; try better models; tune. Evaluate on test; document. Deploy (API, edge) or hand off.\n\nExample projects: Tabular: predict churn or sales (Kaggle Telco Churn, sklearn pipeline). Vision: classify product images (ResNet transfer learning, 5 classes). NLP: sentiment or support ticket routing (DistilBERT fine-tune). Keep scope small; get one pipeline working end-to-end.\n\n**3. Explanation:** Pipeline chains preprocessing and model so fit/predict are consistent. Train/test split prevents leakage; fit on train only (scaler, encoder, model). Save model with joblib (sklearn) or torch.save (PyTorch); load in inference script.\n\n**4. Application:** Real case: Churn prediction. Data: 7K rows, 20 features, binary target. Pipeline: impute missing, scale, RandomForest. train_test_split(0.2); cross_val_score(5-fold, f1); fit on full train; save with joblib. Inference: load pipeline, predict(new_row). F1 ~0.75. Deploy: FastAPI endpoint loads model, predicts on POST.\n\n**5. How to implement:** (1) sklearn: build a Pipeline that chains preprocessing (e.g. StandardScaler, SimpleImputer) and the model (e.g. LogisticRegression, RandomForest); fit on X_train, y_train; save with joblib.dump(pipeline, 'model.joblib'). (2) Load for inference: pipeline = joblib.load('model.joblib'); predict with pipeline.predict(X_new)—the same scaler and model are applied. (3) PyTorch: after training save with torch.save(model.state_dict(), 'model.pt'); when loading create the same model architecture then model.load_state_dict(torch.load('model.pt')). (4) Inference in PyTorch: model.eval(); with torch.no_grad(): pred = model(x) so dropout is disabled and gradients are not computed. (5) Document: data source, features used, train/test split, metric, and how to run (e.g. python predict.py --input data.csv). (6) Optional: wrap in an API (FastAPI/Flask) that loads the model once and predicts on POST requests. See code below.\n\n**6. Logic & how the code works:**\n\nA pipeline chains preprocessing and model so that fit() runs on the same data flow as predict(); when you save the pipeline you save both scaler and model, so at inference you load one object and call predict(new_data) without re-fitting. model.eval() and torch.no_grad() disable dropout and gradient computation so inference is fast and deterministic.\n\n**7. Example problem & solution:** Problem: Build churn predictor end-to-end. Solution: (1) Load CSV; explore and clean (drop high-missing columns, fill median). (2) Split 80/20; fit StandardScaler on train; transform train and test. (3) LogisticRegression or RandomForest; cross_val_score(f1_macro). (4) Save pipeline with joblib. (5) Inference script: load pipeline, input dict → DataFrame, predict, return label. (6) Document: data source, features, metric, how to run.\n\n**8. Additional information:** MLflow for experiment tracking. DVC for data versioning. FastAPI or Flask for API. Docker for deployment. A/B test model in production.",
          codeExample:
            "# sklearn: Pipeline and save/load\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nimport joblib\npipe = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression())])\npipe.fit(X_train, y_train)\njoblib.dump(pipe, 'model.joblib')\nloaded = joblib.load('model.joblib')\npred = loaded.predict(X_new)",
          codeLanguage: "python",
        },
      ],
    },
    {
      title: "System Design & DevOps",
      slug: "system-design-devops",
      description:
        "Design and operate systems at scale: vertical and horizontal scaling, load balancing and caching (e.g. Redis), microservices and service boundaries, REST and gRPC and message queues, CAP and consensus and replication, IaaS/PaaS and Docker and containers, and CI/CD pipelines with automated tests and deployment strategies.",
      order: 8,
      published: true,
      items: [
        {
          title: "System Design",
          description:
            "Vertical vs horizontal scaling; load balancers and health checks; caching with Redis and cache strategies",
          order: 0,
          imageUrl:
            "https://placehold.co/800x400/1e3a8a/white?text=Scaling+%26+Caching",
          content:
            "**1. Learning flow:** (1) Read material on vertical vs horizontal scaling, load balancers (round-robin, health checks), and caching (cache-aside, TTL, invalidation). (2) Draw a high-level diagram: clients → load balancer → 3 app servers → database; add a Redis (or Memcached) layer and show where read requests go (cache first; on miss, DB then populate cache). (3) Trace one read request: client → LB → app → GET cache; on miss app → SELECT from DB → SET cache with TTL → return; on write trace DB update → cache DEL or SET. (4) Real case: e-commerce site with 10K RPS—decide vertical vs horizontal; add LB and 3+ app instances; cache hot product and session data in Redis with a clear key strategy and TTL. (5) Consider: what to cache (hot keys, sessions), when to invalidate (on write), and how to avoid stampede (many misses at once).\n\n**2. Material:** Scale vertically (bigger machine) until expensive or impossible; then scale horizontally (more machines) with load balancer and shared state in DB/cache.\n\nVertical scaling: Add CPU, RAM, disk to one machine. Simple but has limits (hardware ceiling) and single point of failure. Use for early stage or single-node workloads.\n\nHorizontal scaling: Add more servers behind a load balancer (LB). LB distributes traffic: round-robin (equal), least connections (balance load), hash-based (sticky session). Health checks: LB pings /health; stops sending to unhealthy instances.\n\nCaching: Store frequently read data in fast storage (Redis, Memcached) to reduce DB load and latency. Cache-aside: app checks cache first; on miss, fetch from DB and populate cache; on write, update DB and invalidate or update cache. TTL avoids stale data. Use for: sessions, hot keys (e.g. trending items), API responses.\n\n**3. Explanation:** Vertical hits physical limits; horizontal scales indefinitely. LB is single point of failure—use multiple LBs or managed LB (AWS ELB, GCP LB). Cache reduces DB load; invalidation is hard—use TTL or event-driven invalidation.\n\n**4. Application:** Real case: Social feed. Read-heavy; cache user timeline in Redis with 5-min TTL. Write: new post → invalidate that user's timeline in cache. LB: 3 app servers; health check every 10s. DB: primary + read replicas for scaling reads.\n\n**5. How to implement:** (1) Load balancer: use nginx, HAProxy, or a cloud LB (AWS ELB, GCP LB); configure upstream servers and health check (e.g. GET /health every 10s); choose algorithm (round-robin, least_conn, or hash for sticky session). (2) Redis: in your app use a Redis client (e.g. ioredis in Node); for cache-aside on read: GET key; if miss then fetch from DB, SET key with value and TTL (e.g. 60s), return value. (3) On write: after updating the DB, DEL the cache key (or SET with the new value) so the next read gets fresh data or triggers a miss and reload. (4) Define a cache key strategy (e.g. user:123:profile, item:456) and document TTLs per key type so the team knows staleness. (5) Monitor: cache hit rate and latency; if hit rate is low, check key design and TTL. (6) For production use a managed Redis (ElastiCache, Redis Cloud) and consider connection pooling. See code below.\n\n**6. Logic & how the code works:**\n\nCache-aside: the app checks the cache first; on a miss it loads from the DB and writes to the cache so the next request hits the cache. When data is updated you must invalidate (DEL) or update the cache so clients do not see stale data. TTL (time-to-live) limits how long an entry stays in cache and avoids permanent staleness.\n\n**7. Example problem & solution:** Problem: DB overloaded; 80% reads are same 100 items. Solution: Cache top 100 in Redis. Cache-aside: GET from Redis; miss → SELECT from DB → SET in Redis (TTL 60s). Writes: UPDATE DB → DEL key in Redis. Latency drops; DB load down 80%.\n\n**8. Additional information:** Write-through: update cache and DB together. Write-behind: queue writes. Cache stampede: many requests miss at once—use locking or probabilistic early expiry. Consider CDN for static assets.",
        },
        {
          title: "Microservices & APIs",
          description:
            "Splitting by domain; REST vs gRPC; async messaging with queues (e.g. RabbitMQ, Kafka)",
          order: 1,
          imageUrl:
            "https://placehold.co/800x400/2563eb/white?text=Microservices+REST+gRPC",
          content:
            "**1. Learning flow:** (1) Read material and service boundaries. (2) Draw two services: Order and Inventory; show REST call (order creates) and async message (order placed → send email). (3) Compare REST vs gRPC for internal APIs. (4) Real case: Monolith split into user, order, notification services.\n\n**2. Material:** Microservices own one domain (e.g. user, order, payment); they communicate via APIs (sync) or messages (async). Choose boundaries so changes are localized.\n\nService boundaries: By business capability (user, order, payment) or subdomain (DDD). Each service has its own DB—no shared DB across services. APIs: REST (HTTP, JSON) for broad compatibility and tooling; gRPC (HTTP/2, binary, protobuf) for performance and strong contracts.\n\nAsync messaging: Message queue (RabbitMQ, SQS): producer sends; consumer(s) process; decouples and buffers. Use for non-urgent work (emails, notifications) or multiple consumers. Kafka: append-only log of events; many consumers read independently; replay for reprocessing. Use for event sourcing, audit, high throughput.\n\nTrade-offs: Microservices add network latency, eventual consistency, distributed tracing, and ops complexity. Use when teams or scale justify it.\n\n**3. Explanation:** Sync (REST/gRPC): caller waits; simple but coupling. Async (queue): fire-and-forget; decouples but eventual consistency. Saga pattern for distributed transactions across services.\n\n**4. Application:** Real case: E-commerce. Order service: create order (REST from frontend); publish OrderPlaced event (Kafka). Inventory service: consume event, reserve stock. Notification service: consume event, send email. Each service has own DB; no shared tables.\n\n**5. How to implement:** (1) REST API: build with Express (Node) or FastAPI (Python); define routes (e.g. POST /orders, GET /orders/:id); document with OpenAPI/Swagger so clients and frontend can generate types. (2) gRPC: write a .proto file with service and message definitions; use the compiler to generate client and server code; implement the server methods and call from clients; use for internal services when you need performance and strong contracts. (3) RabbitMQ (or SQS): create a connection and channel; producer: channel.publish(exchange, routingKey, buffer); consumer: channel.consume(queue, (msg) => { process(msg); ack(msg); }); use queues for decoupling and retries. (4) Kafka: producer: send messages to a topic with key (optional) and value; consumer: subscribe to topic with a consumer group so each message is processed by one consumer in the group; use for event log and multiple consumers. (5) When splitting a monolith: identify bounded contexts (e.g. order, inventory, notification); give each its own DB and API or events; start with sync REST for critical path and async messages for side effects (email, analytics). See code below.\n\n**6. Logic & how the code works:**\n\nREST is synchronous: the caller waits for the response. With a message queue, the order service publishes an event and returns; the inventory and notification services consume the event asynchronously, so the system is decoupled and can scale consumers independently. Kafka keeps a log of events so multiple consumers can read at their own pace or replay.\n\n**7. Example problem & solution:** Problem: Order and inventory in monolith; need to scale independently. Solution: Split. Order service: POST /orders; on success, publish OrderPlaced(orderId, items). Inventory service: consume OrderPlaced, call reserve(items); on failure, publish OrderFailed. Order service handles OrderFailed (compensate).\n\n**8. Additional information:** API gateway for external clients. Service mesh (Istio) for mTLS and observability. Event-driven: prefer events for cross-service; REST for client-to-service.",
        },
        {
          title: "Distributed Systems",
          description:
            "CAP theorem; consensus (Paxos, Raft); replication (leader-follower); strong vs eventual consistency",
          order: 2,
          imageUrl:
            "https://placehold.co/800x400/16a34a/white?text=CAP+Consistency",
          content:
            "**1. Learning flow:** (1) Read material and CAP trade-offs. (2) For a chat app, choose strong vs eventual consistency and justify. (3) Trace leader-follower replication: write to primary, read from replica. (4) Real case: Multi-region DB—tune consistency vs latency.\n\n**2. Material:** In a distributed system you cannot have consistency, availability, and partition tolerance all at once (CAP). Partition = network split; you must tolerate it. So choose: CP (consistent but may be unavailable) or AP (available but may be inconsistent). In practice: quorum reads/writes (W + R > N) for tunable consistency.\n\nReplication: Leader-follower: one primary takes writes; replicas replicate asynchronously; reads can go to replicas (eventual consistency). Leader election (Raft, Paxos) when primary fails. Multi-leader or leaderless (Dynamo) for multi-datacenter.\n\nConsensus: Paxos, Raft: agree on a value across nodes (who is leader, what is committed). Used in etcd, Consul, DB replication.\n\nConsistency models: Strong (linearizable): after write, all reads see it. Eventual: if no new writes, all replicas eventually agree. Read-your-writes: user sees their own writes.\n\n**3. Explanation:** CAP is often misunderstood: during partition you choose CP or AP; in normal operation you can have both. Quorum (e.g. W=2, R=2, N=3) gives consistency if W+R>N.\n\n**4. Application:** Real case: Chat. Messages: eventual consistency OK (late delivery acceptable). Read receipts: stronger (read-your-writes). Real case: Banking. Balance: strong consistency (CP); accept unavailability during partition over wrong balance.\n\n**5. How to implement:** (1) Use a managed database with replication (e.g. RDS with read replicas, DynamoDB with global tables); configure read preference so reads can go to secondary (eventual consistency) or primary (strong consistency) depending on the use case. (2) In your app: for critical reads (e.g. balance after write) read from primary or use read-your-writes semantics; for non-critical reads (e.g. feed) read from replica to reduce load. (3) Document in your API which endpoints are strongly consistent vs eventually consistent so clients know what to expect. (4) For custom distributed state (e.g. coordination) use a Raft-based store like etcd or Consul. (5) In system design interviews: state the consistency model you need (e.g. chat messages → eventual; financial balance → strong) and justify; mention quorum (W+R>N) if asked how to tune. See code below.\n\n**6. Logic & how the code works:**\n\nLeader-follower replication: writes go to the primary; the primary streams changes to replicas. Reads from replicas may be slightly stale (eventual consistency) but reduce load on the primary. During a partition, CAP forces a choice: either keep consistency (reject writes) or keep availability (allow writes but risk inconsistency). Quorum (W + R > N) lets you tune this.\n\n**7. Example problem & solution:** Problem: Chat app; users in different regions. Solution: Eventual consistency for messages. Write to nearest region; async replicate. User may see delay (few hundred ms) but availability is high. For critical ops (e.g. delete account), use strong consistency.\n\n**8. Additional information:** PACELC extends CAP: if Partition, choose A or C; Else (no partition), choose Latency or Consistency. Dynamo-style: tunable consistency per request.",
        },
        {
          title: "Cloud & DevOps",
          description:
            "IaaS (VMs) vs PaaS (managed services); containers and Docker; when to use what",
          order: 3,
          imageUrl:
            "https://placehold.co/800x400/ea580c/white?text=Docker+Containers",
          content:
            '**1. Learning flow:** (1) Read material and IaaS vs PaaS vs containers. (2) Write a minimal Dockerfile for a Node or Python app; build and run locally. (3) Deploy to PaaS (Heroku, Vercel) or cloud run (Cloud Run, ECS). (4) Real case: App needs consistent env from dev to prod—Docker solves it.\n\n**2. Material:** IaaS gives you VMs; PaaS gives you runtimes and DBs without managing OS; containers (Docker) package app + dependencies for consistent runs anywhere.\n\nIaaS (EC2, GCE, Azure VM): You get a VM; you install OS, runtime, patches. Full control; you manage scaling, backups. Use when you need custom setup or compliance.\n\nPaaS (Heroku, App Engine, Elastic Beanstalk): You deploy code; platform handles runtime, scaling, sometimes DB. Less control; faster to ship. Use for quick iteration and small teams.\n\nDocker: Image = filesystem + config; container = running instance. Dockerfile: FROM base; COPY app; CMD run. Build once; run on dev, CI, or cloud. Same env everywhere. Orchestration: Kubernetes schedules containers; handles scaling, rolling updates, service discovery. Managed K8s: EKS, GKE, AKS.\n\n**3. Explanation:** Containers share host kernel; VMs virtualize hardware. Containers start faster, use less memory. PaaS abstracts containers; you focus on code. K8s for portability and control.\n\n**4. Application:** Real case: Team ships Node app. Dev: Docker Compose. CI: build image, push to registry. Prod: Cloud Run (serverless container) or ECS. Same image everywhere; no "works on my machine."\n\n**5. How to implement:** (1) Write a Dockerfile: FROM node:20-alpine (or python:3.11-slim for Python); WORKDIR /app; COPY package*.json . (or requirements.txt); RUN npm ci --only=production (or pip install -r requirements.txt); COPY . .; EXPOSE 3000; CMD ["node", "server.js"]. (2) Add .dockerignore to exclude node_modules, .git, and other unneeded files so the build context is small. (3) Build: docker build -t myapp:latest . (4) Run locally: docker run -p 3000:3000 --env-file .env myapp (pass env vars or use -e). (5) For production: push image to a registry (Docker Hub, ECR, GCR); deploy to Cloud Run, ECS, or Kubernetes using the same image. (6) Use multi-stage builds if you need a build step (e.g. compile TypeScript) so the final image only has runtime deps. See code below.\n\n**6. Logic & how the code works:**\n\nThe Dockerfile defines the image: base OS, install dependencies, copy app code, set the command. Building the image runs these steps in a clean environment so the same image runs identically on dev, CI, and prod. Containers share the host kernel (unlike VMs), so they start quickly and use less memory; the image is the unit of deployment.\n\n**7. Example problem & solution:** Problem: Prod fails with "module not found"; dev works. Solution: Docker. Dockerfile installs deps in image; no local node_modules. Build image; run same image in prod. Environment parity guaranteed.\n\n**8. Additional information:** Multi-stage builds for smaller images. Use specific base tags (node:20, not node:latest). Scan images for vulnerabilities (Trivy, Snyk).',
          codeExample:
            '# Minimal Node.js Dockerfile\nFROM node:20-alpine\nWORKDIR /app\nCOPY package*.json .\nRUN npm ci --only=production\nCOPY . .\nEXPOSE 3000\nCMD ["node", "server.js"]',
          codeLanguage: "dockerfile",
        },
        {
          title: "CI/CD",
          description:
            "Pipeline: build, test, deploy; automated tests; blue-green and canary deployments",
          order: 4,
          imageUrl:
            "https://placehold.co/800x400/dc2626/white?text=CI%2FCD+Pipeline",
          content:
            '**1. Learning flow:** (1) Read material on CI (build and test on every push), CD (deploy passing builds), pipeline stages (checkout, install, lint, test, build, deploy), and deployment strategies (blue-green, canary). (2) Add a GitHub Action (or GitLab CI) that runs on push: checkout code, install dependencies, run lint and unit tests; ensure the job fails if any step fails. (3) Add a build step (e.g. npm run build or docker build) and optionally push the artifact (e.g. Docker image) to a registry. (4) Add a deploy step that runs on main (or a release tag): deploy to staging automatically; add manual approval for production if required. (5) Real case: on every push run tests in ~1 min; on merge to main deploy to staging; on approval deploy to prod with blue-green so rollback is instant. (6) Use secrets for API keys and registry auth; never log secrets.\n\n**2. Material:**\n\n**CI (continuous integration)** means the codebase is continuously built and tested: on every push or pull request, a pipeline runs (checkout code, install dependencies, lint, run unit tests, build). If any step fails, the pipeline fails and the team sees the problem immediately. That way broken code does not sit in the main branch and integration issues are caught early.\n\n**CD (continuous deployment)** means that passing builds can be deployed automatically (or with a manual approval step) to staging or production. That reduces manual, error-prone deploy steps and makes releases fast and repeatable.\n\n**Pipeline stages (typical order):** Trigger on push or PR. Steps: checkout repository, install dependencies, run linter, run unit tests, build the application, (optionally) run integration tests, build the deployable artifact (e.g. Docker image), push to a registry, deploy to staging, (optionally) run e2e tests, deploy to production (sometimes with manual approval). Tools: GitHub Actions, GitLab CI, Jenkins, or cloud-native (AWS CodeBuild, Google Cloud Build).\n\n**Tests in the pipeline:** Unit tests (fast, isolated, no database or network) run on every push so feedback is quick. Integration tests (real or test DB, APIs) often run on merge to main because they are slower. E2E tests (full browser or full stack) run before production deploy because they are the slowest and flakiest; fail the pipeline if they fail so broken flows do not reach users.\n\n**Deployment strategies:** Blue-green: you maintain two identical environments (blue = current prod, green = new version). Deploy to green; when ready, switch traffic from blue to green in one go. Rollback = switch back to blue. Instant and low-risk, but you need double the capacity. Canary: send a small fraction of traffic (e.g. 5%) to the new version; if metrics are good, increase gradually. Reduces blast radius. Rolling: replace instances one by one with the new version; no second full environment, but rollback is slower.\n\n**3. Explanation:** CI gives fast feedback so developers fix issues before they pile up. CD reduces manual steps and "works on my machine" problems by deploying the same artifact that passed tests. Blue-green gives instant rollback; canary limits the impact of a bad release.\n\n**4. Application:** Real case: Web app. On push: lint, unit tests (30s). On merge to main: build, integration tests, deploy to staging (5 min). On approval: deploy to prod (blue-green). Rollback: switch traffic back to blue.\n\n**5. How to implement:** (1) Create .github/workflows/ci.yml (or .gitlab-ci.yml, Jenkinsfile); trigger on push and optionally on pull_request. (2) First job—lint: checkout repo, setup Node (or Python), run npm ci (or pip install), run eslint (or ruff/flake8); fail the job if lint fails. (3) Second job—test: same setup, run npm test (or pytest); fail if tests fail. (4) Third job—build: build the app (e.g. npm run build) or build Docker image and push to registry (use secrets for registry auth). (5) Deploy job: run only on main (or a release tag); deploy to staging (e.g. Heroku, Cloud Run) using secrets; add manual approval for production if required. (6) Use a matrix strategy to test on multiple Node or Python versions; use caching (actions/cache) to speed up installs. See code below.\n\n**6. Logic & how the code works:**\n\nCI works by running the same sequence of steps on every push (or PR). The pipeline is a script: checkout the code, install dependencies, run lint, run tests, build. Each step runs in a clean environment (e.g. a fresh container or VM), so the build is reproducible. If any step fails (e.g. a test fails or lint reports an error), the pipeline stops and later steps (e.g. deploy) do not run. So code that does not pass tests cannot be merged (if you use branch protection) or cannot reach production. That keeps the main branch and production in a known-good state.\n\nBlue-green deployment works by having two full environments that are identical except for the version of the app. You deploy the new version to "green" while "blue" still serves traffic. When the new version is tested and ready, you switch the load balancer (or router) so all traffic goes to green; blue becomes idle. If something goes wrong, you switch traffic back to blue—instant rollback with no need to redeploy. The cost is that you need to run two environments (or at least have capacity for both during the switch).\n\n**7. Example problem & solution:** Problem: Manual deploy causes prod outage; forgot to run tests. Solution: CI/CD. Push triggers tests; merge triggers deploy. No deploy without green tests. Rollback: one click to revert traffic.\n\n**8. Additional information:** Branch protection: require CI to pass before merge. Semantic versioning for releases. Feature flags for decoupling deploy from release.',
          codeExample:
            "# GitHub Actions: lint and test\nname: CI\non: [push]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-node@v4\n        with: { node-version: '20' }\n      - run: npm ci\n      - run: npm run lint\n      - run: npm test",
          codeLanguage: "yaml",
        },
      ],
    },
    {
      title: "Security & Testing",
      slug: "security-testing",
      description:
        "Secure and reliable software: authentication (JWT, OAuth 2, sessions) and authorization (RBAC), input validation and sanitization to prevent XSS and CSRF and SQL injection, unit and integration and e2e testing and TDD, HTTPS and secrets and security headers in deployment, and threat modeling and OWASP secure coding basics. Before you start: basic backend or full-stack experience (e.g. Node or React + API); Database & SQL and Node.js sections help for context.",
      order: 9,
      published: true,
      items: [
        {
          title: "Authentication & Authorization",
          description:
            "How users prove identity (JWT, sessions, OAuth 2) and how you enforce what they can do (RBAC)",
          order: 0,
          imageUrl:
            "https://placehold.co/800x400/059669/white?text=JWT+OAuth+Sessions+RBAC",
          content:
            "**1. Learning flow:** (1) Read material and auth vs authorization. (2) Implement login that returns JWT; add auth middleware; protect one route. (3) Hash a password with bcrypt; compare on login. (4) Real case: API with JWT; frontend stores token; middleware verifies on each request.\n\n**2. Material:** Authentication answers \"who are you?\" (identity); authorization answers \"what are you allowed to do?\" (permissions). Both are needed: first verify identity, then check permissions for the requested action. Always use standard, well-tested schemes and never store passwords in plain text.\n\n**Authentication—Passwords:** Store only a one-way hash (bcrypt, Argon2id), never the plain password. On registration: hash the password with a cost factor (e.g. bcrypt rounds 10–12) and store the hash. On login: compare the user's input with the stored hash using the library's compare function (it hashes the input and compares in a timing-safe way). If an attacker gets the database, they cannot recover passwords from hashes. Use a high cost factor to slow brute-force; consider Argon2id for new applications (OWASP recommendation).\n\n**Authentication—JWT:** After successful login, the server creates a signed token containing a payload (e.g. userId, role, exp). The signature is computed with a secret (or private key) so the server can later verify that the token was not tampered with. The client sends the token on each request (usually Authorization: Bearer <token> or an httpOnly cookie). The server verifies the signature and reads the payload; no database lookup is needed for each request (stateless). Use short-lived access tokens (e.g. 15 minutes) and optional refresh tokens for long sessions; store refresh tokens securely and rotate them. You cannot revoke a JWT before expiry unless you maintain a blocklist or check a revocation store.\n\n**Authentication—Sessions:** The server creates a session (stores user id and optional data in Redis or a database) and sends a session id in an httpOnly cookie. On each request the server looks up the session and gets the user. Pros: you can invalidate a session immediately (logout, revoke all devices). Cons: you need a store and must handle session persistence across servers (sticky sessions or shared store). Good when you need \"logout everywhere\" or strict control.\n\n**Authentication—OAuth 2:** For \"Login with Google/GitHub,\" the user is sent to the provider; after consent, the provider redirects back with an authorization code; your server exchanges the code for an access token and optionally gets user info. You do not handle the user's password; the provider does. Use for social login and when delegating identity to an external IdP.\n\n**Authorization:** After you know who the user is (req.user), check whether they are allowed to perform the action. RBAC (role-based): users have roles (e.g. admin, editor); each role has a set of permissions; before an action (e.g. delete user), check if the user's role includes that permission. ABAC (attribute-based): check attributes of the user and the resource (e.g. \"user.department === resource.ownerDepartment\"). Prefer deny by default: if no rule grants access, deny. Check on every request; do not rely on the client to hide UI for forbidden actions.\n\n**3. Explanation:** JWT is stateless and scales horizontally but is harder to revoke; sessions give immediate revocation but need storage. OAuth delegates identity and reduces your password-handling surface. RBAC is simple and common; ABAC allows fine-grained rules. Always hash passwords and check permissions on the server.\n\n**4. Application:** Real case: E-commerce API. Login: bcrypt hash password; return JWT (userId, role, exp). Protected routes: middleware verifies JWT; extracts user; next(). Admin route: check role === admin before handler.\n\n**5. How to implement:** (1) Password hashing: on registration use bcrypt.hash(password, 10) (or Argon2id) and store the hash; on login use bcrypt.compare(plainPassword, storedHash)—never compare plain text to plain text. (2) JWT: after successful login call jwt.sign({ userId, role }, process.env.JWT_SECRET, { expiresIn: '15m' }); send the token to the client (body or httpOnly cookie). (3) Auth middleware: read token from Authorization header (Bearer <token>) or cookie; call jwt.verify(token, secret); on success set req.user = payload and next(); on failure return 401. (4) Protect routes: apply the middleware to all routes that need auth (e.g. app.use('/api', authMiddleware) or per-route app.get('/me', auth, handler)). (5) Authorization: after auth, check req.user.role or permissions before performing the action (e.g. if (req.user.role !== 'admin') return 403). (6) Use env for JWT_SECRET; never log tokens or passwords. See code below.\n\n**6. Logic & how the code works:**\n\nPassword hashing is one-way; you never compare plain text to plain text in the DB—you compare the user's input to the stored hash with bcrypt.compare, which hashes the input and compares safely. JWT is signed with a secret; anyone with the secret can verify that the payload (e.g. userId) was not tampered with. Middleware runs before the route handler; if verification fails you respond 401 and never call next(), so protected routes only run when the token is valid.\n\n**7. Example problem & solution:** Problem: Protected route; unauthenticated returns 500. Solution: Auth middleware. Read token from Authorization header. If missing or invalid: res.status(401).json({ error: 'Unauthorized' }); return. Else: req.user = payload; next(). All protected routes use this middleware.\n\n**8. Additional information:** Use env for JWT_SECRET. Short-lived access token + long-lived refresh token. httpOnly cookie for token reduces XSS risk. OWASP: use Argon2id for new apps; bcrypt acceptable.",
          codeExample:
            "// JWT auth middleware\nconst auth = (req, res, next) => {\n  const token = req.headers.authorization?.split(' ')[1];\n  if (!token) return res.status(401).json({ error: 'No token' });\n  try {\n    req.user = jwt.verify(token, process.env.JWT_SECRET);\n    next();\n  } catch (e) { res.status(401).json({ error: 'Invalid token' }); }\n};\napp.get('/me', auth, (req, res) => res.json(req.user));",
          codeLanguage: "javascript",
        },
        {
          title: "Input Validation & Sanitization",
          description:
            "Prevent XSS, CSRF, and SQL injection; validate and sanitize all inputs; use safe libraries",
          order: 1,
          imageUrl:
            "https://placehold.co/800x400/dc2626/white?text=Security+Vulnerabilities",
          content:
            "**1. Learning flow:** (1) Read material and three main injection types. (2) Add express-validator for POST body; return 400 on invalid. (3) Ensure one query uses parameters (never string concat). (4) Real case: User search—parameterized query prevents SQL injection.\n\n**2. Material:** Never trust client input. Validate (type, format, range); sanitize (escape or parameterize); use safe APIs so injection cannot happen.\n\nXSS: Attacker injects script into page; runs in victim's browser. Prevent: escape output (encode <, >, \", ') when rendering user content. React escapes by default. Content-Security-Policy header limits script sources. Avoid dangerouslySetInnerHTML with user input.\n\nCSRF: Attacker tricks user's browser into sending request with user's cookies. Prevent: SameSite cookie; CSRF token in form or header; check Origin/Referer header.\n\nSQL injection: Attacker puts SQL in input; executed by DB. Prevent: parameterized queries only (never concatenate). Use ORM (Prisma, Sequelize) or prepared statements. Example: db.query('SELECT * FROM users WHERE id = ?', [id]).\n\nValidation: Check required, type (number, email), range, length. Use express-validator, Joi, Zod. Return 400 with clear field errors. Sanitize before storing or displaying.\n\n**3. Explanation:** Validation catches bad input early. Parameterization separates SQL from data; DB driver escapes. Escaping output prevents XSS. CSRF token proves request came from your form.\n\n**4. Application:** Real case: User registration. Validate: email format, password length (8+), name length. Sanitize: trim whitespace. SQL: INSERT with parameters. Output: escape in email display. Never trust any input.\n\n**5. How to implement:** (1) Validation: add express-validator (or Joi, Zod) to POST/PUT routes; define rules (e.g. body('email').isEmail(), body('password').isLength({ min: 8 })); call validationResult(req) and if !errors.isEmpty() return 400 with the errors array. (2) Sanitize: trim whitespace, normalize email toLowerCase; apply before validation or after. (3) SQL: never concatenate user input into a query; use parameterized queries (e.g. db.query('SELECT * FROM users WHERE id = ?', [id]) or named params); ORMs (Prisma, Sequelize) do this by default. (4) XSS: when rendering user content use framework escaping (React escapes by default) or encode <, >, \", '; avoid dangerouslySetInnerHTML with user input. (5) CSRF: use SameSite cookie attribute; for state-changing forms include a CSRF token and validate it on the server. (6) Document: list all inputs and their validation rules; run npm audit and fix known vulns. See code below.\n\n**6. Logic & how the code works:**\n\nParameterized queries send the SQL structure and the values separately; the database driver binds the values so they are never interpreted as SQL. That prevents injection regardless of what the user types. For XSS, escaping converts < and > to entities so the browser does not execute script. CSRF tokens are unique per session so a request from another site cannot forge a valid token.\n\n**7. Example problem & solution:** Problem: Search by name returns wrong data; input \"'; DROP TABLE users;--\" could break. Solution: Parameterized query. const [rows] = await db.query('SELECT * FROM users WHERE name LIKE ?', ['%' + name + '%']); Driver escapes; no SQL injection.\n\n**8. Additional information:** Whitelist validation (allowed chars) over blacklist. Validate on server; client validation is UX only. OWASP: use parameterized queries; never trust input.",
          codeExample:
            "// express-validator\nconst { body, validationResult } = require('express-validator');\napp.post('/users', [\n  body('email').isEmail(),\n  body('password').isLength({ min: 8 })\n], (req, res) => {\n  const err = validationResult(req);\n  if (!err.isEmpty()) return res.status(400).json({ errors: err.array() });\n  // ... create user\n});\n// Parameterized query\nconst [rows] = await db.query('SELECT * FROM users WHERE id = ?', [req.params.id]);",
          codeLanguage: "javascript",
        },
        {
          title: "Testing",
          description:
            "Unit tests (fast, isolated); integration tests (DB, API); e2e tests (full flow); TDD and mocking",
          order: 2,
          imageUrl:
            "https://placehold.co/800x400/7c3aed/white?text=Testing+TDD",
          content:
            "**1. Learning flow:** (1) Read material and test pyramid. (2) Write one unit test for a pure function (e.g. validateEmail). (3) Write one integration test for an API route (e.g. GET /users/:id) with test DB. (4) Real case: CI runs unit (always), integration (on merge), e2e (before prod).\n\n**2. Material:** Unit tests verify one function or module in isolation (mock deps); integration tests verify components together (real DB or API); e2e tests verify full user flow.\n\nUnit: Test one function. Mock dependencies (DB, HTTP) so test is fast and deterministic. Use Jest, Mocha, Vitest, pytest. Assert on return value or side effects. Aim for high coverage on critical paths. Pure functions are easy to test.\n\nIntegration: Test API endpoints with real or test DB. Seed data; call API; assert response and DB state. Use supertest (Node), pytest + TestClient (Python). Slower; run in CI. Use test DB or in-memory.\n\nE2E: Test in real browser (Playwright, Cypress) or full stack. Few critical flows (login, checkout). Flaky and slow; use for smoke tests. Run before prod deploy.\n\nTDD: Write failing test first; implement until pass; refactor. Helps design and coverage. Mocking: stub (fixed return) or mock (assert calls). Use when real dep is slow or unstable.\n\n**3. Explanation:** Test pyramid: many unit (fast), fewer integration (slower), few e2e (slowest). Unit catches logic bugs; integration catches integration bugs; e2e catches user-facing bugs. Mock at boundaries (DB, HTTP).\n\n**4. Application:** Real case: API for users. Unit: validateEmail, formatUser. Integration: POST /users (create), GET /users/:id (read), auth middleware. E2E: login → create order → checkout. Run unit on every push; integration on merge; e2e nightly.\n\n**5. How to implement:** Jest: describe, it, expect. Mock: jest.fn(), jest.mock(). Supertest: request(app).get('/users/1').expect(200). E2E: Playwright page.goto, page.click, expect. Use beforeAll/afterAll for setup/teardown. See code below.\n\n**6. Logic & how the code works:**\n\nUnit tests mock external dependencies (DB, HTTP) so the function under test runs in isolation and the result depends only on its logic. Integration tests use a real (or test) DB and hit the API; they catch bugs at the boundary (e.g. wrong SQL or missing auth). E2E tests run in a real browser and verify the full flow so they catch UI and integration issues together.\n\n**7. Example problem & solution:** Problem: Refactor breaks API; no tests catch it. Solution: Integration test. Seed user in test DB; GET /users/1; expect 200 and correct body. Now refactor; test catches regression. Add test for edge cases (404, auth).\n\n**8. Additional information:** Test naming: should return 404 when user not found. AAA: Arrange, Act, Assert. One assertion per test when possible. Use factories for test data.",
          codeExample:
            "// Jest unit test\ndescribe('validateEmail', () => {\n  it('returns true for valid email', () => {\n    expect(validateEmail('a@b.com')).toBe(true);\n  });\n});\n// Supertest integration\ntest('GET /users/1 returns user', async () => {\n  const res = await request(app).get('/users/1');\n  expect(res.status).toBe(200);\n  expect(res.body.name).toBeDefined();\n});",
          codeLanguage: "javascript",
        },
        {
          title: "Secure Deployment",
          description:
            "HTTPS only; secrets in env or vault; security headers (CSP, HSTS); minimal surface",
          order: 3,
          imageUrl:
            "https://placehold.co/800x400/1d4ed8/white?text=HTTPS+%26+Secrets",
          content:
            "**1. Learning flow:** (1) Read material and deployment checklist. (2) Add helmet to Express app; verify security headers. (3) Ensure one secret (JWT_SECRET) is read from env and never logged. (4) Real case: Prod app—HTTPS, env vars, helmet, npm audit.\n\n**2. Material:** In production, encrypt traffic (HTTPS), keep secrets out of code, set security headers, and reduce attack surface.\n\nHTTPS: TLS encrypts traffic; certificates prove server identity. Use Let's Encrypt (certbot, acme.sh) or cloud provider. Redirect HTTP to HTTPS. HSTS header (Strict-Transport-Security) tells browser to use HTTPS only. Use TLS 1.2+.\n\nSecrets: Never commit API keys, DB URLs, passwords. Use environment variables or secret manager (AWS Secrets Manager, HashiCorp Vault). Rotate secrets periodically. In CI: use secret variables; never log secrets. Validate required env vars on startup.\n\nSecurity headers: Content-Security-Policy (limit script and resource sources). X-Frame-Options (prevent clickjacking). X-Content-Type-Options: nosniff. Strict-Transport-Security (HSTS). Use helmet (Node) or equivalent. Customize CSP for your app.\n\nSurface: Expose only necessary ports. Keep dependencies updated (npm audit, Dependabot). Run as non-root in container. Limit rate and body size.\n\n**3. Explanation:** HTTPS prevents eavesdropping and tampering. Env vars keep secrets out of git. Helmet sets sensible defaults. Non-root reduces impact of compromise. Audit finds known vulns.\n\n**4. Application:** Real case: Node API. Env: JWT_SECRET, DB_URL from env; fail on missing. Helmet: app.use(helmet()). Reverse proxy (nginx): TLS termination, rate limit. Container: run as non-root. CI: npm audit --audit-level=high fails build.\n\n**5. How to implement:** (1) Load env: require('dotenv').config() (or similar) at app startup; read secrets from process.env.JWT_SECRET, process.env.DATABASE_URL; validate required vars (if (!process.env.JWT_SECRET) throw new Error('JWT_SECRET required')) so the app fails fast if misconfigured. (2) Never log secrets or include them in error messages; never commit .env to git (add to .gitignore). (3) Security headers: use helmet (Node) or equivalent; app.use(helmet()) sets X-Content-Type-Options, X-Frame-Options, and others; customize Content-Security-Policy for your app. (4) TLS: use a reverse proxy (nginx, Caddy) to terminate HTTPS; or deploy on PaaS that provides TLS; redirect HTTP to HTTPS and set HSTS. (5) In containers: run as non-root user; use multi-stage builds to keep image small; run npm audit (or equivalent) in CI and fail on high/critical. (6) Rate limit and body size limits to reduce abuse; keep dependencies updated. See code below.\n\n**6. Logic & how the code works:**\n\nEnv vars are loaded at runtime and are not in the codebase, so they do not appear in git. Helmet sets HTTP headers (e.g. X-Content-Type-Options, CSP) that restrict how the browser handles content and reduce common attacks. Failing startup when a required env var is missing prevents running with an empty or default secret in production.\n\n**7. Example problem & solution:** Problem: API key leaked in git history. Solution: Rotate key; add to .gitignore; use env. Prevent: pre-commit hook to block secrets; git-secrets or gitleaks. Use secret manager for prod.\n\n**8. Additional information:** OWASP deployment checklist. Rate limit per IP. Validate Content-Type. Keep Node and deps updated. Use CSP report-uri for monitoring.",
          codeExample:
            "// Express with helmet and env validation\nrequire('dotenv').config();\nconst secret = process.env.JWT_SECRET;\nif (!secret) throw new Error('JWT_SECRET required');\nconst helmet = require('helmet');\napp.use(helmet());\n// Never log: console.log(secret);",
          codeLanguage: "javascript",
        },
        {
          title: "Cybersecurity Basics",
          description:
            "Threat modeling; encryption at rest and in transit; OWASP Top 10 and secure coding habits",
          order: 4,
          imageUrl:
            "https://placehold.co/800x400/4338ca/white?text=Security+Best+Practices",
          content:
            "**1. Learning flow:** (1) Read material and threat modeling. (2) List three assets in your app (e.g. user data, API keys, admin access) and one threat for each. (3) Review OWASP Top 10; name one item and how your app addresses it. (4) Real case: E-commerce—protect PII, payment, admin.\n\n**2. Material:** Security is about understanding who might attack, what they want, and how they might do it; then applying controls (encryption, validation, least privilege) to reduce risk. Threat modeling structures that thinking; OWASP Top 10 is a practical checklist of the most common web application risks.\n\n**Threat modeling:** (1) Identify assets: data (PII, payment, credentials), services (admin panel, API), and reputation. (2) Identify threats: who are the attackers (script kiddie, motivated attacker, insider)? What do they want (data theft, disruption, privilege escalation)? (3) Identify vulnerabilities: missing auth, SQL concatenation, default passwords, verbose errors. (4) Prioritize by impact (what happens if exploited?) and likelihood. (5) Mitigate: for each high-priority risk, add a control (e.g. parameterized queries for injection, strong auth and MFA for broken auth, encryption for data exposure). Document the model and review it when the system changes.\n\n**Encryption:** In transit: use TLS (HTTPS) so data between client and server is encrypted and tampering is detected; use TLS 1.2 or 1.3 and strong ciphers. At rest: encrypt sensitive fields in the database (e.g. AES with a key from a key manager) or rely on full-disk encryption; ensure keys are not stored with the data and are rotated periodically. Passwords: store only one-way hashes (bcrypt, Argon2); never reversible encryption for passwords. Use a key management service (AWS KMS, HashiCorp Vault) or env vars for keys; never hardcode keys in source.\n\n**OWASP Top 10 (summary):** (1) Injection—attackers send SQL or other code in input; mitigate with parameterized queries and input validation. (2) Broken authentication—weak passwords, session fixation; use strong hashing, MFA, secure session handling. (3) Sensitive data exposure—logging or transmitting secrets; encrypt at rest and in transit, minimize what you log. (4) Broken access control—missing checks; enforce authorization on every request, deny by default. (5) Security misconfiguration—default credentials, verbose errors; use secure defaults, disable debug in production. (6) Vulnerable components—known CVEs in dependencies; update regularly, run npm audit / Snyk. (7) Identification and authentication failures—overlaps with (2); strong auth and session management. (8) Software and data integrity failures—insecure deserialization, unsigned updates; validate and verify. (9) Security logging and monitoring failures—can't detect or investigate; log auth events, access denials, errors. (10) Server-side request forgery (SSRF)—validate and restrict outbound requests. Use the list as a checklist when building or reviewing an app.\n\n**Secure coding habits:** Principle of least privilege: give each component and user the minimum access needed. Fail secure: on error (e.g. exception in auth check), deny access rather than allow. Never trust input: validate and sanitize all input; use allowlists where possible. Log security-relevant events (login success/failure, access denied, config changes) for auditing and incident response. Defense in depth: do not rely on a single control; combine auth, validation, encryption, and monitoring.\n\n**3. Explanation:** Threat modeling focuses your effort on the risks that matter. OWASP Top 10 reminds you of common gaps. Encryption protects confidentiality and integrity; auth and authorization protect access; validation and parameterization prevent injection. Layering controls (e.g. auth + encryption + logging) limits damage if one control fails.\n\n**4. Application:** Real case: User data. Assets: email, password hash, profile. Threats: SQL injection, stolen creds, XSS. Mitigations: parameterized queries, bcrypt, output escape, rate limit login.\n\n**5. How to implement:** (1) Threat model: list assets (user data, API keys, admin access), threats (injection, auth bypass, data exposure), and mitigations (parameterized queries, strong auth, encryption); document and review when the system changes. (2) OWASP Top 10: go through each item (injection, broken auth, sensitive data exposure, broken access control, misconfiguration, vulnerable components, etc.) and ensure your app has controls (e.g. parameterized queries, bcrypt, HTTPS, auth checks, helmet, npm audit). (3) Dependencies: run npm audit (or pip-audit, Snyk) regularly; fix high and critical; use Dependabot or Renovate for PRs. (4) Sensitive data: encrypt at rest for high-sensitivity fields if required; use TLS for all traffic; never log passwords or tokens. (5) Logging: log login failures, access denials, and security-relevant events (who, what, when) for audit and incident response. (6) Least privilege: DB user should have only needed permissions; app should run as non-root; file permissions minimal. See code below.\n\n**6. Logic & how the code works:**\n\nThreat modeling lists assets (what to protect) and threats (who might attack and how); each mitigation maps to a control (e.g. parameterized queries for injection, bcrypt for passwords). OWASP Top 10 is a checklist so you don't forget common gaps. Encryption in transit (TLS) and at rest (encrypted fields or disk) ensures data is unreadable even if intercepted or the DB is stolen.\n\n**7. Example problem & solution:** Problem: App has no security review. Solution: Threat model. Assets: user data, admin. Threats: injection, auth bypass. Mitigations: add parameterized queries, auth middleware, helmet. Run npm audit. Fix high/critical. Document in security doc.\n\n**8. Additional information:** OWASP Cheat Sheet Series. Bug bounty for disclosure. Penetration testing for critical apps. Incident response plan.",
        },
      ],
    },
    {
      title: "Programming Languages",
      slug: "programming-languages",
      description:
        "Use the right language for interviews and projects: C++ (STL, RAII, smart pointers), Python (types, OOP, decorators, standard library, pip), Java (classes, interfaces, exceptions, Collections, streams), and practice with common patterns and idiomatic code in each language. Before you start: you should already know at least one of these languages at a beginner level; this section deepens and standardizes your knowledge for interviews.",
      order: 10,
      published: true,
      items: [
        {
          title: "C++",
          description:
            "Syntax and types; STL (vector, map, set); OOP and RAII; smart pointers (unique_ptr, shared_ptr); error handling",
          order: 0,
          imageUrl:
            "https://placehold.co/800x400/1e3a8a/white?text=C%2B%2B+STL+%26+RAII",
          content:
            '**1. Learning flow:** (1) Read material and STL containers. (2) Implement a class with RAII (e.g. file handle); use vector and map. (3) Write a small program: two pointers, sort, lower_bound. (4) Real case: Interview problem—vector, map, smart pointers.\n\n**2. Material:** C++ gives control and performance; use STL for data structures, RAII for resource safety, and smart pointers to avoid manual delete.\n\nSyntax: Strong typing; compile with g++ or clang++. Loops, conditionals, functions. Pass by value, reference (&), const reference. Pointers and references.\n\nSTL: vector (dynamic array, O(1) push_back), map (ordered key-value, O(log n)), unordered_map (hash, O(1) avg), set (unique sorted), queue, stack. Iterators; range-based for. Algorithm: sort, find, lower_bound, next_permutation. Use for interviews.\n\nOOP: Classes with public/private. Constructors and destructors. Inheritance and virtual functions (polymorphism).\n\nRAII: Resource (memory, file) tied to object lifetime; constructor acquires, destructor releases. No leak if you don\'t forget to free. Use smart pointers for memory.\n\nSmart pointers: unique_ptr (one owner, move-only), shared_ptr (reference count). No raw new/delete for ownership. Use make_unique, make_shared.\n\nError handling: Exceptions (throw, try/catch). Use for exceptional cases; avoid in tight loops.\n\n**3. Explanation:** STL abstracts data structures; use it instead of hand-rolling. RAII guarantees cleanup on scope exit. Smart pointers prevent leaks and double-free.\n\n**4. Application:** Interviews: vector for arrays, map for lookups, queue for BFS. Projects: RAII for resources; smart pointers for dynamic memory.\n\n**5. How to implement:** (1) Include headers: #include <vector>, <map>, <unordered_map>, <algorithm>; use std::vector for dynamic arrays, std::map (or unordered_map for O(1)) for key-value. (2) Vector: vector<int> v; v.push_back(x); sort(v.begin(), v.end()); use lower_bound for binary search; range-for for (int x : v). (3) Map: map<string,int> m (ordered) or unordered_map for hash; m["key"] = 1; m.find("key") != m.end(); use for Two Sum and frequency. (4) Smart pointers: prefer make_unique<T>() and make_shared<T>(); no raw new/delete for ownership; unique_ptr for single owner, shared_ptr when shared. (5) RAII: wrap resources (file, socket) in a class; acquire in constructor, release in destructor so cleanup is automatic. (6) For interviews: practice two pointers, sort, binary search, and BFS/DFS with queue/stack from STL. See code below.\n\n**6. Logic & how the code works:**\n\nSTL vector and map hide allocation and iteration; sort() uses comparison so you get O(n log n) without writing a sort. unique_ptr owns one object; when it goes out of scope the destructor frees the memory (RAII), so you avoid manual delete and double-free. Two Sum with unordered_map: in one pass, for each x check if (target - x) was already seen; if yes return both indices; otherwise record x and continue.\n\n**7. Example problem & solution:** Problem: Two Sum. Solution: unordered_map<int,int> seen; for each x, if target-x in seen return {seen[target-x], i}; else seen[x]=i. O(n) time, O(n) space. Problem: Top K. Solution: min-heap (priority_queue with greater).\n\n**8. Additional information:** Use auto when type is obvious. const correctness. Move semantics for efficiency. C++17: structured bindings.',
          codeExample:
            '// STL: vector, map, sort\nvector<int> v = {3,1,2};\nsort(v.begin(), v.end());\nmap<string,int> m;\nm["a"] = 1;\n// Smart pointer\nauto p = make_unique<int>(42);\n// RAII file\nifstream f("file.txt");\nstring line;\nwhile (getline(f, line)) { /* ... */ }',
          codeLanguage: "cpp",
        },
        {
          title: "Python",
          description:
            "Syntax, types, and data structures; OOP and decorators; try/except; standard library and pip",
          order: 1,
          imageUrl:
            "https://placehold.co/800x400/16a34a/white?text=Python+%26+OOP",
          content:
            "**1. Learning flow:** (1) Read material and data structures. (2) Write a class with __init__ and one method; use list comprehension and collections.Counter. (3) Add @lru_cache to a recursive function (e.g. Fibonacci). (4) Real case: Interview—list, dict, Counter, enumerate, zip.\n\n**2. Material:** Python is readable and fast to write; use lists and dicts, leverage the standard library, and use virtual environments and pip.\n\nSyntax: Indentation for blocks. Types are dynamic; add type hints (def f(x: int) -> str). List, dict, set, tuple. List comprehensions [x*2 for x in arr if x>0]. Loops and conditionals.\n\nOOP: class MyClass:; __init__(self); self.attr; inheritance; super(). Methods, @staticmethod, @classmethod.\n\nDecorators: Functions that wrap other functions. @decorator above def. Use for logging, caching, auth. @functools.lru_cache for memoization.\n\nErrors: try/except/finally. raise ValueError('msg'). Catch specific exceptions; avoid bare except.\n\nStandard library: os, sys, json, datetime, collections (defaultdict, Counter), itertools, heapq. pip install for third-party. Use venv or conda.\n\n**3. Explanation:** List comprehension is concise and often faster than loop. Counter for frequency; defaultdict for missing keys. lru_cache memoizes recursive calls.\n\n**4. Application:** Interviews: list, dict, Counter, enumerate, zip, heapq. Projects: venv for isolation; pip freeze > requirements.txt.\n\n**5. How to implement:** (1) Lists: use lst.append(x) to add; lst[i] to access; list comprehensions [x*2 for x in arr if x>0] for building lists from iterables. (2) Dict: d[key] or d.get(key, default) for lookup; d[key] = value to set; use dict for Two Sum (store value → index) and for frequency (value → count). (3) Counter: from collections import Counter; freq = Counter(lst); freq.most_common(k) returns the k most frequent (value, count) pairs; use for top-K frequency problems. (4) enumerate and zip: for i, x in enumerate(arr) when you need index and value; for a, b in zip(list1, list2) to iterate two lists in parallel. (5) Memoization: @functools.lru_cache(maxsize=None) on a recursive function (e.g. Fibonacci) so repeated arguments return cached result; use when the same subproblem appears many times. (6) Heaps: import heapq; heapq.heappush(h, x); heapq.heappop(h) for min-heap; negate values for max-heap. See code below.\n\n**6. Logic & how the code works:**\n\nDict lookup is O(1) average; in one pass you store each number and its index, and for the next number you check if the complement (target - x) is already in the dict. Counter counts occurrences in one pass; most_common(k) returns the k most frequent. lru_cache stores return values for arguments so repeated fib(n) reuses results instead of recursing again.\n\n**7. Example problem & solution:** Problem: Two Sum. Solution: d = {}; for i, x in enumerate(nums): if target-x in d: return [d[target-x], i]; d[x]=i. Problem: Top K frequent. Solution: Counter(nums).most_common(k). Problem: Fibonacci. Solution: @lru_cache; return n if n<2 else fib(n-1)+fib(n-2).\n\n**8. Additional information:** Use pathlib over os.path. dataclasses for simple classes. Type hints for IDE support.",
          codeExample:
            "# List comprehension, Counter\nfrom collections import Counter\narr = [1,2,2,3]\nsquares = [x**2 for x in arr if x>0]\nfreq = Counter(arr).most_common(2)\n# enumerate, zip\nfor i, x in enumerate(arr): print(i, x)\nfor a, b in zip(list1, list2): print(a, b)\n# lru_cache\nfrom functools import lru_cache\n@lru_cache(maxsize=None)\ndef fib(n): return n if n<2 else fib(n-1)+fib(n-2)",
          codeLanguage: "python",
        },
        {
          title: "Java",
          description:
            "Syntax, classes and interfaces, inheritance; exceptions; Collections and streams",
          order: 2,
          imageUrl:
            "https://placehold.co/800x400/dc2626/white?text=Java+%26+Collections",
          content:
            "**1. Learning flow:** (1) Read material and Collections vs Streams. (2) Define an interface and one implementation; use HashMap and one stream operation. (3) Write Two Sum and Group By using HashMap and stream. (4) Real case: Interview—Collections, streams, Optional.\n\n**2. Material:** Java is statically typed and object-oriented; use interfaces for abstraction, Collections for data structures, and streams for concise processing.\n\nSyntax: Classes in files; public static void main. Primitive and reference types. Loops, conditionals, arrays. Strong typing; compile with javac.\n\nClasses and interfaces: class A extends B implements I. Interface = contract (methods without body). Abstract class can have implementation. Use interfaces for dependency inversion.\n\nExceptions: Checked (must handle or declare) vs unchecked. try/catch/finally; throw new Exception(). Prefer specific catches.\n\nCollections: List (ArrayList, LinkedList), Set (HashSet, TreeSet), Map (HashMap, TreeMap). Generics: List<String>. Iterate with for-each or iterator.\n\nStreams: list.stream().filter(...).map(...).collect(Collectors.toList()). Optional for nullable. Use for readable pipelines. Collectors.groupingBy for group by.\n\n**3. Explanation:** Interfaces enable polymorphism and testing. Collections provide standard data structures. Streams reduce boilerplate for transformations.\n\n**4. Application:** Interviews: HashMap for lookups, stream for filtering/mapping. Projects: interface-based design for testability; streams for data pipelines.\n\n**5. How to implement:** (1) HashMap: Map<K,V> map = new HashMap<>(); map.put(key, value); map.get(key); map.containsKey(key); use for Two Sum (value → index) and frequency. (2) Lists: List<String> list = new ArrayList<>(); list.add(x); list.get(i); use ArrayList for dynamic arrays. (3) Streams: list.stream().filter(x -> x > 0).map(x -> x * 2).collect(Collectors.toList()); use filter for condition, map for transformation, collect to gather; groupingBy for group-by-key. (4) Optional: Optional.ofNullable(x).orElse(default) for nullable handling; use when a method can return null. (5) Two Sum: in one pass, for each element check if (target - element) is in the map; if yes return indices; else put (element, index). (6) Interfaces: define interface for key behaviors so you can swap implementations and test with mocks; e.g. interface UserRepo { User findById(long id); }. See code below.\n\n**6. Logic & how the code works:**\n\nHashMap gives O(1) average get/put; for Two Sum you store each number and its index as you go, and for each new number you check if (target - number) is already in the map—if yes, you have the pair. Streams build a pipeline: filter keeps only elements that pass the predicate, map transforms each element, collect gathers into a list; the operations are lazy and composed in one pass.\n\n**7. Example problem & solution:** Problem: Two Sum. Solution: Map<Integer,Integer> seen; for i, x: if seen.containsKey(target-x) return {seen.get(target-x), i}; seen.put(x, i). Problem: Group by key. Solution: list.stream().collect(Collectors.groupingBy(Pair::getKey)).\n\n**8. Additional information:** Optional for nullable return. Lambda and method references. Immutable collections: List.of(), Map.of().",
          codeExample:
            "// HashMap, stream\nMap<Integer,Integer> map = new HashMap<>();\nfor (int i=0; i<nums.length; i++) {\n  if (map.containsKey(target-nums[i])) return new int[]{map.get(target-nums[i]), i};\n  map.put(nums[i], i);\n}\n// Stream: filter, map, collect\nList<String> names = users.stream()\n  .filter(u -> u.getAge() > 18)\n  .map(User::getName)\n  .collect(Collectors.toList());",
          codeLanguage: "java",
        },
        {
          title: "Practice & Common Patterns",
          description:
            "Solve small problems in each language; compare solutions; idiomatic style and standard library usage",
          order: 3,
          imageUrl:
            "https://placehold.co/800x400/0d9488/white?text=Go+Best+Practices",
          content:
            "**1. Learning flow:** (1) Read material and the common patterns: Two Sum (one-pass map/dict), Group By (defaultdict, groupingBy, or map of vectors), and sliding window (two pointers with an invariant). (2) Solve Two Sum and Group By in your primary interview language first so you can write them quickly and explain complexity. (3) Solve the same problem in all three languages (C++, Python, Java) and compare: notice how the algorithm is the same but syntax and standard library differ (e.g. Python dict vs Java HashMap vs C++ unordered_map). (4) Practice LeetCode Easy problems in your chosen language using idiomatic style—prefer standard library (Counter, stream().collect(), STL) over hand-rolled loops so your code is short and clear. (5) Real case: in an interview you will use one language; be fluent in that language's idioms (list comprehensions, streams, smart pointers) and know how to express the same pattern in a few lines. (6) Time yourself: Easy in ~15 min, Medium in ~25 min; if you can solve in two languages, you understand the pattern, not just the syntax.\n\n**2. Material:** The same problem (e.g. two sum, group by key) can be solved in C++, Python, and Java; practice each and learn the idiomatic way and standard library.\n\nPatterns: Two sum: map/dict to store seen and complement; O(n). Group by: defaultdict (Python), Collectors.groupingBy (Java), map with vector (C++). Sliding window: two pointers; maintain invariant. Use language-specific helpers: Counter (Python), stream().collect(groupingBy) (Java), unordered_map (C++).\n\nIdiomatic: C++: STL, range-for, smart pointers. Python: list/dict comprehensions, enumerate, zip. Java: streams, Optional, interface-based design. Prefer standard library over hand-rolled loops.\n\n**3. Explanation:** Same algorithm, different syntax. Idiomatic code is shorter and clearer. Standard library handles edge cases (hash, resize).\n\n**4. Application:** Interviews: pick one language; be fluent. Practice: solve in all three to understand trade-offs. Projects: use idiomatic style for maintainability.\n\n**5. How to implement:** (1) Two Sum: one pass with a map/dict; for each element x check if (target - x) is already in the map—if yes return [map[target-x], current index]; then add (x, current index) to the map. Do not add first then check (you would use the same element twice). (2) Group By: iterate over (key, value) pairs; for each key append the value to the list for that key. Python: use defaultdict(list) and d[k].append(v). Java: stream().collect(Collectors.groupingBy(keyExtractor, mapping(valueExtractor, toList()))). C++: map<K, vector<V>>; for each pair m[k].push_back(v). (3) Sliding window: maintain two pointers (left, right) and an invariant (e.g. all chars in window unique); expand right; when the invariant breaks, shrink left until it holds again; update the result (e.g. max length) when the window is valid. (4) Use idiomatic helpers: Python—Counter, enumerate, zip, list comprehensions; Java—streams, Optional, Map.merge; C++—STL, range-for, smart pointers. (5) See Competitive Programming and Interview Prep sections for more patterns (DP, BFS/DFS, heaps); practice 1–2 problems per day in your interview language. (6) Before interviews: pick one language and do 20–30 Easy/Medium in that language so you write without hesitating on syntax.\n\n**6. Logic & how the code works:**\n\nTwo Sum in one pass works because when you are at element x, the pair (if any) is (target-x, x); if target-x was already seen, its index is in the map. Group-by: one pass, for each (key, value) add value to the list for key; each language has an idiom (defaultdict, groupingBy, map of vectors). Same algorithm across languages; idiomatic style uses the standard library so the code is short and clear.\n\n**7. Example problem & solution:** Problem: Group pairs by first element. Python: defaultdict(list); for k,v in pairs: d[k].append(v). Java: stream().collect(groupingBy(Pair::getKey, mapping(Pair::getValue, toList()))). C++: map<int,vector<int>>; for p: m[p.first].push_back(p.second). Compare lines and clarity.\n\n**8. Additional information:** NeetCode roadmap for pattern-based practice. Pick one interview language; master it. Time yourself on Easy (15 min), Medium (25 min).",
          codeExample:
            "# Two Sum - Python vs Java\n# Python\nd = {}\nfor i, x in enumerate(nums):\n  if target-x in d: return [d[target-x], i]\n  d[x] = i\n# Java\nMap<Integer,Integer> m = new HashMap<>();\nfor (int i=0; i<nums.length; i++) {\n  if (m.containsKey(target-nums[i])) return new int[]{m.get(target-nums[i]), i};\n  m.put(nums[i], i);\n}",
          codeLanguage: "python",
        },
      ],
    },
    {
      title: "English Learning",
      slug: "english-learning",
      description:
        "Comprehensive IELTS Academic preparation targeting Band 8: Listening (4 sections, note-taking, accents), Reading (skimming, scanning, paraphrasing, academic texts), Writing Task 1 (graphs, charts, maps) and Task 2 (essay structure, argumentation), Speaking (Part 1, 2 cue card, Part 3 discussion), plus grammar, vocabulary, and test-taking strategies. Before you start: intermediate English (B1–B2); allow 2–3 months of consistent practice for Band 8.",
      order: 11,
      published: true,
      items: [
        {
          title: "IELTS Overview & Band 8 Strategy",
          description:
            "Format, scoring, Band 8 requirements, study plan, and resources",
          order: 0,
          imageUrl:
            "https://placehold.co/800x400/0369a1/white?text=IELTS+Academic+Band+8+Strategy",
          content:
            '**1. Learning flow:**\n\n(1) Read the IELTS format and scoring in full: four sections (Listening, Reading, Writing, Speaking), exact timing for each, and how the 0–9 band score is calculated per section and overall. You need to know the test structure so you can plan your time and know what to expect on the day. (2) Understand Band 8 criteria for each section in detail so you know exactly what examiners look for: Listening and Reading require 35–36 correct out of 40; Writing is marked on Task Achievement, Coherence and Cohesion, Lexical Resource, and Grammatical Range; Speaking is marked on Fluency and Coherence, Lexical Resource, Grammatical Range, and Pronunciation. (3) Create an 8–12 week study plan that rotates all four sections, focuses extra time on your weakest area, and includes at least one full mock test every 2 weeks so you build stamina and identify gaps. (4) Start with one full practice test (e.g. Cambridge IELTS 15 or 16) under strict timed conditions to get a baseline score per section; do not pause or look up answers—this gives you an honest starting point. (5) Use the baseline to allocate more study time to the section that needs the most improvement while maintaining the others so you do not lose progress. (6) Before test day, simulate full exam conditions at least twice: quiet room, strict timer, no pause, and proper transfer time for Listening so time pressure and format feel familiar and you are not surprised on the day.\n\n**2. Material:**\n\nIELTS Academic has four sections. **Listening** (about 30 minutes of audio plus 10 minutes to transfer answers): four sections, from everyday conversation (e.g. form completion) to an academic lecture; you hear each recording once only. **Reading** (60 minutes): three long passages (each around 700–900 words), 40 questions in total; topics are academic (science, history, technology, society). **Writing** (60 minutes): Task 1 requires at least 150 words (describe a graph, chart, table, map, or process); Task 2 requires at least 250 words (essay: opinion, discussion, problem/solution, or advantage/disadvantage). **Speaking** (11–14 minutes): Part 1 is short questions about you and familiar topics; Part 2 is a 2-minute talk on a cue card topic after 1 minute of preparation; Part 3 is a deeper discussion linked to Part 2. Your score is 0–9 for each section; the overall band is the rounded average of the four. Band 8 is described as "Very Good User" — fully operational command of the language with only occasional unsystematic inaccuracies; it is the typical target for competitive university entry or professional registration.\n\n**3. Explanation:**\n\nBand 8 criteria are explicit so you can aim for them. For **Listening** and **Reading**, Band 8 means 35–36 correct answers out of 40; that leaves very little room for carelessness, so you need consistent practice and careful transfer of answers (spelling and word count matter). For **Writing**, examiners use four criteria: Task Achievement (addressing all parts of the question, clear position where required), Coherence and Cohesion (logical flow, paragraphing, linking words), Lexical Resource (wide and appropriate vocabulary, collocations), and Grammatical Range and Accuracy (varied structures with few errors). For **Speaking**, the four criteria are Fluency and Coherence (extended answers without long pauses, logical flow), Lexical Resource (idiomatic language, paraphrasing), Grammatical Range and Accuracy (complex sentences, few errors), and Pronunciation (clear, natural, with only occasional slips). Understanding these criteria helps you know what to improve: for example, if your Writing score is stuck, check whether you are missing the overview in Task 1 or not addressing all parts in Task 2.\n\n**4. Application:**\n\nUse this knowledge to design your preparation. First, take a baseline: one full practice test under timed conditions (Cambridge IELTS or official materials). Check your score per section. Identify your weakest section (and, within it, the question types or criteria where you lose marks). Then build a study plan: for most people aiming at Band 8, 2–3 hours per day is realistic; rotate sections so each day you do at least one Listening task, one Reading passage or set, one Writing task (alternate Task 1 and Task 2), and about 15 minutes of Speaking (e.g. one Part 1 set, or one Part 2 with timer). Schedule a full mock test every 2 weeks so you build stamina and track progress.\n\n**5. How to implement:**\n\n(1) Get official or close-to-official practice tests: Cambridge IELTS 15–18 or similar; do at least one full test for baseline and one every 2 weeks after that. (2) Use free online resources for structure and strategies: IELTS Liz for task types and tips, E2Language on YouTube for section-by-section walkthroughs, and British Council or IDP for official information. (3) Build vocabulary systematically: use an Anki deck for the Academic Word List (AWL) and topic-specific words (environment, technology, education, etc.); review daily so the words appear naturally in your Writing and Speaking. (4) Arrange Speaking practice: book 2–3 mock sessions on iTalki or with a study partner; simulate Part 1, Part 2 (with 1 min prep and 2 min talk), and Part 3 with a timer so you get used to the length and pressure. (5) Track progress: keep a simple log (date, section, score or self-rating, main types of errors) so you see improvement over time and know where to focus. (6) In the last 2 weeks before the test: prioritise your weak section, do one full mock under exam conditions, rest one full day before the test, and confirm venue, time, and ID requirements so there are no last-minute surprises.\n\n**6. Logic & how the code works:**\n\nThe four sections test different skills: Listening tests comprehension from a single playback; Reading tests comprehension under strict time pressure; Writing tests ability to organise ideas and use language accurately to a structure; Speaking tests ability to communicate on the spot. A study plan that rotates sections ensures you improve weak areas without forgetting strong ones. Taking a baseline and then full mocks every 2 weeks gives you measurable progress and highlights which question types or criteria still need work. Tracking scores and errors turns preparation into a feedback loop: you see what improves and what does not, so you can adjust your practice.\n\n**7. Example problem & solution:**\n\nProblem: You do not know where to start or how much time to give each section. Solution: Use a 12-week plan as a template. Weeks 1–2: Familiarise yourself with the format (timing, question types, instructions); take one full baseline test; identify weak areas from the score breakdown. Weeks 3–5: Focus on Listening and Reading; do at least one Listening section and one Reading passage (or full Reading test) most days; review every wrong answer with the script or passage. Weeks 6–8: Focus on Writing Task 1 and Task 2; learn the expected structure for each type (e.g. overview in Task 1, thesis and body paragraphs in Task 2); write at least two full Task 1 and two full Task 2 answers per week and compare with model answers. Weeks 9–10: Focus on Speaking; practice Part 1 (extended answers), Part 2 (2-minute talk with timer), and Part 3 (longer discussion); record yourself and review for fluency and vocabulary. Weeks 11–12: Do full mock tests under timed conditions; review every mistake; in the last week do one more full mock and then rest the day before the test.\n\n**8. Additional information:**\n\nAcademic module is for university entry; General Training is often used for migration or non-academic purposes—check which one you need. Reaching Band 8 typically requires 2–3 months of consistent practice for most learners; do not rely on cramming—steady daily practice is more effective. Common mistakes that cost marks: not reading the instructions (e.g. "NO MORE THAN 3 WORDS" or "Choose TWO letters"); spelling errors in Listening and Reading; writing fewer than 150 or 250 words in Writing; and giving one-word or very short answers in Speaking Part 1. Always leave a few minutes to check your answers in Listening and Reading, and to proofread your Writing tasks.',
        },
        {
          title: "Listening",
          description:
            "4 sections, question types, note-taking, accents, Band 8 strategies",
          order: 1,
          imageUrl:
            "https://placehold.co/800x400/059669/white?text=IELTS+Listening",
          content:
            '**1. Learning flow:** (1) Understand the 4 Listening sections: Section 1 (everyday conversation, e.g. form completion), Section 2 (monologue, e.g. tour), Section 3 (academic conversation), Section 4 (academic lecture)—audio is played once only, so prediction and note-taking matter. (2) Practice Section 1 and Section 4 first (form completion and lecture are common and train prediction). (3) Practice prediction before each audio: read the questions, mark keywords, and guess the answer type (number? name? date?). (4) Practice note-taking: use abbreviations and symbols so you write fast without missing the next part. (5) Do at least one full Listening test with strict time limit and transfer time; review the script afterward to see paraphrasing and distractors. (6) Real case: expose yourself to British, Australian, and American accents (BBC, ABC, TED) so test-day accents are familiar.\n\n**2. Material:** Section 1: Everyday conversation (e.g. booking, registration). Section 2: Monologue (e.g. tour, facilities). Section 3: Academic conversation (e.g. assignment discussion). Section 4: Academic lecture. Audio is played once only. You have time to read questions before the audio. Question types: form/note/table completion, multiple choice, matching, labeling diagram, short answer. Accents: British, Australian, American, others.\n\n**3. Band 8 strategy:** (1) Read questions when "You will hear..."; mark keywords. (2) Predict the answer (number? name? date?). (3) Listen for keywords and paraphrasing ("a significant increase" = "rose considerably"). (4) Do not get stuck on one question; move on. (5) Transfer: check spelling, grammar, word limit (e.g. NO MORE THAN 2 WORDS).\n\n**4. Note-taking:** Abbreviations: govt (government), info (information), diff (different). Symbols: ↑ increase, ↓ decrease, → leads to. Focus: numbers, names, dates, places. Do not write full sentences; keywords only.\n\n**5. How to implement:** (1) Daily: do at least one full section from Cambridge IELTS (e.g. Section 1 one day, Section 4 the next); stick to the time limit and 10 min transfer. (2) Expose yourself to accents: listen to BBC (British), ABC (Australian), and TED or NPR (American) so you are used to different pronunciations. (3) Before each audio: read all questions for that section, underline keywords, and predict the answer type (number, name, date, noun phrase) so you know what to listen for. (4) After each practice: review the script and mark where the correct answer appeared and how it was paraphrased; note distractors (wrong answer given first, then corrected). (5) Common traps: distractor (speaker says one thing then corrects it—wait for the final answer); spelling (e.g. "double L", "hyphen"); word limit (e.g. NO MORE THAN 2 WORDS—count words in your answer). (6) Transfer practice: when copying answers to the answer sheet, check spelling and word count; use the full 10 minutes.\n\n**6. Logic & how the code works:** Prediction (number? name? date?) narrows what you listen for. Paraphrasing means the recording rarely uses the same words as the question—you match meaning, not exact words. Distractors give a wrong answer first, then correct it; wait for the final answer before writing.\n\n**7. Example:** Q: "The project will be completed by ______." Predict: date. Audio: "We initially thought March, but now we\'re aiming for early April." Answer: April (not March—distractor). Q: "The main advantage is ______." Predict: noun phrase. Listen for: "The key benefit is..." "One major advantage..."\n\n**8. Additional information:** Spelling counts. Singular/plural counts. Word limit: if "NO MORE THAN 2 WORDS" and answer is "the green one" — write "green one" (2 words). Practice with earphones; test day use headphones. Do not move your mouth while writing—it distracts focus.',
        },
        {
          title: "Reading Academic",
          description:
            "3 passages, skimming/scanning, question types, paraphrasing, time management",
          order: 2,
          imageUrl:
            "https://placehold.co/800x400/7c3aed/white?text=Reading+Skim+Scan+Paraphrasing",
          content:
            '**1. Learning flow:** (1) Understand all Reading question types: True/False/Not Given, Yes/No/NG, multiple choice, matching headings, matching info to paragraphs, sentence completion, summary completion, short answer—and that question order usually follows text order. (2) Practice skimming: for each passage spend 2–3 min reading title, first paragraph, first sentence of each paragraph, and last paragraph to get the gist. (3) Practice scanning: locate specific keywords (names, numbers, dates) without reading every word. (4) Practice paraphrasing: take a sentence from the text and rewrite it in your own words; this is the key to matching questions to the passage. (5) Do full 60-min practice tests with strict timing: aim for ~20 min per passage (Passage 1 slightly less, Passage 3 slightly more); if stuck on a question for more than 2 min, skip and return. (6) Real case: always read the instructions (e.g. "Choose TWO letters" vs "Choose ONE") and word limits (e.g. NO MORE THAN 3 WORDS).\n\n**2. Material:** 3 passages (each ~700–900 words); 40 questions total. Academic topics: science, history, technology, environment. Question types: True/False/Not Given, Yes/No/NG, multiple choice, matching headings, matching info to paragraphs, sentence completion, summary completion, short answer. Question order usually follows text order.\n\n**3. Skimming vs Scanning:** Skimming: read quickly for gist. Title → first para → first sentence of each paragraph → last para. 2–3 min. Scanning: find specific words. Keywords (names, numbers, dates). Do not read word-by-word first.\n\n**4. Paraphrasing (key to Band 8):** Questions rarely use the exact words from the text. "The decline in population" = "a fall in the number of people." "Initially" = "at first," "in the beginning." "Consequently" = "as a result," "therefore." Learn academic synonyms: increase/rise/grow, decrease/decline/drop, significant/major/considerable.\n\n**5. How to implement:** (1) Time allocation: 60 min for 40 questions—Passage 1 (15–17 min), Passage 2 (20 min), Passage 3 (23–25 min); Passage 3 is usually hardest so leave enough time. (2) For each passage: skim first (title → first para → first sentence of each para → last para) in 2–3 min so you know where ideas are. (3) Read the questions (or question set) before scanning; underline keywords and think of paraphrases (e.g. "decline" = "fall", "drop"). (4) Scan for the keyword or its paraphrase in the text; when you find the relevant sentence, read it fully to confirm the answer. (5) True/False/Not Given: only use what is stated in the text—do not infer; if the text does not say it, the answer is Not Given. (6) If stuck on a question for more than 2 min, leave it and return later; do not block the rest of the passage. (7) Transfer answers carefully; check spelling and that you have followed instructions (number of words, number of letters).\n\n**6. Logic & how the code works:** Skimming gives you the gist so you know where to look; scanning finds the exact sentence for the question. True/False/Not Given depends only on what is stated—if the text does not say it, the answer is Not Given even if it might be true in real life.\n\n**7. True/False/Not Given:** True = statement matches the text. False = statement contradicts the text. Not Given = no information in the text (not wrong—just not stated). Trap: do not infer; only what is written.\n\n**8. Additional information:** Read instructions: "Choose TWO letters" vs "Choose ONE." Matching headings: read options first; predict before reading the paragraph. Summary completion: check if from box or from text. Academic Word List (AWL) for vocabulary. Practice sources: Cambridge IELTS, IELTS Liz, British Council.',
        },
        {
          title: "Writing Task 1",
          description:
            "Describing graphs, charts, maps, diagrams; structure, vocabulary, Band 8 model",
          order: 3,
          imageUrl:
            "https://placehold.co/800x400/ea580c/white?text=Writing+Task+1+Graphs+Charts+Maps",
          content:
            '**1. Learning flow:** (1) Understand all Task 1 types: line/bar/pie (trends and comparisons), table, map (changes over time), process/diagram (steps)—each type needs slightly different vocabulary and focus. (2) Learn the Band 8 structure: paragraph 1 paraphrase the prompt, paragraph 2 overview (main trends or features without number details), paragraphs 3–4 body with key figures and comparisons. (3) Build a vocabulary list for trends (rise, fall, peak, fluctuate), adverbs (steadily, sharply), and linking (while, whereas, in contrast). (4) Write at least 2 Task 1 answers per week under 20 min; compare with a model answer and check overview, key figures, and word count (150+). (5) Real case: always write the overview (1–2 sentences) after the intro—examiners expect it; missing overview caps your score. (6) Leave 2 min to check word count, spelling, and that you have not given opinion (report only).\n\n**2. Material:** Task 1: Describe visual information (150+ words, 20 min). Types: Line/bar/pie (trends, comparisons), Table, Map (place changes), Process/Diagram (flow). No conclusion needed; need overview (1–2 sentences summarising main features).\n\n**3. Band 8 structure:** Paragraph 1: Paraphrase prompt (1–2 sentences). Paragraph 2: Overview — main trends/features without number details. Paragraphs 3–4: Body — group data logically; compare; include key figures. Do not write every number; choose significant ones (highest, lowest, changes).\n\n**4. Vocabulary:** Trends: rise/increase/grow/climb, fall/decrease/drop/decline, fluctuate, remain stable, peak, hit a low. Adverbs: steadily, sharply, gradually, significantly, slightly. Prepositions: from X to Y, between X and Y, over the period. Comparisons: while, whereas, compared to, in contrast.\n\n**5. How to implement:** (1) Identify the Task 1 type (line/bar/pie/table/map/process) and what the question asks (trends? comparison? change over time?). (2) Paragraph 1: paraphrase the prompt in 1–2 sentences (do not copy). (3) Paragraph 2: write the overview—summarise the main trend or the most striking feature in 1–2 sentences without giving specific numbers. (4) Body: 1–2 paragraphs; group data logically (e.g. by trend or by category); include key figures (highest, lowest, start/end, big changes); use linking (while, whereas, in contrast, compared to). (5) Grammar: use passive for process ("The clay is moulded"); comparatives ("X was higher than Y"); past/present/future according to the data; vary sentence types (simple, compound, complex). (6) Leave 2 min to check: word count 150+; no opinion; spelling and key vocabulary (e.g. "significant", "fluctuate").\n\n**6. Logic & how the code works:** Overview first (without details) shows the examiner you see the big picture; then the body gives selected figures. Grouping data logically (e.g. by trend or by category) and comparing (while, whereas) meets Task Achievement and Coherence. You report only; no opinion.\n\n**7. Example overview:** "Overall, the consumption of renewable energy increased significantly over the period, while fossil fuels declined. Solar showed the steepest growth." Example body: "In 2010, coal accounted for 40% of total energy, but by 2020 this had fallen to 25%. In contrast, solar rose from 5% to 20%."\n\n**8. Additional information:** Map: describe changes (built, demolished, expanded). Process: use sequence words (first, then, after that, finally). No opinion; report data only. Word count: 150–170 ideal; <150 = penalty. Sources: IELTS Liz Task 1, Simon IELTS.',
        },
        {
          title: "Writing Task 2",
          description:
            "Essay structure, argumentation, linking words, Band 8 model (250+ words)",
          order: 4,
          imageUrl:
            "https://placehold.co/800x400/dc2626/white?text=Writing+Task+2+Essay+Structure",
          content:
            '**1. Learning flow:** (1) Understand all essay types: opinion (to what extent do you agree?), discussion (both views + your view), problem/solution, advantage/disadvantage—and always address every part of the question. (2) Learn the 4-paragraph structure: intro (paraphrase + thesis), 2 body paragraphs (topic sentence, explain, example, link), conclusion (restate thesis, no new ideas). (3) Build a bank of linking words and phrases (furthermore, however, therefore, for instance) and use them to connect ideas within and between paragraphs. (4) Write at least 2 full Task 2 essays per week under 40 min (5 min plan, 30 min write, 5 min proofread); get feedback from a teacher or compare with a model. (5) Real case: plan before writing—outline 2–3 main ideas and one example each so you do not run out of ideas or go off-topic. (6) Avoid informal language ("lots of", "stuff", "gonna"); use passive and nominalisation where appropriate for academic style.\n\n**2. Material:** Task 2: Essay 250+ words, 40 min. Types: To what extent do you agree? Discuss both views. Problem and solution. Advantages vs disadvantages. Mixed (e.g. cause + opinion). Important: address all parts of the question.\n\n**3. Band 8 structure:** Intro (40–50 words): Paraphrase topic + thesis (clear position). Body 1 (80–90): Main idea 1 + support + example. Body 2 (80–90): Main idea 2 + support + example. (Body 3 optional if 3 points.) Conclusion (30–40): Restate thesis + summarise; no new ideas.\n\n**4. Linking & Coherence:** Addition: furthermore, moreover, in addition. Contrast: however, nevertheless, on the other hand. Cause: therefore, consequently, as a result. Example: for instance, such as, for example. Opinion: in my view, I believe, it seems to me. Each paragraph must have a clear topic sentence.\n\n**5. How to implement:** (1) Read the question twice and underline what you must address (e.g. "both views", "problems and solutions"); plan for 5 min: write 2–3 main ideas and one example each. (2) Intro (40–50 words): paraphrase the topic and state your thesis (clear position). (3) Each body paragraph (80–90 words): topic sentence (one main idea) → 2–3 sentences explaining why → concrete example → sentence linking back to thesis. (4) Use linking words: furthermore, however, therefore, for instance, in my view—each paragraph should have a clear topic sentence and flow. (5) Conclusion (30–40 words): restate your thesis and summarise your main points; do not introduce new ideas. (6) Proofread: check that you addressed all parts of the question, word count 250+, and avoid informal language and repeated words. Argumentation model: "Governments should invest in renewable energy. This is because fossil fuels contribute to climate change, which affects global weather patterns. For example, rising sea levels threaten coastal cities. Therefore, shifting to renewables is essential."\n\n**6. Logic & how the code works:** A clear thesis in the intro tells the examiner your position; each body paragraph supports it with one idea, explanation, and example. Linking words (furthermore, however, therefore) connect ideas so the essay reads as one argument, not separate points.\n\n**7. Example intro:** "It is often argued that technology has made life more stressful. While I agree that constant connectivity can increase anxiety, I believe that technology also brings significant benefits that outweigh these drawbacks."\n\n**8. Additional information:** Time: 5 min plan, 30 min write, 5 min proofread. Plan = outline 2–3 main ideas + 1 example each. Common mistake: not addressing "both views" when required. Word count: 250–280 ideal. Avoid informal: "lots of," "stuff," "gonna." Use passive and nominalisation for academic style.',
        },
        {
          title: "Speaking Part 1, 2 & 3",
          description:
            "Part 1 intro, Part 2 cue card (2 min), Part 3 discussion; fluency, structure, Band 8 tips",
          order: 5,
          imageUrl:
            "https://placehold.co/800x400/16a34a/white?text=Speaking+Part+1+2+3+Fluency",
          content:
            '**1. Learning flow:** (1) Understand the three parts: Part 1 (short questions, 2–3 sentence answers), Part 2 (cue card, 1 min prep, 2 min talk), Part 3 (deeper discussion linked to Part 2). (2) Learn to extend: never answer with one word; use Answer + Reason + Example/Detail in Part 1 and Part 3. (3) For Part 2 create a template: intro ("I\'d like to talk about..."), 3 points from the cue card (Firstly, Secondly, Finally), conclusion ("So that\'s why..."); practice with a 2-min timer until you can speak without long pauses. (4) Practice with a timer for each part; record yourself and review for fluency, vocabulary, and grammar. (5) Prepare 5–6 stories (place, person, event, object) that you can adapt to different cue cards (e.g. "memorable trip" → "favourite place"). (6) Real case: warm up in English 30 min before the test (read aloud or talk to someone) so you are in the language from the start.\n\n**2. Material:** Part 1 (4–5 min): Intro, home, work, hobbies. Short questions; answer in 2–3 sentences. Part 2 (3–4 min): Cue card — 1 topic, 1 min prep, 2 min talk. Part 3 (4–5 min): In-depth discussion; abstract questions related to Part 2.\n\n**3. Part 1 Band 8:** Extend: "Do you like reading?" Do not say "Yes." Answer: "Yes, I do. I especially enjoy non-fiction, particularly books on technology and history. I try to read for at least 30 minutes before bed." Formula: Answer + Reason + Example/Detail.\n\n**4. Part 2 structure:** Intro (10 sec): "I\'d like to talk about..." Body: 3 points from the cue card; each 30–40 sec. Use "Firstly," "Secondly," "Finally." Include past tense if relevant. Conclusion (10 sec): "So that\'s why it\'s memorable to me." Practice 2 min without stopping; use all points on the card.\n\n**5. How to implement:** (1) Part 1: for every question use Answer + Reason + Example/Detail (e.g. "Do you like reading?" → "Yes, I do. I especially enjoy non-fiction, particularly technology and history. I try to read 30 minutes before bed."). (2) Part 2: use the 1 min prep to note 3 points from the cue card; structure your talk as intro (10 sec), 3 points (30–40 sec each), conclusion (10 sec); practice until you can speak 2 min without stopping. (3) Part 3: give long answers with opinion + reason + example (e.g. "Do you think technology will change education?" → "Yes, definitely. I think we\'ll see more personalised learning through AI. For example, adaptive software already tailors exercises. However, face-to-face interaction will still be important."). (4) Practice: do at least 3 full Part 2 talks per week with a timer; record and check that you used all points on the card and varied vocabulary. (5) Prepare 5–6 adaptable stories for Part 2; warm up in English 30 min before the test. (6) Fluency: use brief fillers ("Well," "Let me think") if you need time; paraphrase if you forget a word (e.g. "that place where you keep books" for library).\n\n**6. Logic & how the code works:** Part 1 needs short extended answers (Answer + Reason + Detail). Part 2 needs a clear structure (intro, 3 points, conclusion) so you use the full 2 minutes without running out. Part 3 rewards the same formula: opinion, reason, example. Paraphrasing when you forget a word keeps fluency instead of stopping.\n\n**7. Fluency tips:** Do not be afraid to pause briefly ("Let me think..."). Use natural fillers: "Well," "Actually," "I mean." Paraphrase if you forget a word: "that place where you keep books" = library. Pronunciation: stress important words; intonation rises for questions.\n\n**8. Additional information:** Part 2 topics: place, person, event, object, activity. Prepare 5–6 stories you can adapt (e.g. "memorable trip" can become "favourite place"). IELTS Buddy, Keith Speaking Academy for samples. Practice with a partner or AI (ChatGPT roleplay).',
        },
        {
          title: "Grammar & Vocabulary for IELTS",
          description:
            "Academic collocations, paraphrasing, common errors, Word formation",
          order: 6,
          imageUrl:
            "https://placehold.co/800x400/0d9488/white?text=Grammar+Vocabulary+Paraphrasing",
          content:
            '**1. Learning flow:** (1) Learn the Academic Word List (AWL)—the 570 words that appear most in academic texts; use them in Writing and Speaking so your vocabulary matches the task. (2) Collect collocations (verb+noun, adj+noun) from model answers and articles (e.g. make a decision, strong evidence, significant increase) so you use natural combinations, not literal translations. (3) Practice paraphrasing daily: take a sentence from a Reading passage or prompt and rewrite it in your own words using synonyms and different structures. (4) Review common grammar errors (subject-verb agreement, articles, prepositions, "despite" vs "in spite of") and write 5 error-free sentences per day targeting your weak points. (5) Real case: in the exam, if you forget a word while speaking, paraphrase (e.g. "the place where you borrow books" instead of stopping); in Writing, vary sentence structure (simple, compound, complex) and use passive where appropriate.\n\n**2. Material:** Grammar for Band 8: Mixed tenses (present perfect for "experience," past for "event"). Complex sentences: relative clauses (who, which, that), conditional (if..., would...), participle clauses (Having finished..., ...). Passive voice. Articles: a/an/the. Subject-verb agreement. Prepositions.\n\n**3. Academic collocations:** Make: decision, effort, progress, contribution. Take: responsibility, action, approach, into account. Have: impact, influence, effect (on). Play: role, part. Reach: conclusion, agreement. Draw: conclusion, attention. Strong: argument, evidence, case. Significant: increase, impact, difference.\n\n**4. Paraphrasing:** Increase = rise, grow, climb, go up. Decrease = fall, decline, drop, go down. Important = significant, crucial, vital, essential. Problem = issue, challenge, concern. Solution = approach, measure, strategy. People = individuals, the public, society. Use = utilise, employ, apply.\n\n**5. How to implement:** (1) Study the AWL in chunks (e.g. 50 words per week); use Anki or a list from cambridge.org; try to use at least 3–5 AWL words per Writing task. (2) Build a collocation list: when you read model answers or articles, note verb+noun and adj+noun (e.g. make progress, take responsibility, strong argument); review before Writing and Speaking practice. (3) Paraphrasing practice: every day take 2–3 sentences from a Reading passage and rewrite them (e.g. "The decline in population" → "a fall in the number of people"); use a thesaurus for synonyms but check meaning. (4) Common errors to fix: "There is" + singular / "There are" + plural; "The number of" + singular verb / "A number of" + plural; "Despite" + noun or gerund (no "of") / "In spite of" + noun; "Discuss" (no "about"); "economic" (adj, economy-related) vs "economical" (cheap). (5) Write 5 error-free sentences per day focusing on your most frequent mistakes; use Grammarly or a teacher to identify patterns. (6) Word formation: practice noun/verb/adjective forms (e.g. inform→information, develop→development) so you can understand unknown words in Reading and vary vocabulary in Writing.\n\n**6. Logic & how the code works:** Collocations (e.g. make a decision, not do a decision) sound natural to examiners. Paraphrasing reuses meaning with different words—essential for Reading and Writing. Word formation (prefix/suffix) helps you understand unknown words and vary your vocabulary in Writing and Speaking.\n\n**7. Word formation:** -tion (inform→information), -ment (develop→development), -ity (possible→possibility), -ness (happy→happiness). Prefix: un-, in-, im-, dis- (opposites). Suffix -ly (quick→quickly). Practice: "The economy grew" → "There was economic growth."\n\n**8. Additional information:** AWL 570 words: cambridge.org. Oxford Learner\'s Dictionary for collocations. Anki deck "IELTS Vocabulary." Read academic articles (The Economist, Nature) for exposure. Use Grammarly to check; but understand your own error patterns.',
        },
        {
          title: "Practice & Test-taking Tips",
          description:
            "Mock tests, time management, common mistakes, last-week checklist",
          order: 7,
          imageUrl:
            "https://placehold.co/800x400/4338ca/white?text=Practice+Mock+Test+Tips",
          content:
            '**1. Learning flow:**\n\n(1) Take a full mock test under strict timed conditions: Listening (30 minutes of audio plus 10 minutes to transfer answers), Reading (60 minutes, no pause), Writing (60 minutes total: 20 for Task 1, 40 for Task 2), and Speaking (11–14 minutes, ideally with a partner or recorder). Do this in a quiet place with no pause so you experience the real time pressure and format. (2) Review every mistake in detail: for Listening and Reading, check the script or passage and note why you got each question wrong (paraphrasing? distractor? wrong inference? spelling?); for Writing, compare your tasks with a Band 8 model and check Task Response, Coherence and Cohesion, Lexical Resource, and Grammatical Range; for Speaking, listen to your recording and note gaps in fluency, vocabulary, and grammar. (3) Categorise your errors (e.g. "paraphrasing in Reading", "overview missing in Task 1", "short Part 1 answers", "wrong inference in True/False/Not Given") and create a checklist of weak areas to target in the next 2 weeks. (4) Repeat a full mock every 2 weeks until your scores stabilise; in the last week before the test do 2 full mocks and rest one full day before the test so you are fresh. (5) On test day: arrive 30 minutes early, bring ID and water; warm up in English before the Speaking test (read aloud or talk to someone) so you are in the language from the start; read every instruction carefully (word limit, number of answers, "Choose ONE" vs "Choose TWO").\n\n**2. Material:**\n\nA **full mock test** mirrors the real exam: Listening (about 30 min audio + 10 min transfer), Reading (60 min, 3 passages, 40 questions), Writing (60 min: Task 1 at least 150 words, Task 2 at least 250 words), Speaking (11–14 min: Part 1, Part 2 cue card, Part 3). Simulate real conditions: quiet room, strict timer, no pause. **Review process:** For Listening, use the script to see exactly where the correct answer appeared and how it was paraphrased; note distractors (wrong answers mentioned first). For Reading, for each wrong answer identify whether the error was paraphrasing, logic (True/False/Not Given), or time pressure. For Writing, compare with a Band 8 model and tick off Task Response (all parts addressed?), Coherence and Cohesion (overview? linking?), Lexical Resource (varied vocabulary?), Grammatical Range (complex sentences? errors?). For Speaking, transcribe or listen and note where you hesitated, repeated, or used simple vocabulary.\n\n**3. Explanation:**\n\n**Time management** is critical. In Listening, use the gaps between sections to read the next set of questions so you know what to listen for. In Reading, aim for about 20 minutes per passage (slightly less for Passage 1, slightly more for Passage 3); if you are stuck on a question for more than 2 minutes, leave it and return later. In Writing, Task 2 is worth twice the marks of Task 1, so allocate 20 minutes to Task 1 and 40 to Task 2; do not run over or you will rush Task 2. In Speaking Part 2, use the full 2 minutes; do not stop early or the examiner may ask you to continue. **Common mistakes** that cost marks: not reading the instructions (e.g. "NO MORE THAN 3 WORDS" or "Choose TWO letters"); spelling errors in Listening and Reading; writing fewer than 150 or 250 words in Writing; going off-topic in Writing or Speaking; giving one-word or very short answers in Speaking Part 1; and not addressing all parts of the question in Writing Task 2 (e.g. "discuss both views" requires both views).\n\n**4. Application:**\n\nUse mocks to build stamina and find weak spots. After each mock, spend at least as long reviewing as you did taking the test: go through every wrong answer and understand why it was wrong. Use your error categories to decide what to practice next (e.g. if overview is missing in Task 1, practice writing overviews for 10 different Task 1 types). In the last 2 weeks, do 2 full mocks and focus revision on your weak areas while maintaining the others. On test day, follow the time allocations you practised and read every instruction so you do not lose marks to avoidable mistakes.\n\n**5. How to implement:**\n\n(1) Schedule at least 2 full mock tests in the 2 weeks before your test date; use Cambridge IELTS 15–18 or other official-style materials; do them under exam conditions (timer, no pause, quiet room, proper transfer time for Listening). (2) After each mock, review every wrong answer in Listening and Reading: open the script or passage, find where the correct answer appears, and note whether you missed it due to paraphrasing, a distractor, wrong inference, or spelling. (3) For Writing, compare each task with a Band 8 model answer and note gaps: is the overview present in Task 1? Are all parts of the question addressed in Task 2? Are linking words and vocabulary varied? (4) For Speaking, listen to your recording and note where you hesitated, repeated words, or used simple vocabulary; practise extending answers and using the full 2 minutes in Part 2. (5) Keep a simple error log (date, section, type of error, action taken) so you can see patterns and focus practice. (6) Last week: do 2 full mocks, review all errors, then rest one full day before the test; do not cram new material the day before. (7) Test day: confirm venue, time, and ID the day before; arrive 30 min early; bring water; warm up in English 30 min before Speaking (read aloud or talk). (8) During the test: read every instruction (word limit, number of words, number of answers); stick to your time plan (Writing: 20 min Task 1, 40 min Task 2; Reading: about 20 min per passage); if stuck on a question, skip and return later.\n\n**6. Logic & how the code works:**\n\nTimed mocks expose time pressure and weak spots that you do not see when practising sections in isolation. Reviewing every mistake and asking "why was it wrong?" turns errors into learning: you see the paraphrasing, the distractor, or the missing overview. A checklist of weak areas (e.g. "overview in Task 1", "extended answers in Part 1") focuses your last weeks of practice so you improve where it matters. Warming up in English before the Speaking test gets your brain into the language so you do not start cold.\n\n**7. Example resources and plan:**\n\n**Resources:** Cambridge IELTS 15–18 (official-style tests); IELTS Liz (free tips and structures); E2Language (YouTube, section-by-section strategies); British Council and IDP (official test information); Anki (vocabulary review); iTalki or a partner (Speaking mock). **Example last-week plan:** Day 1–2: full mock, full review. Day 3–4: focus on weak section (e.g. Writing Task 1 overview + Task 2 structure). Day 5: second full mock, full review. Day 6: light review of error log, rest. Day 7 (test day): arrive 30 min early, warm up in English, read all instructions.\n\n**8. Additional information:**\n\nBand 8 is achieved through consistency, not luck. Focus on weak areas but do not neglect strong ones—maintain them with regular practice. Mental preparation: get enough sleep in the days before the test, eat something before the test so you are not hungry, and stay calm during the test (if you miss one answer, move on). On test day: arrive 30 min early, bring water and your ID, and read every instruction (word limit, number of answers). Good luck.',
        },
      ],
    },
    {
      title: "Quantum Computing",
      slug: "quantum-computing",
      description:
        "Introduction to quantum computing: qubits and superposition and entanglement, single- and multi-qubit states, quantum gates (Pauli, Hadamard, CNOT) and circuit composition, Grover and Shor algorithms, and implementation with Python and Qiskit. Before you start: linear algebra (vectors, matrices) and basic Python; optional: CS Theory and competitive programming for math maturity.",
      order: 12,
      published: true,
      items: [
        {
          title: "Qubits & Basics",
          description:
            "Qubit as unit of quantum information; superposition (|0⟩ and |1⟩); entanglement and multi-qubit states",
          order: 0,
          imageUrl:
            "https://placehold.co/800x400/4338ca/white?text=Qubits+Superposition+Entanglement",
          content:
            "**1. Learning flow:**\n\n(1) Read the material on qubits and superposition: a qubit can be in a combination α|0⟩ + β|1⟩ (a superposition) until it is measured; upon measurement it collapses to either 0 or 1 with probability |α|² and |β|² respectively. This is fundamentally different from a classical bit, which is always 0 or 1. (2) Write single-qubit states in vector form (e.g. |0⟩ = [1, 0], |1⟩ = [0, 1], and (|0⟩ + |1⟩)/√2 = [1/√2, 1/√2]) and compute the measurement probabilities; verify that |α|² + |β|² = 1 for any valid state. (3) Study the Bell state (|00⟩ + |11⟩)/√2: it cannot be written as a product of two single-qubit states (it is entangled); measuring one qubit instantly determines the outcome of the other, even though neither qubit has a definite value before measurement. (4) In IBM Quantum Lab or with Qiskit locally, run a simple superposition circuit (apply the Hadamard gate H to |0⟩, then measure) and observe that over many shots you get roughly 50% zeros and 50% ones, confirming the probabilistic nature of measurement.\n\n**2. Material:**\n\nA **qubit** (quantum bit) is the unit of quantum information. Unlike a classical bit, which is either 0 or 1, a qubit can be in a **superposition** of the two basis states: α|0⟩ + β|1⟩, where α and β are complex numbers called amplitudes. The basis states are |0⟩ = [1, 0] and |1⟩ = [0, 1] in vector notation. The state of a single qubit is therefore a unit vector in a two-dimensional complex space: |α|² + |β|² = 1. When you **measure** the qubit in the computational basis, it collapses to 0 with probability |α|² and to 1 with probability |β|²; measurement is irreversible and destroys the superposition. For **multiple qubits**, the state space has 2^n dimensions for n qubits; states are built from the tensor product of single-qubit states. **Entanglement** is a property of some multi-qubit states that cannot be written as a product of single-qubit states. For example, (|00⟩ + |11⟩)/√2 is entangled: if you measure the first qubit and get 0, the second qubit is immediately 0; if you get 1, the second is 1. This correlation exists even though neither qubit had a definite value before the measurement. Entanglement is a key resource for quantum algorithms and quantum communication.\n\n**3. Explanation:**\n\nSuperposition means that a single qubit can effectively hold both 0 and 1 in a weighted combination until it is measured; then it collapses to one of the two. This allows quantum algorithms to explore many possibilities in parallel (in a sense) and then use interference to amplify the correct answer. Entanglement means that two or more qubits can share a state that is not separable: measuring one qubit gives you information about the other(s) instantly. Classical bits cannot exhibit this: two classical bits can be correlated (e.g. both 0 or both 1), but they each have a definite value before you look. In the Bell state, before any measurement neither qubit has a definite 0 or 1; the state is a coherent superposition of |00⟩ and |11⟩. The normalization condition |α|² + |β|² = 1 ensures that the probabilities of the two outcomes sum to 1.\n\n**4. Application:**\n\nIn practice you will create superpositions and entangled states using quantum gates. To create the equal superposition (|0⟩ + |1⟩)/√2, you apply the Hadamard gate H to the state |0⟩. If you then measure many times (many \"shots\"), you will see approximately half the results as 0 and half as 1. To create the Bell state (|00⟩ + |11⟩)/√2, you start with |00⟩, apply H to the first qubit (giving (|00⟩ + |10⟩)/√2), then apply a CNOT with the first qubit as control and the second as target; the result is (|00⟩ + |11⟩)/√2. This state is used in quantum teleportation and in many quantum algorithms. Understanding how to write states and compute probabilities is essential before moving on to gates and circuits.\n\n**5. How to implement:**\n\n(1) By hand: write (|0⟩ + |1⟩)/√2 as the vector [1/√2, 1/√2]; then P(0) = |1/√2|² = 1/2 and P(1) = 1/2; check that they sum to 1. (2) In Qiskit: create a circuit with one qubit (QuantumCircuit(1, 1)), apply the Hadamard gate with circuit.h(0), then measure with circuit.measure(0, 0). (3) Run the circuit with execute(circuit, backend, shots=1000) (use AerSimulator() as backend); get the counts with result.get_counts() and you should see roughly half in '0' and half in '1'. (4) For the Bell state: create QuantumCircuit(2, 2), apply circuit.h(0) then circuit.cx(0, 1), then measure both qubits (e.g. circuit.measure([0, 1], [0, 1])); run with many shots—you should see only the outcomes '00' and '11', each with probability about 1/2. (5) Use IBM Quantum Lab (free account) or the local AerSimulator(); if you run on a real device, you will see more noise and decoherence (results may not be exactly 50-50). The full code example is in the Algorithms & Qiskit topic.\n\n**6. Logic & how the code works:**\n\nA qubit state is represented as a unit vector: the squared magnitudes of the amplitudes give the probabilities of the two measurement outcomes, so they must sum to 1. Superposition means the qubit is in a linear combination of |0⟩ and |1⟩ until a measurement is performed; the act of measurement collapses the state to one of the basis states and returns the corresponding classical bit. Entanglement means that the multi-qubit state cannot be factored into a product of single-qubit states; the qubits are correlated in a way that cannot be reproduced by classical correlation. When you run a circuit many times (many shots), you are sampling from the probability distribution defined by the state; the counts you get (e.g. 512 for '0' and 488 for '1') approximate the true probabilities and get closer as you increase the number of shots.\n\n**7. Example problem & solution:**\n\nProblem: Write the state (|0⟩ + |1⟩)/√2 in vector form and state the probabilities P(0) and P(1) when the qubit is measured in the computational basis. Solution: In vector form the state is [1/√2, 1/√2]. The probability of measuring 0 is P(0) = |α|² = |1/√2|² = 1/2, and the probability of measuring 1 is P(1) = |β|² = 1/2. Their sum is 1, as required. Important: after the measurement, the superposition is destroyed and the qubit is either in |0⟩ or |1⟩ depending on the outcome.\n\n**8. Additional information:**\n\nThe Bloch sphere is a useful way to visualize a single-qubit state (excluding global phase): the state is a point on the unit sphere. Entanglement is essential for quantum speedup in algorithms like Grover's search and Shor's factoring. In real hardware, qubits suffer from **decoherence**: they lose their superposition and entanglement over time due to interaction with the environment, so algorithms must run within the coherence time or use error correction (an active area of research). For hands-on practice, use IBM Quantum (free tier) and the Qiskit tutorials (qiskit.org/learn) to run the circuits described above.",
        },
        {
          title: "Quantum Gates & Circuits",
          description:
            "Single-qubit gates (Pauli, Hadamard); two-qubit gates (CNOT); building circuits from gates",
          order: 1,
          imageUrl:
            "https://placehold.co/800x400/7c3aed/white?text=Pauli+Hadamard+CNOT+Circuits",
          content:
            "**1. Learning flow:** (1) Read material on Pauli X/Z, Hadamard H, and CNOT: Pauli X flips |0⟩↔|1⟩; H creates equal superposition; CNOT uses one qubit as control to flip the other and can create entanglement. (2) Draw the Bell-state circuit on paper: start with |00⟩, apply H on q0, then CNOT with q0 as control and q1 as target; write the state after each step. (3) Compute the resulting state by hand: after H(0) you get (|00⟩+|10⟩)/√2; after CNOT(0,1) you get (|00⟩+|11⟩)/√2. (4) Real case: in Qiskit build this circuit (QuantumCircuit(2); h(0); cx(0,1); measure_all()), run it with AerSimulator() and shots=1000, and verify you see only 00 and 11 with roughly equal counts.\n\n**2. Material:** Quantum gates are unitary operations. Pauli X: bit flip |0⟩↔|1⟩. Pauli Z: phase flip (|1⟩ → -|1⟩). Hadamard H: |0⟩ → (|0⟩+|1⟩)/√2, |1⟩ → (|0⟩-|1⟩)/√2. CNOT: if control |1⟩, flip target; else leave target. Creates entanglement. CZ, SWAP for other operations. Circuits: left-to-right (time); wire = qubit; gates = boxes. Universal set: H, CNOT, T approximate any computation.\n\n**3. Explanation:** Unitary = reversible; preserves norm. H creates superposition; CNOT entangles. H on |0⟩ gives equal superposition; CNOT with that as control gives (|00⟩+|11⟩)/√2 (Bell state). Gates compose: apply in sequence; state flows through.\n\n**4. Application:** Real case: Bell state circuit. Start |00⟩. H(0): q0 → (|0⟩+|1⟩)/√2, q1 still |0⟩. State: (|00⟩+|10⟩)/√2. CNOT(0,1): if q0=1 flip q1. Result: (|00⟩+|11⟩)/√2. Measurement: 00 or 11, each 50%. Used in quantum teleportation, error correction.\n\n**5. How to implement:** (1) Install Qiskit: pip install qiskit qiskit-aer. (2) Build circuit: from qiskit import QuantumCircuit; qc = QuantumCircuit(2); qc.h(0); qc.cx(0,1); qc.measure_all(). (3) Run: from qiskit_aer import AerSimulator; from qiskit import execute; result = execute(qc, AerSimulator(), shots=1000).result(); counts = result.get_counts(). (4) Expect ~500 for '00' and ~500 for '11'; no '01' or '10'. (5) Visualize: qc.draw('mpl') or qc.draw('text'). (6) Try Pauli X: qc.x(0) flips |0⟩ to |1⟩; try H then X then H to see different outcomes. See code in Algorithms & Qiskit.\n\n**6. Logic & how the code works:**\n\nHadamard puts |0⟩ into equal superposition (|0⟩+|1⟩)/√2; applied to the first qubit of |00⟩ you get (|00⟩+|10⟩)/√2. CNOT then flips the second qubit when the first is |1⟩, giving (|00⟩+|11⟩)/√2 (Bell state). The circuit is read left to right; each gate multiplies the state vector by the gate's unitary matrix.\n\n**7. Example problem & solution:** Problem: H on q0, CNOT(0,1) from |00⟩. Result? Solution: H(0): (|00⟩+|10⟩)/√2. CNOT: (|00⟩+|11⟩)/√2. Bell state. Measuring q0: if 0, q1=0; if 1, q1=1.\n\n**8. Additional information:** X, Y, Z are Pauli matrices. T gate: π/8 rotation; needed for universal set. Decomposition: any gate ≈ sequence of H, CNOT, T. Qiskit Textbook (qiskit.org/learn) for visual circuits. IBM Quantum Composer for drag-and-drop.",
        },
        {
          title: "Algorithms & Qiskit",
          description:
            "Grover's search and Shor's factoring in concept; running simple circuits with Qiskit in Python",
          order: 2,
          imageUrl:
            "https://placehold.co/800x400/0d9488/white?text=Grover+Shor+Qiskit+Python",
          content:
            "**1. Learning flow:** (1) Read Grover and Shor at a high level: Grover gives O(√N) search over N items using an oracle and diffusion; Shor factors integers in polynomial time using period finding and breaks RSA. (2) Install Qiskit: pip install qiskit qiskit-aer. (3) Build the Bell state circuit (QuantumCircuit(2); h(0); cx(0,1); measure_all()) and run it on AerSimulator() with shots=1000; verify you get roughly half 00 and half 11. (4) Plot the result with plot_histogram(counts) to visualize the distribution. (5) Real case: create a free IBM Quantum account and run the same circuit on a real backend (e.g. ibmq_qasm_simulator or a small real device) to see how results differ from the ideal simulator due to noise and decoherence.\n\n**2. Material:** Grover: unstructured search of N items. Classical O(N); Grover O(√N). Oracle marks target; diffusion amplifies its amplitude. Used for search, optimization. Shor: factors integers in poly-time (digits); breaks RSA. Uses period finding via QFT. Qiskit: QuantumCircuit(n), add gates (h, cx, etc.), measure, execute(circuit, backend). Backend: AerSimulator() or IBMQuantumProvider() for real hardware. Get counts, plot histogram.\n\n**3. Explanation:** Grover: start in superposition; oracle flips phase of target; diffusion amplifies target amplitude. Repeat √N times; measure. Shor: reduce factoring to period finding; QFT finds period; classical post-processing factors. Both exploit superposition and interference.\n\n**4. Application:** Real case: Bell state in Qiskit. from qiskit import QuantumCircuit; from qiskit_aer import AerSimulator. qc = QuantumCircuit(2); qc.h(0); qc.cx(0,1); qc.measure_all(). result = execute(qc, AerSimulator(), shots=1024).result(); print(result.get_counts()). Expect ~512 '00', ~512 '11'. Vary shots; more shots = smoother distribution.\n\n**5. How to implement:** (1) pip install qiskit qiskit-aer. (2) Import: from qiskit import QuantumCircuit, execute; from qiskit_aer import AerSimulator. (3) Build circuit: qc = QuantumCircuit(2); qc.h(0); qc.cx(0,1); qc.measure([0,1],[0,1]) or qc.measure_all(). (4) Run: backend = AerSimulator(); job = execute(qc, backend, shots=1000); counts = job.result().get_counts(); print(counts). (5) Visualize: from qiskit.visualization import plot_histogram; plot_histogram(counts). (6) For IBM real hardware: from qiskit_ibm_runtime import QiskitRuntimeService; service = QiskitRuntimeService(); backend = service.backend('ibmq_qasm_simulator'); then execute(qc, backend, shots=1024). (7) Explore Grover: use qiskit.circuit.library.GroverOperator in a circuit; for Shor see Qiskit documentation and tutorials. See code below.\n\n**6. Logic & how the code works:**\n\nQiskit builds a circuit (gates on qubits), then execute() runs it on a backend (simulator or real device). shots=1000 means you run the circuit 1000 times and collect outcomes; the counts dict gives how often each bitstring was observed. For the Bell state you expect roughly half 00 and half 11 because the state is (|00⟩+|11⟩)/√2.\n\n**7. Example problem & solution:** Problem: Bell state circuit; run 1000 shots. Expected? Solution: ~500 for 00, ~500 for 11 (may vary due to randomness). No 01 or 10. Confirms entanglement: when q0=0, q1=0; when q0=1, q1=1.\n\n**8. Additional information:** Grover: qiskit.circuit.library.GroverOperator. Shor: advanced; see Qiskit tutorials. IBM Quantum: free tier for real hardware (limited qubits). Decoherence limits current devices. Post-quantum crypto: research ongoing for RSA replacement.",
        },
      ],
    },
    {
      title: "Interview Preparation",
      slug: "interview-preparation",
      description:
        "Prepare for top-company interviews: coding (patterns, LeetCode, complexity), system design (requirements, scale, trade-offs), object-oriented design (OOD) for low-level problems, behavioral stories (STAR, leadership principles), resume and portfolio checklist, and company-specific prep and offer negotiation. Before you start: complete or review Competitive Programming and CS Theory for coding; System Design & DevOps and Computer Networks for system design; have at least one project and resume ready.",
      order: 13,
      published: true,
      items: [
        {
          title: "Coding Interviews",
          description:
            "Data structures & algorithms, problem-solving, time complexity, practice platforms (LeetCode, Codeforces)",
          order: 0,
          imageUrl:
            "https://placehold.co/800x400/1e3a8a/white?text=Coding+Interview",
          content:
            '**1. Learning flow:**\n\n(1) Read the material below and the list of patterns (two pointers, sliding window, binary search, DP, BFS/DFS, heaps, etc.) so you know what interviewers typically ask and how to classify a problem. (2) Work through the Competitive Programming section in this curriculum so you have solid foundations for each pattern: complexity, classic problems, and code templates. (3) Practice 1–2 LeetCode Easy or Medium problems daily; aim for 150–200 problems before your first interviews so patterns and coding speed become automatic. (4) For each practice problem, simulate the real process: clarify the question, state brute force and complexity, then optimize and code, then test with an example and edge case. (5) Real case: in a 45-minute coding round you will typically get one Medium or two Easy/Medium problems; spend the first few minutes clarifying and planning so you do not code the wrong solution.\n\n**2. Material:**\n\n**What they test:** Can you understand a problem, propose a correct and efficient solution, and implement it cleanly under time pressure? They care about your problem-solving process as much as the final code: clarifying requirements, identifying the right pattern, stating brute force and then optimizing, coding with clear variable names and structure, and testing with examples.\n\n**Patterns to master:** Two pointers (sorted array pairs, palindromes); sliding window (subarray/substring with a condition); binary search (on index or on the answer); dynamic programming (1D and 2D, state and recurrence); BFS and DFS (graphs, trees, level order); heaps (top K, merge K lists); hash map (lookups, counting); recursion and backtracking (subsets, permutations). Each pattern has classic problems (e.g. Two Sum, Sliding Window Maximum, Climbing Stairs, Number of Islands) that you should be able to solve and explain in under 25 minutes.\n\n**How to prepare:** Practice 1–2 problems daily on LeetCode (Easy and Medium); do at least 150–200 problems before interviews so you see enough variety. Always state brute force first and its time/space complexity, then optimize and state the new complexity. Clarify input range, duplicates, and return value before coding. Test your code with the given example and at least one edge case (empty input, single element, all same). Time yourself: aim for about 15 minutes for an Easy and 25 minutes for a Medium including explanation and testing.\n\n**3. Explanation:**\n\nInterviewers use coding rounds to see how you think, not only whether you get the answer. They want to see: (1) that you understand the problem (repeat it, ask clarifying questions); (2) that you can break it down (brute force first, then improve); (3) that you can code clearly (meaningful names, logical structure); and (4) that you verify your solution (run through an example, consider edge cases). Communication matters as much as the solution: talking through your approach helps them follow your reasoning and often surfaces bugs before you write code. Stating time and space complexity shows you understand the trade-offs.\n\n**4. Application:**\n\nUse this process in every practice and every interview. Example: Two Sum variant. Clarify: Is the array sorted? Can there be duplicates? Do we return indices or values? Can we use the same element twice? Brute force: two nested loops, check every pair — O(n²) time, O(1) space. Optimize: one pass with a hash map storing value → index; for each element check if (target - current) is in the map — O(n) time, O(n) space. Code with clear variable names; test with [2, 7, 11], target 9 → indices 0, 1; test edge case empty array or no solution. State final complexity. In a real 45-minute round you might get one such problem plus a follow-up (e.g. Three Sum) or a second problem.\n\n**5. How to implement:**\n\n(1) Repeat the problem in your own words and ask 2–3 clarifying questions: input size and range, duplicates, sorted or not, return value (indices, value, count, boolean), and edge cases (empty, single element, no solution). (2) Work through a small example on the board or paper (e.g. given [2, 7, 11], target 9 → indices 0, 1) and one edge case (e.g. empty array → return empty or -1). (3) State brute force and its time/space complexity (e.g. two loops → O(n²) time, O(1) space). (4) Optimize: identify the pattern (e.g. hash map for O(1) lookup), explain the improved approach, and state new complexity (e.g. O(n) time, O(n) space). (5) Code in clear steps: use meaningful variable names (e.g. seen or indexByValue), add a brief comment if the logic is non-obvious, and mention where you would add null or empty checks in production. (6) Test with your example and one edge case; state final time and space complexity. (7) Use the Competitive Programming section in this curriculum for detailed pattern breakdowns (two pointers, sliding window, DP, BFS/DFS, heaps, etc.). Time yourself in practice: Easy in about 15 minutes, Medium in about 25 minutes, including thinking and testing.\n\n**6. Logic & how the code works:**\n\nInterviewers expect a clear sequence: clarify the problem, propose a brute force and its complexity, then improve (e.g. hash map for O(n) lookups, or sliding window to avoid re-scanning). Your code should read like a narrative: build a map of value to index, iterate once, for each element check if the complement exists in the map, return or update as needed. For a sliding-window problem (e.g. longest substring without repeating characters), the logic is: maintain a window [left, right] such that all characters in the window are unique; when advancing right adds a duplicate, advance left until the duplicate is removed; at each valid window update the maximum length. Testing with an example (e.g. "abcabcbb" → 3) and an edge case (e.g. "" or "a") confirms the code before you finish.\n\n**7. Example problem & solution:**\n\nProblem: Longest substring without repeating characters. Given a string, find the length of the longest substring without repeating characters. Clarify: ASCII only or Unicode? If Unicode, use a map for counts. Brute force: check every substring O(n²), for each check uniqueness O(n) → O(n³) or O(n²) with a set. Optimize: sliding window + set (or map of char → count). Maintain [left, right]; for each right, while s[right] is already in the set, remove s[left] and advance left; add s[right], update max length. Code; test "abcabcbb" → 3 ("abc"); test "bbbbb" → 1; test "" → 0. Time O(n), space O(min(n, alphabet size)).\n\n**8. Additional information:**\n\nUse a pattern-based roadmap (e.g. NeetCode roadmap or Blind 75) so you cover all major patterns. Time yourself in practice: Easy 15 min, Medium 25 min. Do mock interviews with a friend or on Pramp/Interviewing.io to get used to speaking while coding. Record yourself and review: did you clarify? Did you state complexity? Did you test? Common mistakes: coding too soon before clarifying, not stating brute force, not testing with an example, and not mentioning time/space complexity. Refer to the Competitive Programming section in this curriculum for full details on each pattern and classic problems.',
        },
        {
          title: "System Design Interviews",
          description:
            "Scaling, APIs, databases, trade-offs; whiteboard and discussion; design URL shortener, chat, feed",
          order: 1,
          imageUrl:
            "https://placehold.co/800x400/2563eb/white?text=System+Design",
          content:
            "**1. Learning flow:**\n\n(1) Read the material and the recommended framework below so you have a consistent structure: clarify requirements, draw high-level design, do back-of-envelope estimates, deep-dive one or two components, and discuss trade-offs. (2) Study the System Design & DevOps, Computer Networks, and Operating Systems sections in this curriculum so you have the building blocks (load balancers, databases, caches, message queues, REST, scaling). (3) Practice designing systems on paper or a whiteboard: start with URL shortener and chat app, and time yourself (about 30–40 minutes each) so you get used to the pace. (4) In a real 45-minute system design round you will typically: spend 5–10 minutes clarifying requirements, 10–15 minutes on high-level design and estimates, 15–20 minutes deep-diving one or two components (e.g. database sharding, caching, or message flow), and 5–10 minutes on trade-offs and follow-ups.\n\n**2. Material:**\n\n**What they test:** Can you design a scalable, maintainable system and discuss trade-offs? They want to see end-to-end thinking: from requirements and scale to components, data flow, and how you would scale or fix bottlenecks. You do not need to know every technology in depth, but you should be able to reason about load balancers, databases, caches, message queues, and when to use strong vs eventual consistency.\n\n**Framework:** (1) **Clarify requirements:** Ask about scale (DAU, QPS, growth), latency (p50, p99), consistency (strong vs eventual), and key features (read-heavy vs write-heavy, real-time vs batch). (2) **High-level design:** Draw clients → load balancer → app servers → database and cache; add message queue or CDN if the problem needs it. (3) **Back-of-envelope:** Estimate storage (e.g. 1M users × 1KB per user = 1GB), QPS (e.g. 10K requests/s), and bandwidth (QPS × request/response size). (4) **Deep-dive:** Pick one or two components (e.g. database sharding, cache invalidation, or message flow) and explain how they work and how they scale. (5) **Trade-offs:** Discuss CAP (consistency vs availability), latency vs consistency, cost vs redundancy. **Classic problems to practice:** URL shortener, chat app, news feed, rate limiter, design Twitter/Instagram-style feed.\n\n**3. Explanation:**\n\nInterviewers use system design to see how you think about distributed systems: they want requirements first so you do not over- or under-design, then a clear high-level picture (data flow, main components), then depth on at least one area (e.g. how would you shard the database? how would you invalidate the cache?). Back-of-envelope numbers (e.g. 1M users, 10K QPS, 1KB per request → 10 MB/s bandwidth) show you can reason about scale. Trade-offs (e.g. strong consistency vs availability, or caching vs consistency) show you understand real-world constraints. Start simple (single server, single DB) and add complexity (replication, sharding, cache) when the interviewer asks or when scale demands it.\n\n**4. Application:**\n\nUse this framework in every practice and interview. Example: Design a URL shortener. Requirements: 1M new URLs per day, 7-year retention, redirect latency matters. High-level: Client → API → app servers → database (id → longUrl); generate short code from id (e.g. base62). Deep-dive: database will grow (1M × 365 × 7 rows); shard by id range or hash of id; use a cache (e.g. Redis) for hot URLs so most redirects do not hit the DB. Trade-off: cache invalidation is eventual (if someone updates a long URL, cache may be stale for a short time)—acceptable for redirects. Another example: design a chat app (10M users, 1K messages/sec, real-time). High-level: clients → WebSocket servers → message queue → DB for history. Deep-dive: message queue (e.g. Kafka) for fan-out to online users; persist to DB for history; clients get real-time via WebSocket and can fetch history from DB.\n\n**5. How to implement:**\n\n(1) Clarify requirements: ask about scale (DAU, QPS, expected growth), latency (p99, p50), consistency (strong vs eventual), and key features (read-heavy vs write-heavy, real-time vs batch, retention). (2) Draw high-level: clients → load balancer → app servers → database and cache; add message queue, CDN, or search index if the problem needs it. Label the main data flow (e.g. write path vs read path). (3) Back-of-envelope: estimate storage (e.g. 1M users × 1KB = 1GB), QPS (e.g. 10K reads/s), bandwidth (QPS × payload size); this bounds the problem. (4) Deep-dive one or two components: pick the bottleneck or the most interesting part (e.g. DB sharding by user_id or by id range; cache strategy and invalidation; message queue for async processing or fan-out). Explain how it works and how it scales. (5) Discuss trade-offs: CAP (consistency vs availability under partition), latency vs consistency (e.g. read-your-writes vs eventual), cost vs redundancy (replicas, multi-region). (6) Use the System Design & DevOps and Computer Networks sections in this curriculum for details on load balancers, databases, caches, REST, and scaling patterns.\n\n**6. Logic & how the code works:**\n\nClarifying requirements (QPS, latency, consistency) bounds the problem so you do not over-design (e.g. no need for 10 data centres if QPS is 100) or under-design (e.g. single DB will not hold 1B rows). The high-level diagram (clients → LB → app → DB/cache) shows data flow and where bottlenecks might be. Deep-diving one component (e.g. how to shard the DB by user_id, or how cache invalidation works when a value is updated) demonstrates that you can go from architecture to implementation details. Trade-offs (e.g. strong vs eventual consistency) show you understand that real systems make compromises and that the right choice depends on the use case.\n\n**7. Example problem & solution:**\n\nProblem: Design a chat application. Requirements: 10M users, 1K messages per second, real-time delivery, message history. High-level: clients connect via WebSocket to app servers; when a user sends a message, the server publishes it to a message queue (e.g. Kafka); consumers persist to the database and push to online recipients; clients can fetch history from the API (read from DB). Deep-dive: use a message queue so that multiple app servers can consume the same message and fan out to the right users; partition the queue by conversation or user so parallelism is possible; store messages in the DB with (conversation_id, timestamp, sender, content) and index by conversation_id for history. Trade-off: real-time delivery is best-effort (we push when the user is online); history is eventually consistent if we write to DB asynchronously—acceptable for chat. Scale: 1K msg/s × 500 bytes ≈ 500 KB/s write; DB can be sharded by conversation_id.\n\n**8. Additional information:**\n\nRecommended reading: Designing Data-Intensive Applications (Kleppmann). Online: ByteByteGo, System Design Primer (GitHub). Practice with mocks (Pramp, Interviewing.io) or with a friend; draw clearly and communicate your assumptions. Allocate 2–4 weeks for system design prep with regular mocks. In the interview, state your assumptions when you do not have exact numbers and be ready to adjust the design if the interviewer changes the requirements.",
        },
        {
          title: "Object-Oriented Design (OOD)",
          description:
            "Low-level design: parking lot, elevator, deck of cards; classes, interfaces, SOLID in practice",
          order: 2,
          imageUrl: "https://placehold.co/800x400/16a34a/white?text=OOD+Design",
          content:
            '**1. Learning flow:**\n\n(1) Read the material below and review the SOLID and OOP sections in the CS Theory part of this curriculum so you understand encapsulation, interfaces, and composition over inheritance—OOD interviews test whether you can model a real-world problem with clear classes and interfaces. (2) Design a parking lot on paper first: identify the main nouns (ParkingLot, Level, Spot, Vehicle) and verbs (park, unpark, findAvailableSpot); define an interface (e.g. Parkable or Vehicle with getSize()) so the lot logic does not depend on concrete vehicle types. (3) Draw a class diagram showing relationships (ParkingLot has Levels, Level has Spots, Spot can hold a Vehicle; Car and Motorcycle extend or implement Vehicle) and then code the core flow: park(vehicle) finds an available spot of the right size and assigns the vehicle; unpark(vehicle) frees the spot. (4) In a real 30-minute OOD round the interviewer expects you to clarify requirements (e.g. spot sizes, vehicle types), list classes and methods, draw or describe the diagram, and implement one or two core methods in code—so practice under time pressure with a clear structure.\n\n**2. Material:**\n\n**What they test:** OOD rounds assess whether you can take an ambiguous problem (e.g. "Design a parking lot" or "Design an elevator") and produce a clean object-oriented model: clear classes, sensible interfaces, and methods that match the problem. They look for single responsibility (each class has one job), extensibility (adding a new vehicle type or elevator algorithm without rewriting existing code), and the ability to tie your design to SOLID and design patterns when asked.\n\n**Steps that work:** (1) **Identify nouns and verbs:** Nouns in the problem description (parking lot, level, spot, vehicle, elevator, request) are candidates for classes; verbs (park, unpark, find spot, add request, move) are candidates for methods. (2) **Define interfaces:** Use interfaces or abstract classes for key behaviors (e.g. Vehicle with getSize(), or Parkable) so the main logic (e.g. ParkingLot) depends on abstractions, not concrete types—this keeps the design open for extension (new vehicle types) and closed for modification. (3) **Use inheritance only when there is a clear is-a relationship:** Car and Motorcycle may extend Vehicle; prefer composition (Vehicle has Engine) over deep inheritance when behavior can be composed. (4) **Consider extensibility:** How would you add a Truck (different spot size)? A new elevator scheduling algorithm? Design so that adding these does not require changing existing classes.\n\n**Classic problems:** Parking lot (levels, spots, vehicles, park/unpark), elevator (floors, requests, direction, move algorithm), deck of cards (Card, Suit, Deck, shuffle, deal), chess (Board, Piece, Move, legal moves). Tie your choices to SOLID (e.g. Single Responsibility: Spot only knows its state; Open/Closed: new vehicle types via new classes) and to design patterns (e.g. Strategy for elevator algorithm) when the interviewer asks.\n\n**3. Explanation:**\n\nNouns in the problem become classes: ParkingLot, Level, Spot, Vehicle. Each class has a single responsibility: Spot holds a vehicle or is empty; Level holds a list of spots; ParkingLot holds levels and delegates park/unpark. Verbs become methods: park(vehicle), unpark(vehicle), findAvailableSpot(size). Interfaces (e.g. Vehicle with getSize()) provide abstraction: the lot only needs to know the vehicle\'s size to find a spot, so you can add Car, Motorcycle, Truck without changing the lot logic. Composition over inheritance means you prefer "Vehicle has an Engine" over "Car extends Engine" so that behavior can be combined flexibly and you avoid deep, fragile inheritance trees. In an interview, stating these choices ("I\'m using an interface here so we can add new vehicle types later") shows you understand maintainability and extensibility.\n\n**4. Application:** Real case: Parking lot. Classes: ParkingLot (levels, capacity), Level (spots), Spot (size, vehicle), Vehicle (plate, size). Methods: park(vehicle), unpark(vehicle), findAvailableSpot(size). Extensibility: Car, Motorcycle extend Vehicle; add Truck with different spot size.\n\n**5. How to implement:** (1) List nouns (candidates for classes: ParkingLot, Level, Spot, Vehicle) and verbs (candidates for methods: park, unpark, findAvailableSpot). (2) Draw a class diagram: boxes for classes, arrows for has-a (composition) and is-a (inheritance); prefer composition over deep inheritance. (3) Define interfaces for key behaviors (e.g. Parkable for vehicles, or Vehicle with getSize()). (4) Code one class at a time: start with core entities (Spot, Vehicle), then aggregate (Level, ParkingLot); implement the main flow (ParkingLot.park(vehicle) → find spot → assign). (5) Handle edge cases: lot full, no spot for vehicle size, unpark when empty; use return values or exceptions as appropriate. (6) Consider extensibility: new vehicle types (Truck, Motorcycle) without changing lot logic. See CS Theory OOP and Design Patterns sections for SOLID and patterns (Strategy, Factory).\n\n**6. Logic & how the code works:**\n\nNouns in the problem (parking lot, spot, vehicle) become classes; actions (park, unpark) become methods. An interface (e.g. Parkable) abstracts what can be parked so you can add new vehicle types without changing the lot logic. Composition (Vehicle has Engine) is preferred over deep inheritance so behavior can be combined flexibly.\n\n**7. Example problem & solution:** Problem: Design elevator. Classes: Elevator (currentFloor, direction, requests), Request (floor, direction). Methods: addRequest(floor), move(), getNextFloor(). State: IDLE, MOVING_UP, MOVING_DOWN. Algorithm: SCAN or nearest-first. Code move() and addRequest(). Extensibility: multiple elevators → ElevatorController.\n\n**8. Additional information:** Amazon, Microsoft often ask OOD. Practice: parking lot, elevator, deck of cards, chess, ATM. Use design patterns when they fit (Strategy for elevator algorithm). Keep it simple; don\'t over-engineer.',
        },
        {
          title: "Behavioral & Communication",
          description:
            "STAR method, leadership principles, conflict, impact; Amazon/Google LP; soft skills",
          order: 3,
          imageUrl:
            "https://placehold.co/800x400/7c3aed/white?text=Behavioral+STAR",
          content:
            '**1. Learning flow:**\n\n(1) Read the material below and the STAR format in full so you know exactly how to structure each answer: Situation (brief context, about 20 seconds), Task (your responsibility, about 15 seconds), Action (what you did step by step, about 60 seconds—this is the most important part), and Result (outcome and metric if possible, about 25 seconds). (2) Write 5–7 complete stories that cover the main themes interviewers ask about: conflict with a teammate or stakeholder, leadership or ownership, a failure and what you learned, impact with a measurable outcome, teamwork or cross-team collaboration, and deadline pressure or prioritisation. (3) Practice each story out loud with a timer; aim to finish in under 2 minutes so you do not ramble and you leave time for follow-up questions. (4) In a real 30-minute behavioral round they will ask 3–5 questions and want concrete examples with specifics—not generic answers like "I am a team player"; they want to hear what you did, what you said, and what the outcome was, ideally with a number or metric.\n\n**2. Material:**\n\n**What they test:** Can you work effectively with others, take ownership, and drive impact? They want evidence, not claims. Every answer should be a concrete example from your past: when, where, who was involved, what your role was, what you did (with enough detail that they can picture it), and what the result was. If you can add a metric (reduced latency by 40%, shipped 2 weeks early, improved conversion by 15%), that strengthens the answer.\n\n**STAR format:** **Situation** (20 sec): Set the scene—when, where, which team or project, what was at stake. Keep it brief so you have time for the rest. **Task** (15 sec): Your responsibility—what were you accountable for? This shows ownership. **Action** (60 sec): The heart of the answer. What did you do? Use "I" not "we" when describing your actions—they want to know your contribution. Include 3–5 concrete steps: e.g. "I scheduled a 1:1," "I proposed a compromise," "I ran an A/B test." **Result** (25 sec): What was the outcome? Did you hit the goal? What did you learn? If you have a number (time saved, users affected, bugs fixed), say it.\n\n**Themes to prepare:** Conflict (disagreement with a teammate or manager; how you resolved it). Leadership (a time you took ownership or led without authority). Failure (a project or goal you missed; what you learned and what you would do differently). Impact (a result you are proud of, with a metric if possible). Teamwork (working with another team or a difficult stakeholder). Deadline pressure (tight timeline; how you prioritised and delivered). Company fit: research the company\'s values (e.g. Amazon Leadership Principles, Google Googleyness) and prepare 1–2 stories that align with each value you expect to be asked about.\n\n**3. Explanation:**\n\nSTAR works because it gives the interviewer a clear structure: they get context quickly (Situation), they see that you took ownership (Task), they hear the details of what you did (Action—the most important part), and they get proof that it mattered (Result). Interviewers are trained to look for specificity: "I led the project" is weak; "I ran daily standups, unblocked three engineers on API design, and we shipped 2 weeks early" is strong. Using "I" instead of "we" when describing your actions makes it clear what you contributed. Metrics (percentage improvement, time saved, number of users) make the result credible and memorable. If you do not have a metric, a clear outcome ("we chose approach A based on the data," "the customer signed the contract") still works.\n\n**4. Application:**\n\nUse STAR for every behavioral question. Example: "Tell me about a conflict with a teammate." Situation: "On my last project, a teammate and I disagreed on the API design—I wanted REST, they wanted GraphQL." Task: "I owned the backend API, so I needed to align with them without blocking the frontend." Action: "I scheduled a 1:1, listened to their concerns about over-fetching, proposed we run a two-week spike on both approaches and compare latency and developer experience. I documented the trade-offs and we presented to the team. We ran the spike and chose GraphQL based on the data." Result: "We shipped on time and both sides were happy with the decision. I learned that data beats opinion in technical disagreements." Keep the whole answer under 2 minutes; if they want more they will ask follow-ups (What would you do differently? What was the hardest part?).\n\n**5. How to implement:**\n\n(1) List 10–15 past experiences: projects you led or contributed to, conflicts you resolved, failures you learned from, times you had to influence without authority, tight deadlines, cross-team work, and any situation where you had a clear impact (with or without a number). (2) Map each experience to 1–2 company values or common themes (e.g. conflict → Ownership and Customer Obsession; failure → Learn and Be Curious; impact → Deliver Results; leadership → Bias for Action). (3) Write a full STAR for 5–7 stories: Situation (2–3 sentences: when, where, team, stakes), Task (your responsibility in one or two sentences), Action (4–6 concrete steps using "I"; include what you said or did, not just "we discussed"), Result (outcome and one thing you learned). (4) Practice each story out loud with a 2-minute timer; record yourself and review—are you specific enough? Are you using "I" for your actions? (5) Prepare follow-ups for each story: What would you do differently? What did you learn? What was the hardest part? What would you do if the same situation happened again? (6) For company-specific prep (e.g. Amazon): look up their Leadership Principles and have 1–2 stories that demonstrate each principle you expect to be asked about; you do not need a story per principle, but you should be able to answer "Tell me about a time you demonstrated Ownership" or "Customer Obsession" with a real example.\n\n**6. Logic & how the code works:**\n\nSTAR keeps your answer structured so the interviewer can follow and so you do not forget the result. Situation gives context quickly (they need to know the setting). Task shows ownership (they want to know it was your responsibility). Action is where you spend most of the time because they want evidence of behaviour—what you did, not what the team did. Result should include a metric or a clear outcome so they believe it mattered. Interviewers are looking for patterns: do you take ownership? Do you communicate? Do you learn from failure? Concrete examples with "I" and with numbers or clear outcomes are what they remember and what they use to score you.\n\n**7. Example problem & solution:**\n\nProblem: "Tell me about a time you failed." STAR answer: (S) "We had a deadline to ship a feature for a key client; I owned the backend." (T) "I was responsible for the API and integration with the frontend." (A) "Halfway through I realised we had scope creep—the client had added requirements that weren\'t in the original estimate. I raised it in standup, scheduled a call with the PM and the client, and proposed we cut the least critical part to hit the date. We negotiated and agreed to ship the core in two weeks and the rest in a follow-up. I reprioritised my tasks and we delivered the core on time." (R) "We launched one week late for the full scope but the client was happy because we communicated early and delivered the most important part on time. I learned to flag scope creep as soon as I see it." Keep under 2 minutes; show that you took ownership, communicated, and learned. Follow-up: "What would you do differently?" → "I would have asked for a written scope at the start and had a change process so we didn\'t discover new requirements mid-sprint."\n\n**8. Additional information:**\n\nAmazon Leadership Principles: have 1–2 stories per principle you expect (Ownership, Bias for Action, Customer Obsession, Deliver Results, Learn and Be Curious, etc.). Google often asks about ambiguity, bias for action, and impact. Practice with mock interviews (Pramp, Interviewing.io, or a friend) so you get used to saying your stories out loud. Be specific; avoid generic answers like "I am a hard worker" or "I love teamwork" without a story. Always use "I" when describing your actions so they know what you did. If you do not have a metric, a clear outcome ("we shipped on time," "the bug was fixed," "the customer renewed") is still strong.',
        },
        {
          title: "Resume & Portfolio",
          description:
            "CV structure, projects to highlight, GitHub, LinkedIn; preparation checklist",
          order: 4,
          imageUrl:
            "https://placehold.co/800x400/ea580c/white?text=Resume+%26+Portfolio",
          content:
            '**1. Learning flow:**\n\n(1) Read the material and the resume checklist below so you know what recruiters and hiring managers look for: strong verbs that show ownership, metrics that prove impact, and a tech stack that matches the job. (2) Update your resume: replace weak phrases ("Helped with," "Worked on") with strong action verbs (Designed, Implemented, Led, Optimized) and add at least one metric per bullet where possible (latency reduction, user count, release count, test coverage). (3) Ensure your GitHub has 2–3 clean repositories: each should have a clear README (what the project does, how to run it, tech stack, and optionally screenshots), a sensible .gitignore, no secrets in code, and ideally tests or a deployment link so reviewers see you care about quality. (4) Before every interview: know every line on your resume; be ready to go deep on any project (what problem it solved, your role, technical decisions, and outcome) in about 2 minutes. Recruiters and interviewers will ask "Tell me about this project" and you need a concise, confident answer.\n\n**2. Material:**\n\n**Resume structure:** For most candidates with under about 5 years of experience, one page is the norm; recruiters spend only a few seconds on the first pass, so every line should earn its place. Use strong action verbs at the start of each bullet: Designed, Built, Implemented, Led, Optimized, Reduced, Shipped, Architected. Avoid weak or vague wording: "Helped with" or "Worked on" without saying what you owned; "Responsible for" without saying what you did. Add metrics wherever you can: reduced latency by 40%, shipped to 1M users, led a team of 4, improved test coverage from 60% to 85%. List your tech stack (languages, frameworks, tools) so ATS and recruiters can match you to the job description. Use 2–4 bullet points per role or project; each bullet should be one clear achievement, not a list of duties. Format: PDF, no graphics or complex tables that break applicant tracking systems (ATS), consistent font and spacing, and no typos—proofread and have someone else review.\n\n**Portfolio and GitHub:** Your GitHub is part of your portfolio. Choose 2–3 repos that best show your skills: ideally a full-stack or backend project, or something relevant to the role. Each repo should have a README that explains the problem, the solution, how to set up and run the project, and the tech stack; screenshots or a link to a live demo help. Code quality signals: .gitignore so generated files and secrets are not committed, no API keys or passwords in the repo, and tests or a CI config show you care about reliability. LinkedIn should be updated and aligned with your resume (same dates, same role titles, consistent story) so there are no red flags when they cross-check.\n\n**3. Explanation:**\n\nStrong verbs (Designed, Implemented, Led) signal ownership: they show you did the work, not just that you were on the team. Metrics (40% faster, 1M users, 3 releases) give proof that your work had impact; they are what interviewers remember and what they use to compare you to other candidates. Tech stack and keywords from the job description help ATS rank your resume and help recruiters see a fit. One page forces you to prioritise: only your strongest, most relevant achievements stay, so every line counts. A clean GitHub with a good README and tests signals that you write code for others to read and that you care about quality; it also gives interviewers something concrete to ask about ("How did you structure this?" "Why did you choose this stack?"). Knowing your resume cold means you can answer "Tell me about this project" or "Walk me through your experience" without hesitation and with the right level of detail (problem, your role, outcome).\n\n**4. Application:**\n\nApply these rules to every bullet. Example of a weak bullet: "Worked on the API." It does not say what you did or what the result was. Strong version: "Designed and implemented REST API serving 10K req/s; reduced P99 latency by 40% via caching and query optimisation." Another weak bullet: "Used React." Strong version: "Built React dashboard with TypeScript and Redux; reduced initial load time by 50% with code splitting and lazy loading." For each role or project, ask yourself: What did I own? What was the outcome? Can I add a number? If you led a team, say the size ("Led team of 4"); if you shipped something, say the scale ("Shipped to 500K users"); if you improved something, say the before/after ("Reduced deployment time from 2 hours to 15 minutes").\n\n**5. How to implement:**\n\n(1) Use strong action verbs for every bullet: Designed, Built, Implemented, Led, Optimized, Reduced, Shipped, Architected, Introduced; avoid Helped, Worked on, Assisted without clarifying your ownership. (2) Add one metric per bullet when possible: latency or performance improvement, user or traffic count, number of releases, team size, test coverage, time or cost saved. If you do not have an exact number, use a range or a qualitative outcome ("significantly reduced," "improved user feedback"). (3) Tailor your resume to the job: read the job description and include keywords (tools, languages, concepts) in your bullets so ATS and recruiters see a match; you can have a base resume and tweak a few bullets per application. (4) Keep to one page if you have under about 5 years of experience; use two pages only if you have many relevant roles, publications, or open source. (5) GitHub: for 2–3 repos write a README with problem, solution, setup instructions, tech stack, and optionally screenshots or demo link; ensure .gitignore is in place and no secrets are in the code; add tests or a note on how you ensured quality so reviewers see you care. (6) Before each interview: read your resume again; for each project prepare a 2-minute explanation (what it was, why it mattered, your role, technical choices, outcome). (7) Export as PDF; avoid graphics or complex tables that break ATS parsing; proofread and ask someone else to review for typos and clarity.\n\n**6. Logic & how the code works:**\n\nStrong verbs work because they imply ownership: "Designed" means you made decisions; "Implemented" means you wrote the code; "Led" means you coordinated others. Metrics work because they give evidence: "Reduced latency by 40%" is more convincing than "improved performance." ATS and recruiters often scan for keywords (e.g. "React," "Node," "distributed systems"); including them in your bullets increases the chance your resume is shortlisted. One page works because recruiters spend only a few seconds on the first pass; a second page often is not read unless the first page is strong. A clean GitHub works as a portfolio: when an interviewer says "Tell me about this project," you can point to the README and the code and give a structured answer (problem, solution, your role, outcome), which reinforces the story on your resume.\n\n**7. Example problem & solution:**\n\nProblem: Your resume has no metrics; bullets are vague ("Implemented features," "Optimized the system"). Solution: For each bullet ask: How much? How many? How fast? "Implemented feature" → "Shipped feature used by 50K users; reduced support tickets by 20%." "Optimized query" → "Reduced average query time from 2s to 200ms via indexing and query rewrite." "Led team" → "Led team of 4; delivered 3 releases on time; improved test coverage from 50% to 80%." "Worked on API" → "Designed and implemented REST API for payment flow; handled 1K req/s with p99 under 100ms." If you truly do not have a number, use a clear outcome: "Eliminated recurring production incident," "Enabled migration to new platform without downtime." Quantifying impact makes your resume stand out and gives interviewers something concrete to ask about.\n\n**8. Additional information:**\n\nATS (applicant tracking systems) parse resumes for keywords; use terms from the job description where they honestly apply. Avoid graphics, images, or complex tables that can break parsing. Proofread carefully; typos suggest carelessness. Have a colleague or friend review for clarity and impact. LinkedIn: keep headline and summary aligned with your resume; endorsements and recommendations add credibility. A personal portfolio site (optional) can showcase projects and writing and shows initiative. Before every interview, know your resume cold: you should be able to explain every line and go deep on any project without looking at the document.',
        },
        {
          title: "Company-Specific Prep & Timeline",
          description:
            "FAANG/top company process; how many weeks to prep; what each company emphasizes; offer & negotiation basics",
          order: 5,
          imageUrl:
            "https://placehold.co/800x400/dc2626/white?text=Offer+Negotiation",
          content:
            "**1. Learning flow:**\n\n(1) Read the material and the suggested timeline below so you know how much time to allocate to coding, system design, and behavioral preparation—this avoids under-preparing for one type and over-preparing for another. (2) Plan your prep: typically 4–8 weeks for coding (LeetCode plus the Competitive Programming section in this curriculum), 2–4 weeks for system design (mocks and diagrams), and 1–2 weeks for behavioral (STAR stories and company values); overlap weeks 3–6 so you are doing system design and behavioral while coding is still fresh. (3) Research each target company: look up their interview process (how many rounds, whether they include OOD, how many behavioral rounds) and what they emphasise (e.g. Amazon Leadership Principles, Microsoft OOD, Google coding and system design) so you prep the right format and do not get surprised. (4) When scheduling: try to batch interviews in a 2-week window so you receive multiple offers around the same time and can compare and negotiate from a position of leverage; recruiters can often accommodate a short delay so your loops align.\n\n**2. Material:**\n\n**Timeline:** For interview-focused prep (you already code but need to sharpen for interviews), a typical plan is 2–6 weeks total: 2–4 weeks of intensive coding (LeetCode Easy/Medium and the Competitive Programming section), 2–4 weeks of system design (reading, diagrams, and mocks with a partner or video), and 1–2 weeks of behavioral (writing STAR stories and researching company values). These can overlap: e.g. weeks 1–4 coding, weeks 3–6 system design and behavioral. If you are starting from a weaker baseline (e.g. new to algorithms), allow 2–4 months for a full pass of the curriculum plus practice. The key is to cover all interview types: coding, system design (for mid-level and above), and behavioral; many candidates only grind LeetCode and then underperform in system design or behavioral.\n\n**Process by company type:** Most tech companies use 1–2 coding rounds (45–60 min each), 1 system design round (45 min, for mid-level and above), and 1–2 behavioral rounds (30–45 min). Some add an object-oriented design (OOD) round (e.g. Amazon, Microsoft)—design a parking lot, elevator, or similar with classes and interfaces. Amazon is known for 3–4 behavioral rounds heavily focused on Leadership Principles (LP); you need 1–2 stories per principle. Google and Meta typically have 2 coding, 1 system design, 1–2 behavioral. Microsoft often includes OOD. Research the specific company on Glassdoor, Blind, or their careers page so you know the exact format.\n\n**Offers and negotiation:** Getting all offers in a short window (e.g. within 2 weeks) lets you compare total compensation (base, bonus, equity) and role and gives you leverage to negotiate. When you have an offer, it is standard to ask for 1–2 weeks to decide; use that time to finish other loops or to negotiate with the first company if you have a competing offer. Negotiating: be polite and professional; you can state market data (e.g. from Levels.fyi) or that you have another offer and would prefer to join them if they can match or improve on X. Never burn bridges: even if you decline, thank them and leave the door open. Always get the offer in writing (email or letter) before accepting; never accept verbally without a written offer. You can negotiate both base salary and signing bonus; equity is often harder to change but sometimes possible.\n\n**3. Explanation:**\n\nA clear timeline ensures you do not only grind coding and then show up unprepared for system design or behavioral. Different companies weight rounds differently: Amazon weights behavioral (LP) very heavily; Microsoft often asks OOD; Google and Meta weight coding and system design. Researching each company lets you allocate prep time where it matters. Batching interviews in a 2-week window is a practical strategy: you do not want one offer expiring while you are still in the middle of another company's process; having two or more offers at once gives you a better sense of your market value and the ability to negotiate. Asking for 1–2 weeks to decide after an offer is standard practice; recruiters expect it and it is acceptable to use that time to finish other interviews or to think. Negotiating politely with data (market rates, competing offer) is normal; companies often have room to improve an offer, especially if you have leverage. Never lying (e.g. inventing a fake offer) is important for your reputation and for reference checks.\n\n**4. Application:**\n\nUse this to plan. Example: You want to start interviewing in 6 weeks. Week 1–4: Focus on LeetCode and the Competitive Programming section; aim for 1–2 problems per day and ability to solve a Medium in 25 minutes. Week 3–6: Add system design: read or watch 2–3 system design breakdowns (e.g. URL shortener, chat), do 2–4 mocks with a partner. Week 5–6: Write 5–7 STAR stories and research Amazon LP (if you are applying to Amazon) or other company values; tailor 1–2 stories per value. Apply in week 4–5 so that by week 6–7 you are getting first rounds; try to schedule onsites in a 2-week window. When you get an offer, ask for 2 weeks to decide; use the time to finish other loops or to negotiate. Example by company: Amazon—prioritise LP stories (3–4 behavioral rounds); Microsoft—add OOD practice (parking lot, elevator); Google/Meta—prioritise coding and system design; all—have STAR stories ready.\n\n**5. How to implement:**\n\n(1) Choose your timeline based on when you want to start the job; work backward so you have enough weeks for coding, system design, and behavioral. (2) Weeks 1–4 (or more if needed): Focus on LeetCode and the Competitive Programming section in this curriculum so you can solve Easy problems in about 15 minutes and Medium in about 25 minutes and explain time/space complexity. (3) Weeks 3–6: Add system design: read Designing Data-Intensive Applications or watch ByteByteGo / System Design Primer; do 2–4 system design mocks (with a partner or using a video format) so you can sketch a system, do back-of-envelope estimates, deep-dive one component, and discuss trade-offs. (4) Weeks 5–6: Prepare behavioral: write 5–7 STAR stories (conflict, leadership, failure, impact, teamwork, deadline) and research each target company's values or leadership principles (e.g. Amazon LP); map your stories to their values so you can answer \"Tell me about a time you demonstrated Ownership\" with a real example. (5) Apply and try to schedule interviews so that onsites or final rounds fall in a 2-week window; when a recruiter offers dates, you can ask if they can accommodate a date that fits your other interviews. (6) After you receive an offer: reply promptly and thank them; ask for 1–2 weeks to decide (e.g. \"I'm very interested; I need to complete a couple of other conversations before I can make a final decision. Would two weeks be possible?\"); use the time to finish other loops or to prepare a negotiation (gather data from Levels.fyi, clarify the other offer if you have one). (7) When negotiating: be polite, state your case (market data or competing offer), and ask if they can match or improve; never burn bridges even if you decline.\n\n**6. Logic & how the code works:**\n\nA clear timeline (e.g. 4 weeks coding, 2–4 system design, 1–2 behavioral) ensures you cover every interview type instead of only grinding LeetCode. Many candidates neglect system design or behavioral and then underperform in those rounds; allocating time to each type raises your overall chance of success. Batching interviews in a 2-week window means you receive multiple offers around the same time, so you can compare total compensation and role and negotiate from a position of leverage; if you have only one offer and it expires soon, you have less room to wait for another. Researching each company's process (e.g. Amazon LP-heavy, Microsoft OOD) lets you prep the right format and reduces surprise; knowing that Amazon will ask many LP questions means you prioritise story preparation. Asking for 1–2 weeks to decide after an offer is standard; recruiters expect it and it is acceptable. Using that time to finish other interviews or to negotiate is normal; being polite and professional preserves relationships and your reputation.\n\n**7. Example problem & solution:**\n\nProblem: You have one offer but are still waiting for another company's result. Solution: Reply to the first company promptly and thank them; ask for 2 weeks to make a decision (e.g. \"I'm very excited about the role; I'm in the final stages with one other company and would like to make a fully informed decision. Would it be possible to have two weeks?\"). Use the time to follow up with the second company and, if possible, speed up their process. If the second offer comes and is better: you can go back to the first company and say, \"I have another offer; I'd prefer to join you if we can match the total compensation\" (or a specific number)—be polite and factual; never invent an offer. If the second company does not respond in time, you can still ask the first for a short extension (e.g. a few more days) if you need it; many recruiters can extend. Never lie about having another offer; if you do not have one, you can still negotiate based on market data (e.g. Levels.fyi) and your expectations.\n\n**8. Additional information:**\n\nUse Levels.fyi for compensation data (base, bonus, equity by company and level). Blind has company-specific tips and sometimes salary threads. Recruiters can often extend an offer deadline by a few days or a week if you ask politely. Always get the offer in writing (email or formal letter) before you accept; never accept verbally without a written offer. You can negotiate both base salary and signing bonus; equity is sometimes negotiable depending on level and company. Never accept an offer you are not happy with just because of time pressure—it is better to ask for an extension than to accept and then renege. If you decline an offer, do it politely and thank them; you may work with them or their company in the future.",
        },
      ],
    },
    {
      title: "Operating Systems & Concurrency",
      slug: "operating-systems-concurrency",
      description:
        "Core CS for system design and backend interviews: process vs thread and context switch, virtual memory and paging and TLB and stack vs heap, race conditions and mutex and semaphore, four conditions of deadlock and prevention (ordering, timeouts), and CPU scheduling (FCFS, SJF, round-robin, preemption). Before you start: basic programming and the idea of programs running in memory; Computer Networks and System Design sections complement this for full-stack understanding.",
      order: 14,
      published: true,
      items: [
        {
          title: "Processes & Threads",
          description:
            "Process vs thread; context switch; multi-threading; when to use which",
          order: 0,
          imageUrl:
            "https://placehold.co/800x400/1d4ed8/white?text=Processes+%26+Threads",
          content:
            "**1. Learning flow:** (1) Read material and the difference between process and thread: process has its own memory space and is isolated; thread shares memory with other threads in the same process and is lighter to create. (2) Run a multi-threaded program (e.g. Python threading.Thread(target=fn).start() or Java new Thread(() -> {}).start()) so you see how multiple threads run concurrently; optionally run a multi-process version (e.g. Python multiprocessing.Process) and compare. (3) Compare Node.js (single-threaded event loop; I/O done by libuv thread pool) vs Apache (multi-process or multi-threaded workers) so you understand when one process per request vs one thread per request vs one thread for many requests is used. (4) Identify a real case: a web server that uses worker processes (isolation, crash containment) vs worker threads (shared memory, lower overhead but need locks).\n\n**2. Material:** A **process** is an instance of a program with its own address space, file descriptors, and system resources; the OS isolates processes so a crash in one does not affect others. Creating a process (e.g. fork()) is relatively heavy because the OS must set up a new address space and copy or share resources. A **thread** is a unit of execution within a process; threads in the same process share the address space (code, data, heap) but have their own stack and register state. Creating a thread is lighter than creating a process, but because threads share memory, any shared data (e.g. a counter, a cache) must be protected with synchronization (mutexes, semaphores) to avoid race conditions. **Context switch:** When the OS switches from one process or thread to another, it saves the current state (registers, program counter) and restores the state of the next; switching between threads of the same process is cheaper than switching between processes (same address space, so no TLB flush).\n\n**3. Explanation:** Process isolation means a bug or crash in one process does not corrupt another; that is why browsers run tabs in separate processes. Threads share memory so they can communicate efficiently but must coordinate access to shared data. The context-switch cost affects how many threads or processes you can run efficiently; thread switches are cheaper so multi-threaded servers can handle more concurrent work per process, but you must get synchronization right.\n\n**4. Application:** Web server: multi-process (e.g. Apache prefork) gives isolation—one crashed request does not kill others—but higher memory per connection; multi-threaded (e.g. Apache worker) shares memory and is lighter but requires thread-safe code. Node.js: single thread + event loop handles many connections without blocking; I/O is offloaded to libuv so the main thread stays responsive. Use multiple processes when you need isolation or when the language (e.g. Python with GIL) limits CPU parallelism of threads; use threads when you need shared memory and the workload is I/O-bound or you have few CPU-bound sections.\n\n**5. How to implement:** (1) Python threads: import threading; t = threading.Thread(target=worker_fn); t.start(); t.join() to wait. (2) Python processes: import multiprocessing; p = multiprocessing.Process(target=worker_fn); p.start(); p.join(). (3) Java: new Thread(() -> { ... }).start(); or extend Thread and override run(). (4) C: fork() for a new process (child gets a copy of the parent's address space); pthread_create() for a thread. (5) For a thread pool use concurrent.futures.ThreadPoolExecutor (Python) or ExecutorService (Java) so you limit the number of threads and reuse them. See code below.\n\n**6. Logic & how the code works:**\n\nA process has its own memory space so a crash or bug in one does not corrupt another; creating a process (fork) is heavier because the OS must set up a new address space. A thread shares memory with other threads in the same process, so it is cheap to create but shared data (e.g. a counter) needs synchronization. Context switch: the OS saves the current thread's registers and restores another's; thread switches are cheaper than process switches because the same address space is kept.\n\n**7. Example problem & solution:** Problem: App handles 1000 concurrent requests; single-threaded blocks. Solution: Multi-threaded pool (e.g. 8 threads) or multi-process (e.g. 4 workers). Each handles requests; process is isolated, thread shares cache.\n\n**8. Additional information:** Use multiple processes for isolation (e.g. separate services); use threads for parallelism inside one process (e.g. request handling). GIL in Python limits CPU parallelism for threads; use multiprocessing for CPU-bound.",
          codeExample:
            "# Python: threading vs multiprocessing\nimport threading\nimport multiprocessing\ndef worker():\n  print('Worker running')\n# Thread (shares memory)\nt = threading.Thread(target=worker)\nt.start(); t.join()\n# Process (isolated)\np = multiprocessing.Process(target=worker)\np.start(); p.join()",
          codeLanguage: "python",
        },
        {
          title: "Memory Management",
          description:
            "Virtual memory, paging, TLB; stack vs heap; memory leaks",
          order: 1,
          imageUrl:
            "https://placehold.co/800x400/2563eb/white?text=Virtual+Memory",
          content:
            "**1. Learning flow:** (1) Read material on virtual memory (each process has its own address space; OS maps virtual pages to physical frames via page table; TLB caches mappings), stack vs heap (stack for locals and calls, heap for dynamic allocation), and why memory leaks happen (allocated heap never freed). (2) Run a small program that leaks memory (e.g. in a loop allocate a buffer and never free it); watch the process RSS grow over time (e.g. with top or /proc/<pid>/status). (3) Fix the leak: in C/C++ add matching free/delete or use RAII (e.g. std::unique_ptr); in Node/JS reduce long-lived references and avoid holding large data in closures. (4) Use a tool to find leaks: Valgrind (memcheck) or AddressSanitizer (ASan) for C/C++; they report allocations that were never freed. (5) Real case: a long-running server that leaks a small amount per request can hit OOM after days; monitoring RSS and fixing leaks is essential for production.\n\n**2. Material:** Virtual memory lets each process see a full address space; OS maps virtual pages to physical frames. Stack = function calls, local vars; heap = dynamic allocation. Paging: Memory split into pages; OS keeps page table (virtual → physical). TLB caches recent mappings to avoid slow table lookups. Swap: rarely used pages can go to disk. Memory leak: allocated heap not freed; process grows over time. Fix: free when done, use RAII/smart pointers, or GC.\n\n**3. Explanation:** Virtual memory isolates processes; each sees contiguous address space. Page table maps virtual to physical; TLB is a cache for recent mappings. Memory leak: heap grows until OOM.\n\n**4. Application:** Real case: Web server handles millions of requests; one path leaks a buffer per request. After hours, RSS spikes; OOM killer. Fix: audit allocations, use RAII or GC.\n\n**5. How to implement:** (1) C/C++: Use malloc/free or new/delete; prefer RAII (e.g. std::unique_ptr, std::shared_ptr, or a wrapper that frees in the destructor) so you never forget to free. (2) Node/JavaScript: V8 manages heap with GC; avoid memory leaks by not holding references in closures or global state longer than needed (e.g. remove event listeners, clear caches with a bound). (3) To find leaks: run under Valgrind (memcheck) or build with AddressSanitizer (ASan) and run your test or workload; they report allocations not freed. (4) Monitor: use top or /proc/<pid>/status to watch RSS over time; if it grows unbounded with stable load, suspect a leak. (5) Fix: ensure every allocation has a matching free (or is owned by an RAII object); for Node audit closures and long-lived references. See code below.\n\n**6. Logic & how the code works:**\n\nVirtual memory gives each process its own address space; the OS maps virtual pages to physical frames via the page table. The TLB caches recent mappings so most accesses don't walk the full table. A memory leak is heap allocation that is never freed; the process's resident set grows until the system runs out of memory. RAII ties resource lifetime to object lifetime so the destructor frees the resource when the object goes out of scope.\n\n**7. Example problem & solution:** Problem: Server memory grows unbounded. Solution: Profile with top or /proc; find growing process. Use Valgrind or ASan to find leak. Fix: free in destructor, use smart pointers, or fix reference in closure.\n\n**8. Additional information:** Swap extends usable memory but is slow. Overcommit allows more virtual than physical; can cause OOM when all commit. Transparent huge pages reduce TLB misses.",
          codeExample:
            '// C++: RAII prevents leak\nstruct FileHandle {\n  FILE* f;\n  FileHandle(const char* path) { f = fopen(path, "r"); }\n  ~FileHandle() { if (f) fclose(f); }\n};\n// Or: std::unique_ptr\n// Python: no manual free; watch closures holding refs',
          codeLanguage: "cpp",
        },
        {
          title: "Concurrency",
          description:
            "Race conditions; mutex, semaphore, lock; thread-safe data structures",
          order: 2,
          imageUrl:
            "https://placehold.co/800x400/16a34a/white?text=Concurrency+%26+Locks",
          content:
            "**1. Learning flow:** (1) Read material and mutex vs semaphore. (2) Run the counter example below; see wrong result without lock, correct with lock. (3) Implement a thread-safe queue. (4) Identify real case: web server handling concurrent requests with shared cache.\n\n**2. Material:** Race condition = two threads access shared data and at least one writes; result depends on timing. Fix with synchronization. Mutex (lock): Only one thread holds it; others block. Semaphore: Counter; N threads can enter; use for limiting concurrency or signaling. Deadlock: two threads each hold a lock and wait for the other’s.\n\n**3. Explanation:** Mutex ensures mutual exclusion. Semaphore limits concurrency (e.g. max 5 DB connections). Always acquire in same order to avoid deadlock.\n\n**4. Application:** Web server: shared connection pool, cache. Producer-consumer: queue with mutex. Rate limiter: semaphore. Real case: Node.js event loop; libuv thread pool for I/O; shared state needs care.\n\n**5. How to implement:** (1) Identify shared data (e.g. a counter, a cache map) and every place it is read or written. (2) Protect the critical section with a mutex: acquire the lock before accessing the shared data and release it after; use a scoped guard (e.g. std::lock_guard in C++, with lock: in Python) so the lock is always released even if an exception occurs. (3) C++: std::mutex mtx; std::lock_guard<std::mutex> lock(mtx); /* access shared data */ . (4) Python: lock = threading.Lock(); with lock: ... access shared data ... . (5) Java: synchronized (object) { ... } or ReentrantLock. (6) For limiting concurrency (e.g. max 5 DB connections) use a semaphore instead of a mutex. See code below.\n\n**6. Logic & how the code works:**\n\nWithout a lock, two threads can read the same value, both increment, and both write back; one update is lost. A mutex ensures only one thread at a time runs the critical section (e.g. counter++), so read-modify-write is atomic. lock_guard (or with lock) acquires on construction and releases on destruction so you cannot forget to unlock.\n\n**7. Example problem & solution:** Problem: Two threads increment counter; without lock you get lost updates. Solution: Wrap increment in mutex. Real case: rate limiter tracking requests per user; mutex protects the map.\n\n**8. Additional information:** Minimize shared state; use thread-safe structures. Prefer higher-level primitives (channels, async/await) when available.",
          codeExample:
            "// C++: mutex for counter\nstd::mutex mtx;\nvoid increment() {\n  std::lock_guard<std::mutex> lock(mtx);\n  counter++;\n}\n// Python\nlock = threading.Lock()\nwith lock:\n    counter += 1",
          codeLanguage: "cpp",
        },
        {
          title: "Deadlock",
          description:
            "Conditions for deadlock; prevention (ordering, timeouts); detection and recovery",
          order: 3,
          imageUrl:
            "https://placehold.co/800x400/ea580c/white?text=Deadlock+Prevention",
          content:
            "**1. Learning flow:** (1) Read material and four conditions. (2) Write code that deadlocks (two threads, two locks, acquire in opposite order). (3) Fix with lock ordering. (4) Identify real case: DB transactions holding locks.\n\n**2. Material:** Deadlock needs four conditions: mutual exclusion, hold-and-wait, no preemption, circular wait. Break any one to prevent it. Prevention: Lock ordering—always acquire locks in the same order (e.g. A then B) so no cycle. Timeout: if lock not acquired in time, release and retry. Avoidance: only grant resource if it cannot lead to deadlock (banker’s algorithm). Detection: build wait-for graph; cycle = deadlock. Recovery: kill one process or preempt a resource.\n\n**3. Explanation:** Circular wait = cycle in wait-for graph. Lock ordering breaks circular wait: if all acquire A before B, no thread holds B and waits for A.\n\n**4. Application:** Real case: Transfer between accounts. Thread 1: lock A, wait B. Thread 2: lock B, wait A. Deadlock. Fix: always lock in order (e.g. by account id: lock smaller id first).\n\n**5. How to implement:** (1) Define a global lock order (e.g. always acquire mutexA before mutexB, or lock resources by a consistent key such as account id: lock the smaller id first). (2) In every code path that needs multiple locks, acquire them in the same order so no thread can hold B and wait for A while another holds A and waits for B. (3) Alternatively use try_lock with a timeout: if you cannot acquire the second lock within the timeout, release the first and retry (or back off) to avoid waiting forever. (4) Document the lock order in comments so future code does not break it. (5) For transfer between two accounts, lock the account with the smaller id first, then the other, so both threads agree on order. See code below.\n\n**6. Logic & how the code works:**\n\nDeadlock occurs when thread 1 holds A and waits for B while thread 2 holds B and waits for A; the cycle in the wait-for graph means neither can progress. Lock ordering removes cycles: if every thread acquires A before B, no one can hold B and wait for A. Locking by a consistent key (e.g. account id) makes the order well-defined and avoids circular wait.\n\n**7. Example problem & solution:** Problem: Two threads transfer money; each locks source then destination; opposite order causes deadlock. Solution: Lock accounts in consistent order (e.g. by id: lock min(id1,id2) first, then max). No circular wait possible.\n\n**8. Additional information:** DBs use lock ordering (e.g. by row id) and timeouts. Many systems prefer prevention over detection; recovery is costly.",
          codeExample:
            "// Deadlock prevention: lock ordering\n// WRONG: Thread1 locks A then B, Thread2 locks B then A → deadlock\n// RIGHT: always lock smaller id first\nvoid transfer(Account& from, Account& to, int amt) {\n  auto& first = from.id < to.id ? from : to;\n  auto& second = from.id < to.id ? to : from;\n  std::lock_guard l1(first.mutex);\n  std::lock_guard l2(second.mutex);\n  // ... transfer\n}",
          codeLanguage: "cpp",
        },
        {
          title: "Scheduling",
          description:
            "CPU scheduling (FCFS, SJF, round-robin); preemption; fairness vs throughput",
          order: 4,
          imageUrl:
            "https://placehold.co/800x400/059669/white?text=CPU+Scheduling",
          content:
            "**1. Learning flow:** (1) Read material and scheduling policies. (2) Trace: 3 processes arrive; compute turnaround and wait time for FCFS vs RR. (3) When would SJF starve? (4) Real case: OS scheduler for interactive vs batch jobs.\n\n**2. Material:** Scheduler decides which process/thread runs next. Goals: throughput, low latency, fairness. FCFS: First come first served; simple but long jobs can block others. SJF: Shortest job first; good for throughput but can starve long jobs. Round-robin: Each process gets a time slice; fair, good for interactive; slice size trades context switch cost vs responsiveness. Preemption: OS can take CPU away (e.g. when slice ends) so one process cannot monopolize.\n\n**3. Explanation:** FCFS is non-preemptive; once a process runs, it runs until done (or I/O). RR is preemptive; after quantum, switch to next. SJF needs knowledge of burst time (estimate from history).\n\n**4. Application:** Real case: Desktop OS uses RR-like (e.g. CFS in Linux) for responsiveness. Server batch jobs might use FCFS or priority. Real-time systems use EDF or rate-monotonic.\n\n**5. How to implement:** (1) Most applications do not implement CPU scheduling; the OS scheduler does. For interviews and exams: given a set of processes with arrival and burst times, draw a Gantt chart for the requested policy (FCFS, SJF, RR). (2) Compute turnaround time per process = completion time - arrival time; wait time = turnaround - burst time; then average. (3) FCFS: run processes in order of arrival; no preemption. (4) SJF: run the process with the smallest burst time next; if non-preemptive, run to completion; if preemptive, can switch when a shorter job arrives. (5) Round-robin: give each process a time quantum (e.g. 4 ms); run in order, preempt when quantum expires and move to back of queue. (6) Compare policies: RR improves response for short jobs; SJF minimizes average wait if burst times are known. See example in section 7.\n\n**6. Logic & how the code works:**\n\nFCFS runs jobs in arrival order; no preemption so a long job blocks everyone behind it. Round-robin gives each job a time slice (quantum); when the slice ends the job is preempted and goes to the back of the queue, so short jobs finish quickly and the system feels responsive. SJF minimizes average wait time if burst times are known but can starve long jobs; typically used with estimates from past behavior.\n\n**7. Example problem & solution:** Problem: P1 burst 24, P2 burst 3, P3 burst 3; all arrive at 0. FCFS: P1 runs 24, then P2 3, P3 3. Avg wait = (0+24+27)/3 = 17. RR q=4: P1 runs 4, P2 3 (done), P3 3 (done), P1 runs 20 more. Better for P2, P3. SJF: run P2, P3 first; then P1. Avg wait lower.\n\n**8. Additional information:** Multilevel feedback queue: combine RR with priority; promote/short bursts get better response. Linux CFS: fair scheduling with virtual runtime.",
        },
      ],
    },
    {
      title: "Computer Networks",
      slug: "computer-networks",
      description:
        "Essential for system design and backend: TCP vs UDP (reliable vs connectionless, when to use which), HTTP methods and status codes and REST and idempotency, DNS resolution and caching and CDN for latency, and TLS/HTTPS for encryption and certificates in production. Before you start: basic idea of client-server and request/response; Node.js or any backend experience helps; System Design & DevOps builds on this.",
      order: 15,
      published: true,
      items: [
        {
          title: "TCP vs UDP",
          description:
            "Connection-oriented vs connectionless; reliability, ordering; when to use which; ports",
          order: 0,
          imageUrl:
            "https://placehold.co/800x400/1e3a8a/white?text=TCP+%26+UDP",
          content:
            "**1. Learning flow:** (1) Read material and the TCP vs UDP trade-offs: TCP gives reliability and ordering (handshake, retransmit, flow control) at the cost of higher latency when packets are lost; UDP has no guarantee but low overhead and is better for real-time. (2) Trace an HTTP request end-to-end: browser opens a TCP connection to port 443, performs TLS handshake, then sends HTTP request and receives response over the same connection. (3) Compare use cases: video call or game (UDP—late packet is useless, prefer drop) vs file download or web page (TCP—every byte must arrive in order). (4) Use Wireshark or browser DevTools (Network tab) to observe the TCP handshake (SYN, SYN-ACK, ACK) and subsequent data segments.\n\n**2. Material:**\n\nTCP = reliable, ordered, connection-oriented; UDP = no guarantee, low overhead, connectionless.\n\nTCP: Three-way handshake (SYN, SYN-ACK, ACK); guarantees delivery and order; flow control and congestion control. Use for: HTTP, HTTPS, SSH, when you need reliability.\n\nUDP: No handshake; packets may be lost or reordered. Use for: video/voice (real-time), DNS queries, gaming. Ports: 0–65535; well-known (e.g. 80 HTTP, 443 HTTPS) vs ephemeral for clients.\n\n**3. Explanation:**\n\nTCP adds headers and retransmission; UDP sends datagrams with minimal overhead. Real-time apps prefer UDP (a late packet is useless; better to drop) over TCP (retransmit delays). HTTP/HTTPS use TCP because you need every byte of the page.\n\n**4. Application:**\n\nReal case: Browser loads a page → TCP to :443, TLS handshake, HTTP request/response. Video call → UDP; lost frames cause brief glitch, not long wait. DNS → UDP for one query; TCP for large response. Gaming → UDP for position updates; TCP for chat.\n\n**5. How to implement:** (1) In Node.js: http.request() or fetch() use TCP under the hood; for raw TCP use net.createConnection(port, host). (2) For UDP in Node: require('dgram'); createSocket('udp4'); send(buffer, offset, length, port, host). (3) In the browser, fetch and XHR use TCP (you cannot open raw UDP from the browser). (4) In C/socket programming: socket(AF_INET, SOCK_STREAM, 0) for TCP (then connect, send, recv); socket(AF_INET, SOCK_DGRAM, 0) for UDP (then sendto, recvfrom). (5) To observe: use Wireshark and filter by tcp or udp; or browser DevTools → Network → right-click request → Copy as cURL to see the HTTP over TCP flow. See code below.\n\n**6. Logic & how the code works:**\n\nTCP establishes a connection (handshake), then guarantees ordered delivery by retransmitting lost segments and reordering at the receiver; that adds latency when packets are lost. UDP sends datagrams with no retransmission; if a packet is lost it is gone. For real-time traffic (game state, video frames), a late or retransmitted packet is often useless, so UDP with loss is better than TCP blocking on retransmit.\n\n**7. Example problem & solution:**\n\nProblem: Should a real-time game use TCP or UDP? Solution: UDP. Game state updates are frequent; if one packet is late, skip it (next update is coming). TCP would block on retransmit and cause lag. Use UDP with custom reliability only where needed (e.g. critical actions).\n\n**8. Additional information:**\n\nQUIC (HTTP/3) combines UDP with reliability where needed. WebRTC uses UDP for media. Learn TCP 3-way handshake diagram for interviews.",
          codeExample:
            "// Node.js: HTTP (TCP) vs UDP\n// HTTP uses TCP internally\nfetch('https://example.com');\n// UDP socket\nconst dgram = require('dgram');\nconst client = dgram.createSocket('udp4');\nclient.send(Buffer.from('query'), 0, 5, 53, '8.8.8.8');",
          codeLanguage: "javascript",
        },
        {
          title: "HTTP & REST",
          description:
            "Methods, status codes, headers; idempotency; REST best practices; HTTP/1.1 vs HTTP/2",
          order: 1,
          imageUrl:
            "https://placehold.co/800x400/2563eb/white?text=HTTP+%26+REST",
          content:
            "**1. Learning flow:** (1) Read material and HTTP methods. (2) Use fetch or curl to send GET, POST, PUT; observe status codes. (3) Design a REST API for a resource (e.g. /posts/:id). (4) Explain idempotency for GET vs POST.\n\n**2. Material:** HTTP is request-response over TCP; REST uses URLs as resources and HTTP methods as actions. Methods: GET (read, idempotent), POST (create), PUT (replace, idempotent), PATCH (partial update), DELETE (idempotent). Status: 2xx success, 3xx redirect, 4xx client error, 5xx server error. Idempotent: same request twice = same effect (GET, PUT, DELETE).\n\n**3. Explanation:** REST is a style, not a protocol. Nouns in URL; verbs = HTTP methods. Correct status codes help clients and tools. Idempotency matters for retries: PUT twice = same result; POST twice = two resources.\n\n**4. Application:** Real case: API for users. GET /users (list), GET /users/1 (one), POST /users (create, 201), PUT /users/1 (replace, 200), DELETE /users/1 (204). Version in URL /v1/users or header.\n\n**5. How to implement:** (1) Use fetch or axios for requests; always check res.ok and res.status (e.g. 200, 201, 404, 500) and handle errors. (2) GET: no body; pass query params in URL or as searchParams. (3) POST/PUT/PATCH: send JSON with headers: { 'Content-Type': 'application/json' } and body: JSON.stringify({ ... }). (4) For idempotency: send Idempotency-Key header (e.g. UUID) on POST so retries do not create duplicates. (5) Design REST: nouns in URL (e.g. /users, /users/:id); GET = read, POST = create, PUT = replace, PATCH = partial update, DELETE = remove; return correct status (201 for create, 204 for delete). (6) Version API via URL path (/v1/users) or header (Accept: application/vnd.api+v1). See code below.\n\n**6. Logic & how the code works:**\n\nHTTP is application-layer; it runs on top of TCP so each request is a stream of bytes. GET is idempotent (same request twice has the same effect); POST is not (two POSTs create two resources). Retrying a failed POST can therefore create duplicates; an idempotency key lets the server recognize a retry and return the same result without creating again.\n\n**7. Example problem & solution:** Problem: Client retries POST; server creates duplicate. Solution: Use idempotency key in header; server deduplicates. Or design as PUT with client-generated ID. Real case: payment API uses Idempotency-Key header.\n\n**8. Additional information:** REST: Nouns in URL, use status codes and body; version in URL or header. HTTP/2: multiplexing, binary, header compression.",
          codeExample:
            "// fetch GET\nconst res = await fetch('/api/users/1');\nif (res.ok) const user = await res.json();\n// fetch POST\nawait fetch('/api/users', {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({ name: 'Alice' })\n});",
          codeLanguage: "javascript",
        },
        {
          title: "DNS & CDN",
          description:
            "How DNS resolution works; caching; CDN for static assets and latency",
          order: 2,
          imageUrl:
            "https://placehold.co/800x400/16a34a/white?text=DNS+CDN+%26+Edge",
          content:
            "**1. Learning flow:**\n\n(1) Read the material below so you understand how DNS maps domain names to IP addresses (resolver → root → TLD → authoritative server, with caching at each level) and how a CDN caches static content at edge locations close to users to reduce latency and offload the origin server. (2) Use dig or nslookup to trace DNS for a domain (e.g. example.com): run the command and observe the resolver, root server, TLD server, and authoritative server in the response; note the TTL values and record types (A, AAAA, CNAME). (3) Trace a request to a CDN-hosted asset: open DevTools Network tab, load a page that uses a CDN (e.g. Cloudflare or CloudFront), and inspect the request URL and response headers (e.g. x-cache, server) to see that the response came from an edge. (4) Real case: a user in Sydney requests example.com; the browser resolves the domain via DNS (possibly cached), then requests the page and static assets; for CDN-hosted assets the CDN routes the request to an edge in or near Sydney so the user gets low-latency responses and the origin server is not hit for every user.\n\n**2. Material:**\n\n**DNS (Domain Name System)** maps human-readable domain names to IP addresses so clients can connect to servers without memorizing numbers. When the browser (or OS) needs an IP for a domain, it asks a resolver (often provided by the ISP or a public resolver like 8.8.8.8). The resolver may have the answer cached; otherwise it follows the hierarchy: root servers (.) point to TLD servers (.com, .org), which point to the authoritative servers for the domain (e.g. example.com). Caching at the OS and resolver reduces load and speeds up repeated lookups; TTL (time to live) in the response controls how long a cache can store the result. Record types: A (IPv4 address), AAAA (IPv6), CNAME (alias to another name), MX (mail), etc.\n\n**CDN (Content Delivery Network)** is a network of edge servers that cache static content (images, JavaScript, CSS, video) close to users. When a user requests a CDN URL, the request is routed to the nearest edge (e.g. by DNS or anycast); if the edge has the content cached it serves it directly, otherwise it fetches from the origin and caches it for future requests. This lowers latency (user gets data from a nearby server), reduces load on the origin, and improves availability. Use CDNs for static files, media, and global applications where users are distributed.\n\n**3. Explanation:**\n\nThe DNS hierarchy (root → TLD → authoritative) and caching at each step mean that most lookups are answered from cache and only the first lookup (or after TTL expiry) traverses the full chain. TTL controls how long resolvers and clients can cache; short TTL allows fast changes (e.g. failover) but increases load. A CDN edge is effectively a cache close to the user: the first request for an asset may hit the origin, but subsequent requests from the same or nearby users are served from the edge, so latency drops and the origin handles fewer requests.\n\n**4. Application:** Real case: Global web app. Origin in US; users in Asia get slow load. Add CDN; static assets cached at Asia edges; latency drops. DNS: use CNAME for subdomain (e.g. www → load balancer).\n\n**5. How to implement:** (1) DNS lookup: from terminal run dig example.com or nslookup example.com; use dig +trace example.com to see full resolution path (resolver → root → TLD → authoritative). (2) Inspect record types: dig example.com A (IPv4), AAAA (IPv6), CNAME (alias); note TTL in the response. (3) Configure a CDN: in your DNS, add a CNAME for the subdomain (e.g. static.yoursite.com) pointing to the CDN hostname (e.g. d1234.cloudfront.net); in the CDN dashboard set the origin (your server or S3 bucket) and which paths to cache (e.g. /assets/*). (4) Set cache TTL (e.g. 1 day for static assets); use cache invalidation when you deploy new JS/CSS. (5) Use CloudFront, Cloudflare, or Fastly; test by requesting the asset and checking response headers (e.g. x-cache: Hit from cloudfront). See code below.\n\n**6. Logic & how the code works:**\n\nDNS resolution walks the hierarchy (resolver → root → TLD → authoritative); each step can be cached (TTL) so repeated lookups are fast. A CDN is a distributed cache: the first request for an asset hits the origin and the edge caches it; later requests from the same region are served from the edge, so latency is low and origin load is reduced.\n\n**7. Example problem & solution:** Problem: Users in Europe get 2s load for JS from US origin. Solution: CDN with European edges. First request: edge fetches from origin, caches. Next requests: edge serves from cache; latency ~50ms. TTL (e.g. 1 day) balances freshness vs load.\n\n**8. Additional information:** DNS over HTTPS (DoH) encrypts queries. CDN invalidation when you update static files. Edge computing: run code at edge (Cloudflare Workers, Lambda@Edge).",
          codeExample:
            "# DNS lookup: dig or nslookup\ndig example.com\n# A record (IPv4), AAAA (IPv6), CNAME (alias)\ndig example.com A\ndig www.example.com CNAME\n# Trace resolution\ndig +trace example.com",
          codeLanguage: "bash",
        },
        {
          title: "TLS & HTTPS",
          description:
            "Encryption, handshake; certificates; why HTTPS matters in production",
          order: 3,
          imageUrl:
            "https://placehold.co/800x400/059669/white?text=TLS+%26+HTTPS",
          content:
            "**1. Learning flow:**\n\n(1) Read the material below so you understand that HTTPS is HTTP over TLS: the connection is encrypted and the server is authenticated via a certificate so the client can trust that it is talking to the right server and that no one can eavesdrop or tamper with the data. (2) Open browser DevTools → Network tab, load an HTTPS site (e.g. https://example.com), and inspect the request: you will see the protocol (h2 or http/1.1 over TLS) and that the connection is secure; optionally check the certificate (click the lock icon or view connection details) to see the issuer (CA) and validity. (3) Use Let's Encrypt (certbot) or a cloud provider (e.g. AWS ACM, Cloudflare) to obtain a certificate for a domain you control so you see the steps: generate a key pair, request a certificate (often with automatic domain validation), and configure your server or load balancer to use it. (4) Real case: a login form over HTTP sends the password in plaintext—an attacker on the same network (e.g. public Wi‑Fi) can intercept it; over HTTPS the entire request and response are encrypted so the password cannot be read in transit.\n\n**2. Material:**\n\n**HTTPS** is HTTP carried over TLS (Transport Layer Security). It provides confidentiality (encryption so eavesdroppers cannot read the data), integrity (tampering is detected), and authentication (the server presents a certificate so the client can verify it is talking to the right host). Browsers show a lock icon and treat HTTPS as secure; HTTP is increasingly marked as not secure.\n\n**TLS handshake:** The client sends a Client Hello (supported ciphers, etc.); the server responds with Server Hello (chosen cipher), its certificate (binding the domain to a public key), and key exchange parameters; the client verifies the certificate (signature from a trusted CA, valid domain, not expired) and derives a shared secret; thereafter all application data (HTTP) is encrypted with a symmetric key derived from that secret. The certificate proves the server owns the domain; a Certificate Authority (CA) like Let's Encrypt or DigiCert signs the certificate so browsers (which ship with a list of trusted CAs) can verify it. After the handshake, bulk encryption uses a symmetric key for performance.\n\n**Practice:** Always use HTTPS in production for any site that handles credentials or sensitive data. Store TLS private keys and other secrets in environment variables or a secret manager (e.g. AWS Secrets Manager), never in source code or in the repository.\n\n**3. Explanation:**\n\nThe TLS handshake negotiates the cipher suite, authenticates the server via the certificate (the client checks the CA signature and that the certificate's domain matches the host), and establishes a shared secret used to derive symmetric keys for encryption. The certificate binds the domain name to a public key; the CA's signature allows the client to trust that binding. Once the handshake completes, application data (HTTP request/response) is encrypted so an attacker on the path cannot read or modify it without being detected.\n\n**4. Application:** Real case: API with sensitive data. Without TLS: man-in-the-middle can read/modify. With TLS: encrypted; attacker sees ciphertext only. OAuth, login, payments—all need HTTPS.\n\n**5. How to implement:** (1) Use a reverse proxy (nginx, Caddy) in front of your app to terminate TLS; the proxy holds the certificate and forwards plain HTTP to your app on localhost. (2) Or use a PaaS (Heroku, Vercel, Netlify) which provisions and renews certificates for you. (3) Get a certificate: Let's Encrypt with certbot (e.g. certbot certonly --standalone -d example.com) or acme.sh for automation; cloud providers (AWS ACM, GCP) can also issue and attach certs to load balancers. (4) In nginx: set ssl_certificate and ssl_certificate_key to the paths of fullchain.pem and privkey.pem; listen 443 ssl. (5) Redirect HTTP to HTTPS: server { listen 80; return 301 https://$host$request_uri; }. (6) Set HSTS: add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains\"; so browsers always use HTTPS. (7) Never put API keys or secrets in client code or in git; use environment variables or a secret manager. See code below.\n\n**6. Logic & how the code works:**\n\nThe TLS handshake negotiates a cipher suite and authenticates the server via its certificate; the client checks that a trusted CA signed the cert and that the domain matches. After the handshake, a symmetric key is used to encrypt the rest of the session. Without TLS, anyone on the path can read or modify traffic; with TLS, only ciphertext is visible and tampering is detected.\n\n**7. Example problem & solution:** Problem: New site on HTTP; browser shows \"Not secure.\" Solution: Get cert (Let's Encrypt free); configure nginx with ssl_certificate; redirect 80 → 443. HSTS: Strict-Transport-Security header forces HTTPS.\n\n**8. Additional information:** Certificate chain: server cert → intermediate → root (in browser). TLS 1.2/1.3; avoid TLS 1.0/1.1. Store API keys in env or secrets manager; never in client code or git.",
          codeExample:
            "# Let's Encrypt with certbot\ncertbot certonly --standalone -d example.com\n# nginx SSL config\nserver {\n  listen 443 ssl;\n  ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;\n  ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;\n}",
          codeLanguage: "bash",
        },
      ],
    },
  ],
};
